{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "499_A2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5tos15BFuVzm",
        "lfxcnVReUp-J"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ColbyLe/CS499A2/blob/master/499_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95fTUMJCAfsQ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!mkdir /root/.kaggle\n",
        "!mkdir .kaggle\n",
        "\n",
        "import json\n",
        "token = {\"username\":\"colbyle\",\"key\":\"f77beaea20746ec9c2d601f26ba19909\"}\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orQjdOW8Au4b",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v/content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kaiBl-qCYER",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!kaggle competitions download -c cs4990-fall2019-assignment-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I287Ls8lJIxe",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!mv /content/competitions/cs4990*2/test_data.csv.zip /content/test_data.csv.zip\n",
        "!mv /content/competitions/cs4990*2/train_data.csv.zip /content/train_data.csv.zip\n",
        "!mv /content/competitions/cs4990*2/train_target.csv /content/train_target.csv\n",
        "!rm -r competitions\n",
        "\n",
        "!unzip /content/train_data.csv.zip\n",
        "!unzip /content/test_data.csv.zip\n",
        "!rm /content/train_data.csv.zip\n",
        "!rm /content/test_data.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So73YZrvZ1rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Activation, GaussianNoise\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP-GLcu3bwD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data and targets\n",
        "train_data = np.loadtxt(open(\"train_data.csv\"), delimiter = \",\")\n",
        "\n",
        "train_target = np.loadtxt(open(\"train_target.csv\"), delimiter = \",\")\n",
        "\n",
        "test_data = np.loadtxt(open(\"test_data.csv\"), delimiter = \",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qsf9HSzuKV1",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "toDiv = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2E6ZDM2DoNx",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "if(toDiv == 0):\n",
        "  train_data /= 255.0\n",
        "  test_data /= 255.0\n",
        "  toDiv+=1\n",
        "  print(\"Feature scaling complete\\n\")\n",
        "else: print(\"NOPE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9idyUkAlBiR",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# display 1 image\n",
        "im1 = train_data[11119].reshape(48,48)\n",
        "plt.imshow(im1)\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqqNccRgbtfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape data to fit model\n",
        "train_data = train_data.reshape(16175,48,48,1)\n",
        "test_data = test_data.reshape(3965,48,48,1)\n",
        "\n",
        "#change target to one-hot encoding\n",
        "train_target = to_categorical(train_target)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv1Xek25y1qD",
        "colab_type": "code",
        "outputId": "8f1459f3-5b15-4fe8-c151-e0dc6e710384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#split data into training and validation sets\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_target, test_size=0.1, random_state=42)\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_valid.shape, Y_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14557, 48, 48, 1) (14557, 3)\n",
            "(1618, 48, 48, 1) (1618, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhMhq-6N0jRh",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "e2734d65-77a7-47c9-a46b-4991a67a27a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#@title\n",
        "images = range(0,9)\n",
        "for i in images:\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    plt.imshow(X_train[i].reshape(48,48))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD8CAYAAAAYJk2jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpFhe_ONoQ0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define initial parameters\n",
        "num_classes = 3\n",
        "batch_size = 64\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFBx5yaKTt0P",
        "colab_type": "text"
      },
      "source": [
        "<br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOT4CY1IrWnO",
        "colab_type": "text"
      },
      "source": [
        "Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jo2qiIhrU8I",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# simple horizontal flip\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVskzgjuwoKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator for augmented image data\n",
        "moreGen = ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=0.05,\n",
        "                               height_shift_range=0.05,\n",
        "                               zoom_range=[0.9, 1.1],\n",
        "                               horizontal_flip=True,\n",
        "                               fill_mode='nearest',\n",
        "                               data_format='channels_last')\n",
        "\n",
        "moreGen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "gb-NJhOe78lj",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "extraGen = ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=0.05,\n",
        "                               height_shift_range=0.05,\n",
        "                               #shear_range=0.01,\n",
        "                               zoom_range=[0.8, 1.3],\n",
        "                               horizontal_flip=True,\n",
        "                               #vertical_flip=False,\n",
        "                              shear_range=0.05\n",
        "                               fill_mode='nearest',\n",
        "                               data_format='channels_last')\n",
        "\n",
        "extraGen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g-Zn14I1ShB",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "32f2ae2b-6a10-4e8c-932d-65e159c5f739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#@title\n",
        "for X_batch, Y_batch in moreGen.flow(X_train, Y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(48, 48))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD8CAYAAAAYJk2jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9e6zlWXbf9Vl7/17nde+599atd3dV\n93T39Dw8Dz8GO7ZjY0NI7EASJViQCAJYWChCIgKUB0ICJJDCP0AkniOCMBZgE4iwBSaBhDD2jDP2\nODPj8Yz7Mf2o6u7qqlt13+f1e+29+WPv3z7n1vR0dU1Xaqpr7pJaXeeec37nnL1+e+21vmut7xLn\nHKdyKqdyKqfy3kV9t7/AqZzKqZzKB01ODeepnMqpnMp9yqnhPJVTOZVTuU85NZynciqncir3KaeG\n81RO5VRO5T7l1HCeyqmcyqncp7wvwykif1REXhKRV0TkrzyoL3Uq31051evjK6e6fTAi32kdp4ho\n4GXgnwTeAr4E/PPOuT94cF/vVB62nOr18ZVT3T44eT8e52eAV5xzrznnauCXgT/xYL7WqXwX5VSv\nj6+c6vYBSfI+3nsJeHPl8VvAP/Zub0jzgesl6wC4RGETQbonHTgBp8NDDTYFlRkA8qSlr2ty1fpr\n0aLExfcLJz1nF/7SvcK55b8BDIrGaZzzf7MIjdO01p8l1imME0z32ChoBNX49yeVQ9UWm6ruCxA+\nEADV2m/5/ceLm7vOue13W6NHQO5br8W4cKOLg/hY4VDiF0Lj16ENij08HqBLkLA8qrZIY3BNWFjn\nEBFcLwegHmukZ9DKvyFVBi1LXTfW68y6Ts+CswLd8jtBLIi/jeL/Oz3Jyr+juJX7UIEyxOuJ+9bX\nzw7f+iDoFe5Tt5nuuZ5e8w+0winFyhbCZgqT+n8rA7pa3vNOCzYVgloQB1b79YSgBwGXdK/Hr2un\nW+0NQp75+8I4hbWCtf6CIiDi4n3RTxqmTYba9YrT8xaX6uWX7fbnymOn5MTvuVumRze+rV7fj+F8\nTyIivwD8AkDWG/OZT/8FAGyumZ/Llgtr/aI2Q/+HaizML1jSyzMAnt7e4/vGb/OR3tsAnE+O6KuK\nQvzCFmLi5umkdAk1fvEapzFO0YTHM5tzp11jagr/Wpuy1wy4XY0AmDY5h2WP49Jv4NmkQHZyere8\n5sevGoavHlFve4NhCoW0S83kuwv/D+Vf7wT+7m//e9ff32o+OrKq1+H5AX/6l34GABN00Bm3nqrZ\nSOd87s6zAOz+rSfAweiGPwCLOxXp2we0b9yI19abYw7/Cf/62/90xZVze1zoHwOwmfn7YdZ6vexV\nA+4sBhzNewC0raKpE+zM39pSapKZkB3575UsQNUnLV84i/2/G38o1t19uCkkUygObXjekZQn3//5\nX/tLj6Vei3SNH37+FwBot3pkr+xA5i3l7CNnufOpFBssyOgNx/DtBqxfG5co5tsJzeDk9avN4Khk\noCpo+/719dkWFEjl90uyVWKM4vyZI/96J8yrjEXpP18pR5JY1vt+n/3AmTf53FvPsPHZIQCDF+/Q\nnhnhtIrfRzXGG0vApYqmn7yr4fzN//Mvf1u9vp9Q/QbwxMrjy+FvJ8Q591nn3A86534wzYfv4+NO\n5SHJfeu12Mgf2pc7lfcl99Ttql6z5C6rdypR3o/H+SXgWRF5Cr/4/xzwZ9/1HQI28x6fNBYxDpsF\n17sLhbqQyoJqhLb1r69MQmUT6uDbm3c7Kt5FNC7+X2NR4YO1WJQ4kvBYiSNRNnpOojx0YIKNqEcK\nM8zRpf/CTgtYh839WdSOcsSseCYfnMKv+9brmWTKz5/5DcCvqxIX1/lau8HM5vzK8fcDkAggd4XM\nIkjwBCRJcOe3OXzWL9i5rSOeWbvDxdx7Ho3TLExKovwFLEJjliGZiPdGbNJhJg4QbAgpjfMhmq6C\nZySCTVy8/7qQTlfhoVkJIwkhZ/Kd3XuPgNyXbp0S7DADYHYhRx9voKbewzt+MqEZOXq3ggeZwOxc\nivEvJ6kcvb0WXXvd1EMBtVxXm3pvs4NEcEJ/c0Z1zUd8plX0hxX7E2+8x8M5edrGaLuzC93znyuf\n4YcvXuOlv3gOgN1fusD4pSkSkt+qbMG5GL478WG6ClGiTe9Pp9+x4XTOtSLyrwN/B9DAf+ec+8a9\n3mczvyHSskUZMCvfV9xJA6paaFr/+sb4DVOFHWDcEosEsHjDtxquK7ERrNI4DEvRYknFxA0OkIoh\nDRsyEUOuW/p5HT5HmDqonLecYhXJoqB/yz+vausNwsL/AKfEG9NuvT4ge+070Wtf4FPZ8lbSojDO\nr0PpjtljwHTHRxsbrSM/cqjGPy/G4tIEycKO05p2q8figo+fPz484onigDyAywfNgERZevjH1gnO\nCRIOOGv9YwIWhg04VvdQAwmo2v9BGYdNJGJvqnHYZInF6UXY5EWAIJqVzf4Bk+9Et078786ODPMn\nB6QTD20tzgvZEQxueT3axO9dExyhckNRD4VsEgyXgWq4xDyTOTSjZajehehmEAzAJGXr3AH7AYIB\n6KfN8oulLbMyQwWMs6oTvnTrSX74go+uv/JnNft/8yxr1/z+1JVBT0pUcGbaQYLNhGTh93vbuz9T\n+L4wTufcrwO/fj/v6Sy7NAYxDiedKxYWcNVwNoJr/PO10dQ2oQl3rUV5oymG+xEVUP5UWgrVUDqv\njNKmKHFkAfBKlEXEkXbgc15jnTALhrxqU6alRtfekOf7DTZVKLMCkIvEEw9zEhd7lOU70uvKAaSB\nA+s9kz0z5u12g3zH32r5sT9gdL1cJ2lN3KAA9VqKWvN6yZQhfQcd1wFcO64KyiahrkMk0mqsEZ9c\nANDO41qry6/AduhCJSciA6d99KCb4JGW0CqJkYZdCLr+4Ojybrkv3Qrx8M8OaxbnC3a/zy9E23Nk\nhxIxTpP7dUk6T177fEW1Ed4/ORmxoQAnuMTfB8lEUVcpw3NTAKb7fVqreHpjH4BJkzNIa/qpN4TH\nVcF8xRnp5Q2N0Xxt7yIAH93Y4Ys/WyC/5pNb66+VuCyJ+9DminqoUMEjdmplr74H+eAEkKdyKqdy\nKo+I/CPPqt8tqx6nat3JrJYjnv5iBGmA1r+gMYrKLD3O+q54ySAxo9vJahhuEBo0aQjYUwyFNDEr\nPw2hexpc3kQshW5PXK9NW5q+P/GqdcWiEYo9/z2KOxVKeewWQKyLGUZYVlk8juKAxi29wsYZdow/\nk+cu53cmT5P6ZDhifbicHAawK1G+BCkNt2KeMzuvGQwngA/Fyw6gxGOc1gm3Sx/6L5qURFmM9utu\njPK4yApm6RTYLISMleAs0VNSDWC/vX585ONoe/7eMhkkpf3WEqbHUMQ49CyUA61lTC9qJs95Pau5\nwiZLCMPkQjMQknnIkq8J2bGLVTL1KJR1BTF5gESSbr97XWeJ33OjrRmtVfQTv9+Gqb9fOiiu0M2J\ncsFMG3b217z+gZc4yx+6fI2/+yMf868/SsmOJO5PLLS5UK/p+FvfNcV+lzx0w9mFZC7VSOuWYVIA\n5bsb2LvNEsFB54TWKebWY2GZGFJpYxjXJYvuNpZdHaENzrXukkG48H6vqFw1zG0Wkw65brErC+mc\nQMaJx7URFtt+CUdvapwIuu2SDkCqltimvHelfNDE4bDYE39rAkh4q1nnjdlGXAebQFI6VBUwSp35\ntQmHjPR7zC4KW4XfKEoclU1iXWgqhqnNY6jeSxvSwrBz7JMKtlUe3uliqWGDKRQmYGh6odBzIQlx\nnk0hXax88WB3u9vobjSoS37IyZ/7WIoT8QcbHj6ZPuFwWdg/hwpTQDPqyrwcdV9ISv9e04NaJK5T\nO3CoWiI+bHIwIwMhVDeFoujVzBY+ln9i65BRWtLT/j5R4k4kBZ8qjtgupnzhraf99+mVDAcldUga\nzaqMnXLED3zsNQC+vvMc278npMcBiisN+UTT5sFu3OdB+NANp3R1Xqn2uELENB26cbRFqLtSgikc\npMED1JZELCrc0bXTsYh9VZpg7N4JFxtIHbPo1ikat/z53ts09JU/4VqtMU5oQx1mLyEW2/r3w5FR\nzM/7z1+cSentnqxjE2OXv899D+y0IApFGfSy06wzrfNofEwmpDO3PEic87V2IatuRz2qM4ZBwLJy\n1ZIqE/U+dxmTtoiexzCrmDcZdcCqsIIkLjZOpKn/f3nokxrJrtC/6b1ICE0WZpm8c/iEUXeAqxak\ncTHpYdOAh32AMOvvVGyuWJz3yZnFlsb0HGoaPLRWMLmLGKhqfda86YeIsg14ZljXduhw4uJ9oNqV\n5B1gz9Zc3dznmzu+3vzJwQGXewfkwbGpXMK0zdlI5wAMdcluM+JHL3vD+Pdfe5Yr2wcclV7PzgmT\nOudj4wMAXv/+XWa3thiF+0Tmht7tmvKMj2accF/OzSnGeSqnciqncp/ycD1O50inoe5RCaan4sme\nzq3HpbrsZeoznyr3rx9kNaO0pB8KwRqXUNqUTJ30LFdD9a5UCXxpknUq/q12Gi02hvBALHkB35K5\nGqqXJsUipDp4MtqS5w3zgY/d5mcT8iODqpbfRy1axD7+nqZCyGWJQ1auwYRba2pyynbZoWGTkLkO\np7sqW1+SpL0nYAY5btjSS7wuRmlJX9URojlsekyaZcF9pgy3yhxru14+36pnpuH7HPXo3Ra2b/v7\nojg0JIulThZnEo+7Jt338221XdmKEx+WJ4ulh+rUB7qW876k7fl1LbcEtEVVXSeO851+vS6kUpjM\nkcyWddmm5yLWbHOLGIlYs02tj49DPeL6+pzNfMb60GPXzw12uJAexDrq/XbIRjLj6ew2ABPb42Y9\n5kfWXgVg79KAo7rHKA/2wWgGaU1P+8jljz/5Df7nK3+YwU7wcFtFOmliHae/H997FPFQDae4lR7u\n0Lsak0GtC8XF/mmTewA5z72r7hehiYbROKF0KTqEwIU0oVYzgNVOnzCiGhvxTQiG1KqYHDKi0Mqe\neA8QQ0SA2iQxROzqBzu72wzB5AodbiyprcfLvgecegcnME7FEgbZqUZUzfI280ZKoKtxLVswy8PG\n5pokNzEpcCE7IlcN+60vdF6YlNKkEfOsraasU1zYgK7WJHsJ/Zv+8eiGIZ0YTICAqjXN4TNJDM1V\n4zHXdHYykdcVyMdkVshlNYnQ5rJs03yc7adAFTDMcsutphx8mK7ApUEPysZEHHj4w5cfLRsRpFS4\n3N8n+VqFNYpm7g+4UVGRiuV8SApuJDPWdBkTg6m0PJ3tMZA6fr0n871oSL9//U2+PrkYMdDWagZJ\nzZnUlzd9uLjJ//TkAv0b/nq6MuDcErJJOKFLd4+w/SF7nL75HsJJ7pZYk64sNlPLLF0PXG4pQpN/\nP6ljoqcTi4qF8EYU34pq2hNY56pRbJymkZa+8jsiFcPMLrM/agVPBajsyaUyVmhbFTpT/E3S9BXp\ntCustt8TOFgn5tvUwLXWZ8FXl89vuIA1lc1JbEmg16/YzDyWtZHMmFuPawIc1z0W7dK7LduEttHY\nJjQ6HCasvQ6DnWDZnPcqu+xu2/PfpVO172CRiGFmE+fvzeCJpJX1XlfEZH0GeSXR/9iKA0zYjy5x\nSC0xQvSRg4uOg+2HapKQnLHiKxlc4feflBpdCXYtOD6tRsQhIYfRT+sTyaDGaQ5NP36XsZ5zqxnz\nbH4LgKvpPueTI261njTomeIWc5vFfarEUaiGK9kuABeTA569cJuqvOCfrww4SOYhAg6dRO+1UeXx\nd4dO5VRO5VQesDz8UH3uXW0zyBALuuxYZyxtT9MOurowB5mNLY+FbshVG3HITAx9qShUx47UnPis\nVXwTIAveahfKK7Fo58hWPNJCrRw3Fubk7Nc+RPzm0Ta3j4eUc++quPokxVY7dNRrQrEXyjOsO9Fy\n+b0kFhv10YXUnYfnlK+fs3nwDGZdiN2E54WqSvn6gfcMjtuc0qQc197jPKoKjFVkAWueljnNLEUW\n3tNJZ4K0jmrkH7c9Dw103T75QehL70LO1HuQ3WOxvvIjspvNW8ToiGnqWmj6fE/otlsL8JCGqpbr\npGrB5OK9Toilel3KwSn/Gpsv18lkDkInYGtTVK+lCHXRShz7dZ/xSm2YwjLvWrwUTGxxYp9PbBH/\nfVZPeK64GXMWM5sz1nOez7yHekY3/NjWq/zt0WX/25zvKOu4JsTcXy7ioSeHaINrnCjS45b02C+c\n04q2r2hDa6pNIClaRpkPpcfpgo10xpb2mMV2csxAaopQrlBzsne9SwZ1UrokliL5x2koaQoF9i7B\nOhUV9ZXpk7xyvB3rA+ta0ysa9MgXqk13hqi5ihiPyRzVWOFC3RvGeRyvq1t9/PcZsMQ6O72kypCn\nLWW6ghmmvlcYINkHjEXCOlUbCfWe5s0bPky70V4AB+1aKLweNRS9Ggp/3yzKFGoVe8+dclRbQkBg\nfBtg6XyrJ5DvtyhjsYFurO1rTCHLer7aodqlvlRrEQfJItxfqQ/rnX38YRixy/IhXcqJelbV+prW\nJbrVlSEFx6QBU+A5PCG0Vzr0xB9oykBz1pEO/X5atCmvHZ3h4tCTuVzKD6lsGssNDSXWKV6s/IG6\n265xLj2K9gBgoGrG2ndaNC5hU085E0L/c7rH0/nt2IDjRKjXEpLAp6tLc7Ll8h529OEaTutwXYeI\ng2TWxvo9lymavlpiTz1LL29ikmAtKRmpMmKSXSKoXkEbVg1l47RPUHSt4vh+Zb1SBzp3OTeaDQBe\nmF3kjfkGbx15zORgbwhW6K17xX7i0tv80Ph6xExfuHiBL759JZJXuMRhchWzkLkWpLWY3uMPhq0W\nwJuwvv2VaodUm0hYqxpo+9AMQsdVt7ECz+PBs5q1iwcc3/QHVv+1hOzYUY39BeZPCE1iIibpiYol\nGk5pBWmJhNNivTHMDtvw2OFEIqdAvt+CSDTkTsmJjLkYh1pUpOFvplCk86VhfZw7wtpCqNfDgbIA\nl4AOBe6qBpWDWyyz6NiT3UFV4vkmwK+XCroBIiF0Gzp9bh8Pfa32yOtlvx3QWhUjltv1yHulIUk4\n0iWN08yCo1PohrGeMVbeYx2phkJctH+paF6pzqEDl2oybxDnMIF0qO3pE2Qw90oOnWKcp3Iqp3Iq\n9ykPF+NcDW8EVG1iaNsWmra3LF9whWFQ1BHLWpiU0qUxlNZiKfAlSbCkmVstOTJOnajTTKWNr6+d\n5qXyAv/XTd/Lev2tM8hCR8wmHZdc2T7g+zf9pIHnilsMVBUzfefyYz585jYvhM6HxSyn7WsWW/7z\niv2UdHeO6kL3x7jlclV0OLJHwVPYTGdoOeO7wAAJoyxMCI1tL0XPfL86wOK85fn1I473vGdhUx8e\nd+U/qvLvG4Rqi3mS07plC6RqQrfPyr2WH1qyrjfeOT+qI/f3gTQGdTxHjzxGVG/1l+FlEHU4JQkV\nErqfYBON+15wOWS5rrrykUJXz6orsPVd5GSyfGzyUHbWYcW1D/VjHWewPFXpQ0zbKEbjOXngh9it\nhihxtB30hmMzm8X9rcRSuyTu50PbP4F/GicUCuqV8PuL+0+t8G9qpLEkbYfhhi/+HiGYh45xSkgC\nqDrBpjqC7DZT2HSJo+ijhN1kjVlY2Bf0OfK0jQWuW8WMK/19nsw97VRHEzdSPpYYqCpSyEEXqicR\n05zYHtfLrTgao7++YOPigsujQwA+PNzhQ/kOYz2P15jYHiZiqUKiLKNeKLhtNO0oZbHtQ9DBTkp6\nx8Vk2PeK4QRfx9lXfh3OZhO0stheIB5OfMF505FmFAkqS6EJmOhUeOGly2x8NSR75s6HdAH7zg4U\ni82UfNu/vpfXlGkvbsRQ/x5DxmTu6N2cxREKNkswWz2OrgY6wCPH+Kt1pBurNhLfchkMtSkStFKo\nI4+lZaMcUxT3TXz7QRRdQRr4NJ32YXdX76or3za7ekBZveQ1bYaBfONopSA+Y1ljLkArmJDUk8SR\nJYajkARU4ih0S2m8YjNlaJzmKNwIxikKaWOJosaS6jbub4ugcGQr++7a/ibnAp1htZWiKrekN1R4\nspfu99yDYu6h96oTOmmkMSgR6tB5YxNBtS72sDoBV2rmTajlcoARdmuvkOsNfMUI7RlviNe2ZlzZ\nOODDox0APta/wXZyfKJ2s+5wT3wnQiKGT571M4wGuuZifsiV3Nd9jdSCxiVMbKcoYaddZ7fx2Ftl\nExKx0SNWyuF6hjbcMOVY008U6tgbXpd8QNlv34MIguoOlI7vNMx2upLtkigLgRzC6cCq3kHdqcIV\nKRI6h0avQXM7YfvLgR2pl2ByHTFRsYpmLYMn/fvXioqD1C4NY+pxtFVD2qwvDV12UFGPMxbboa6z\nL6Tzzfh8uaHQ9Upjhk1IBj3Uof8+yf6MdJTSDLtpbg9wIR8xEeOip+8CS1Q67zw05zPR3e9XHhfs\nWKQQyI5WO64k8AKEdc8dUilc8EClaGiNYr/0kUY/9fy3HcZZmoTdahiHNVonWCdsBNotg4oVNkBk\nOUtXSl/6eY1L/H62iXj2/y7y0fdnCr8XAo5TOZVTOZUHKg+9c0i6ciS819mF6k1fKDeF9mM+JPr0\npbc5W0xZhPmjlUl8e1143BjNtMmoW/8TWqPYW/S5mfqs+KX84MQUTCB4kKEe0PSwTrEZTqytdMbF\n7IC36k0A/uHRk7y4e5bZa/56/ZuKeuxohiF0WWu4eGHZSysCklraQcjar/uZRGrPT2fsfvfjKHfT\nyq3+ezOUi3QRk8kEXboY0plck6QaNfSexsbLJYuzGarynkWzliGtY3ox1GX2YXgdbj3rPf9L60dI\nYmOaux34+rxYdqKEtshoA2tPsZdgEyGQ7KBaOHpquQ2cglqBDliqOMj3M9RheMHhMdmoAJY1hI+1\ndGWac08Bmcy6ukd3gk/Xj8l2mMLrKTvyOu4w0nqt4yhYXles4EJI7FrFokpjpyBkGKsiZwH4ybOE\nIpWm8bwTcVy4GI5NwVh56G0cWM7SMGHCOMvHtm7xzdFm+P6+ljOyNbmupfS9QTD3NJwi8gTwPwDn\n/M/ls865vy4im8CvAFeBa8DPOecO3vVibrUcyWHzJIZE9Zqw+HDFs9ses9zKZ1wp9jiT+BBprOek\n0sZQe6xnzGweQ+m36k3228G3tGWu8m+eaNF0ikSZ2OLV1xXfmF/i8zue32/n5W3GLwpXXg0F9wcV\nL/18j+QwYJiv5tw6PEv/qjeMadp6Mtd+GC63rqg2c9I3utDl0cLEHqReV0N1gAZDEzgEtvSMXtKg\nQmtdtQm92ytJhEKwWYIKc9TTm4dMnjzH3qfGgMc2N16u4watNhxtX+jplVba1NIOwuO5wqw7dFfX\nmQilkjjbphorksVyA7eFN5bhNsBkYApHOunqUhT5Zo7eC4XY0yn6zhFFh13fx7iFhyEPdL/Kstwq\nKS2qdnF2uhjnf3twfCTMbupaqPPGYBOh6Xf1st5w2lDP6xKH0w4JyVVXakymI6+BsYrGKmobIJys\nQuHi40x5uOy4XR5g1inWQr3U2C4opCFdqRc7k015qYNsJn5UcHcQdDOwutv4QfSqt8C/5Zz7soiM\ngH8oIv8P8C8Bf88599dE5K8AfwX4y/e8WnejieBSHU+oaixk/Zo8WbKuK7ExGXOnHbHTrEfGoqO2\nx3qy4GzqDde6nqPExjnp1nkCj44UIJUWLJG4WItlPVlEvr+jts8/uP0URfj8T336VW5+8UPxu7z8\nL/b5d3/iV/lvXvtx/302xkhu6YUTcpRXzPOUvbAjm/WEaqwYdtjmfXYmPAR5sHq9S7pfe07XPD3c\n5UV9FoB6bMkPFGnVNQ4obLHEf9vtNXY/fbIOc3E290w7eMad/CNHfHz7JgDXjreQFQzVBl5IszLK\nyslyw5oerLZ8+RlDjq4tug2f09WF6sr3uuf7vl5XH05wx9NHOYJ4oHqNU2dbzychgaRHXKh5jdiy\nivi1f4HvrqpHS8zTCcve9o79vVOFdoiycWJp1SS0raYfGh0SZeklDW1gwUrEUlnNcUgWxXrP1s8Y\nGqkFMCcNQ/0KbbixGJNNArvZURNmrXekQz4J2RXBv+86TufcTefcl8O/J8ALwCXgTwC/GF72i8Cf\nvNe1TuXRkVO9Pp5yqteHI/eFcYrIVeDTwG8D55xzN8NTt/ChwT0uAITsaccAbyIbkqNtNbPGZ9nr\nPOFzu8/xjdf91Lr+yzmI7zUGmF2G9CPHPLPls+AfXtuhr+oYinfSeZiFtDTSRExyGDoPOpk2OVWb\n8KmtGwB8enidX/qXB7z+qveULj51h986eob1wocClz9yjWFasZZ0Ix4st6tRvN6t44x6lOD63gOW\n2ep8hkdL3q9e32l0RieFCN8/uMav81H/We23MiWZXOMKD17tfqrP4JlDZnMfGptZSrqXLHkdB4Yn\nxocxa1objbNL3oBuhk2HhbXa4XKLBF7X2gQQM85owQe0XeyuHVKriFWnU8GkUI9D2dpogL2zhzue\nhC/0yEUSUd6vXsW6ExM9xbhlCzEOl0gc921T33HVbSnVuhNUbR1NpO1o5nTwNkPddKefbmZQ22ja\nWjOLAarj7HAauSs6+riO5rFxGovEiPPQDPxEB9fVlVV8becil/b8fpXKYItk2TF2F/fAvTrC3rPh\nFJEh8L8Bf9E5dywrrqxzzom880eJyC8AvwBQ6NFyREKmsZmi6XUL74tgu97w1944S3EtI7Sysv6a\nodhrSKbe9X5rbcTVzf1IMfbS8Tk+unaTC5nvdR3pRZhL5Be4EINRFYPQsjmRAutU7F9fTxb8iSe/\nxjO5L2dKxfAXrv597lz2rv9R22duM54f+ntP4yhtGqGDucmo0oTtvjf8e+sD6vUUGwqt9fHsvS71\nQ5UHodfLl3RstQSwbslCaoHn85usB0UemQFtnzi8zTY+XDZDb5gmT8Gz60fcSXxoPM9T5klBMfQb\n5kefuMaH+nd4de5HLBir/Djgpms0CN89MmQ70rWKQW/J42icxA1qjMK0GhPe7xqFUy4W7NdjSBbL\nukS71kcmM1zZ9R4+moUpD2S/ZutkK8TjsDQwYk62pzZ9TwnZXXWxLSzOObKQVNNVqOMM38M6zytA\ngFB0YsnzlkG+1NOiTimrlZ7enW4AACAASURBVGRwncfyv17eMNB1NKAaS2lThgHjLJ3vc5+HU/pt\n26P65hqq9PbBiaAn1dJwJhJ/43uR92Q4RSTFK+F/dM79rfDnHRG54Jy7KSIXgNvv9F7n3GeBzwKs\nF+ddx/TttMLkisYnUz2h7I0cEwpgz7zhqEfQ/mH/Q+/8gGb0fw/Qtd9g5ScW/KlzX+Hl8jwAr8+2\n2GsGfKzvPcaxnpFKG1mRUrFkzsaieCUOJTbOGLqa7cYMMPg563OXs514DHVLTz2jUjAQnWI6otV9\nhlQ2ib31g17NfOCwRWABqpY3xKMiD0qvn/pk5qqVmUrGOXTYILVzXNQVH9nyLDVflC1MvpyOKMZ7\nK20/JAXO1vzQ5nVeSM/H6208MeeJwucx1vUissGD50V1duWGd5zoOcYKqwwribaIlcgYH+3J6v8F\nXEhmNWuKZqpoQ7Ko2SjIpkNUiCQQgeN3WqHvnjyw/dq74NKjwI85Sn2yKHbeKNq+ploLExVGgukJ\nk2fCxIaLE9aSliL1Ht+dr5wjnQhNFxEo/KHW99cfr81ZL0rSFU9ykNVM0hB5WKE2OjpKKnesJQvW\nk2UktzoNVWP9lIiQTP6t2bMMbgimH17jIL19QBFItJ3W/jt1HvU9DsR7Hpfij6q/AbzgnPtPVp76\nNeDPh3//eeBX73WtU3l05FSvj6ec6vXhyHvxOH8U+BeA3xeRr4a//TvAXwP+FxH5eeA68HP3vJJS\nuLwDQbzbX212HRzW410hRDr4KJitmisjH9NtFjP+4J86H6cW/tHLrzKxBU/ldwB4Kr/DSJcxFPel\nCGaFNu7kGaEDZ2QRsu5dvWdXzrSmStYoqUMHTBNGcazS0NVO06jgKeFHFw/CjJMia5j03ZI+rXnk\nPM4Hplfn3ImeYIBm5XEK/Mzm7wPw+f5H6R1LZMEyDZhUUAErk6TlQ/kOG4nX++16DSUuhmCN0yix\nsTWvahKcUREDlSbgl13k3giNZNRZGAurrWceDzFlSKaebAVMlx0xzoj3kEOHSb2eoOp11HyF//X1\ne63QQ5UHt18JIybwI02ckmgxTM+H5l3WvFkTyk1HftYXyJovj6krOLgcsthPz6ivD3x4DtjCovst\n6yPvMW725mR6Oc20CBn0Lls+b1Ksk5VedcdQV1zOfPniWM+YmF7kkqid9v+F/fu5O8+y9kZLcug/\nz2X+h0joCIsxSedpvt9yJOfc51eve5f89L3ef+JaSpYjE1pHta4oz4QyknHLaHPG5XUfmm/mc9bS\nkqd63jCu6wV/+tyXMSth19zmkWZuoGq0WMbKKy6V9oShK52mL20kLl6WJS1p5pRNY9tWE/DPjqqu\nGy3ckQosr1GF66dMdcFx4jf0RrHg1tBQBzq0/BErR3qgeuXd6QtLB5/MPYRy4cO3Ob5xPhbA28zj\nZCYPGGKpeXFxkSfzPQCuFrscmR6/sfcsAPvlgDO9KdcOfSFzlhhkvGC25zeMlKBahRl0BNmC3ktY\n5EV8vXFC2414uCuURxyi3TL8F4/BdqM36kohJqN4xPTZyYPUKyIr438tTT+Js5vaQmj6siQeTz1n\nqrnp9eCerkh3Mja+7l+/P8iQszXMgslJLUobBpl3KDJtSMQsMUzd0IiGzBs6LRbnJD5vnZCqNjpK\nI1UykDrmNA5Nn8Yl0RF69dY2T+3WMUkrBw2uNcjdrdDvMdn38Oeqh4J3mwuziwq74X/42sacZ7fu\n8NzQQy+X8gO29DQuhBaPT3ZsRwrLpfQgPt84fSKjrnGkYiLG0QBXkoaJ8zjmnhlSuuVc9ont0UgS\nr59K+y04hnUqKqIJJ1n3mal4dvquoP5MMSUZNTS90Bs7mbzfpXtkxRE5Mr5FLEvWfYB/9ern+Q+e\n+pOMv97xXxKmRoYXtIq9ZhDrd9f1glv1Gi/e9kngxX6Pt47PYwNHwSeeeguAG5nv8NqrN5BSoufT\nNhr7doHa9QfekfRRqY2G0VnxtZ5dcskJpBZRHbmFw2oXDUSzEJzSmKz3PlbsgyMxYWK9l1mHJJnJ\n/PwmE/oCnAYSB32/Hz/99Bu8vrnFNPDdykKjNmpMqLcV7VDK0diOEV5hZdmbbpSQKhOTt631+GaX\nRZ+0OTeqjaWh1H0OTZ8q4Jy5ahjpBXeMT+7q1wuSySGu8F9YAGZzXHuX4XyPCaJHMyV4KqdyKqfy\nCMvDH50RXOHFmcxjIgPvqp8dTbnYO+JS7rOnT6R7J2jxOw+kwyIzLDVLj9HiG2M776ZGn6CV8y2X\nsBVc+7dV5Vs2fSsJuWowK7jGWHf1nydnGcXv4xQNmjKAdaVNTzDQp2JZG81ZnPWhy8YPfhy+9L/e\n33p9QMQhNHdFhx2k0tF7VUFPH81v8HM//Dv873s/AsD6K8saQABpLJOmoA4u6DfrbfpJw+Io1MMu\nNNmRouyF53fPADAIHSauZ5BDRROmXm6uzzgA3A2vZ33TdyG5bHlviJU48gHtcJbYiYRyuGTpEbcD\nz+JVrX9v+BwdzZpYQ5sL9bArS/JdWHGWlABGGI29p//q/hnqr27QjRBqB4KZJhEW6SCAMrRYFkmC\nEkcSPEy/l5Y6ap3i1mTEdBpo55Tjm4NtXhj66ouLgyNePtxmEmgif+zS64xHc/77mz8IwIV/0KKO\n55hNX+amrIU0OTGaGuAdRuW+ozxUw+kSRXnOG5L5tqJdN6wFPstzvQmX8kMupd5wntUT1lVF1hU6\nO0WDiq763aLEYlbC9VTMXYbMYJyjmx21qaccmj4H1tdDTUzBSJcniI/HehYx0RodSxw6MSuhfvf3\n7vsp8fyCx+f8jffanxnBl76jZXvkxfGtybfV8NwgK0k1zR9b+xpf+EHPCXB0dN6PYQh1yumR4k45\njO+t2oRPbL6NCgXScpCE2kC/7nM9AOUoe34Hi7bUGwZ122+wO4uEpNdie4GzYKbo7aglppqulMfg\nOSWtXYE9A8bZ/Zy2B2KWPdmPtTiHKr1iqrN9yk0VQ3ObeqNpk6733B9AXah9uD9gOOXk/HntoOkq\n4gXT6thiWbYJmTaxF700vrSva3QodEOetswChGIOco7uFBzhOQ1ebS4v2zqBP+ifZ5SUfPN3rgDw\n7Ms7uOk8lsmxKHHGQNpZ/kd4WJvJhOMr/iOrsceS1gpvOC8UR5xLj2It5aYuKVZqdA2Oxi2HsnUG\nq6urbJyiWSEqxoKVZYG7QWiIDSUMpKavqoiRTEzB3GYREyWBQp3MhFvUClFq93kB82FpsMEbcueE\ndttfQ2ePZjLhQYjjpKG0bmko43oFw3po+2gcn9jyPKh/++NjXK3Rx4G4eKK4cbBOLxRCrxUVW9mU\n/sDfJ1UgdYgzf4wgC+WTPADKodcbTBnuj4OEtlKxMLvdakgWGb1QxdiMPE9k1/Ei2gEK29Ftanei\n192m/sOz4/deLP2BFRHK896xuPWZlLbvIjGxKfyaxE4gKzjlSJOQk8iN5wXoiPc3a/JeQ7XfTWP0\nibkuSTevMmzW4FZrbpVlmHkP9mJyxHpawpZ/7tp0k7f2xtR7wQNdaEzmsIHsRSvLF3aeZuOF8FPq\nxienZ/56kmXIxjjyuL4jgfGdb7803xvxxqmcyqmcygOUhxyqB08Tf2KpwrCe+fq8jWTOSJXLrLVT\npCuAg/col6GxQZGtPG8QZjaPz3ddPl25glaWidXR9TeIn80enjeJUNmUeYhFZqpmZDOMLLFVLSZC\nAaXzM5C6bgU/VVNHz3NnsUbdan7kudcAGKUl/+2DW8pHTu6GUFY9TXMX/nm7HXHceE/hqUu7DNKa\nV3e9K1G/skZ7p48KEIfLa95abFAufEilWjh+1vDk87419vqbZ0gPU5qOf1N7hqR8FEaaTBL0XC0Z\n57WjPN+SHQRsbddRr4tvBwRIBZc6XLPynZU70Wpo87uwvcdU6pHm2p/0P3Dz0i4H1zawYdSFzR0m\nd3E8trShZjZ4kGvDBcfPC+52iO0llH51rr/z1QxdPa1xQt3qGOo39mS2O1ctw7yKz18ojtgZrfHa\nlr9v3j5YRwPjofco17MFX/u9D3H1mr8P3LAPwz6EDj5b5J4JKeRcHLzneUPwsA2nIpInOA06MRSB\nqDQNYEg37hOgkSYaOuAEKYd1ihk61lV27+sMFw6KlblDpUvZs0tjW7oUheViwFRLl3KnXYujMaam\noNHTuOm1+KLorgypDoay+06V9Ub0sPGhyJ3FgCwxXO37esS9rrf0MRR315hm4MQBd7fx1CtDuBqj\nmZHFFkgcpAeaec8b1uOk5XfnT2DqcL2R36y3jwMOKt3M73C9kcMmmiQYzmq9IbuRxeSO0wkyrjn+\niH+88VVN77aLhdz1us8PdIXaOD9gzHbD5hpBL1jSpT3Gkowb/tgPfA2A2+WQg9EIMw3YsMaPvQi+\ni9MOaYTJzOvt+Ys7PL91mxdHniTn8HBAW6aR1AMcokDrMKY5MSTaxLpqgHmbxYJ4kwrjdEE/zBTL\nVUOhmgjF9ZKGRCzbhYf67pRDhtdVpMFbXB7hlNB/1RfMu1yHgW0r2aAVNE0epZlDTkMz7lo8oJ+Z\n6KlU1ntwg5WCcl/A3hWs25gA6qRxSUzKNC5hoKqIpaViuJQcMnPeNYgFsZ3H6RQzm/G706cA+PWX\nPs6Vc3v8kXMeFLlRjTmXHrGtj5efRRI9zPqupFDjNFOTM2mWxKqfOXudq4Vnb9qp1h7MIj6C4pND\nS710xtL/W05MGzVOMVILzmS+M+jV5gy10ZQHIWvetwyva8zEH4TZjx9hneU41FkmlcBCU4akHpnF\nZI5id2nIqgER89zYmnJ0uEG+HzZ8ITgnjC94vR7IiI2vJhQHoWC+FWwmtIHoyqnQWtTNTFIKVeo4\nrfFxlr6u4wSGRFm2zkzYP9hcvsDR5ehw4jzz1b7X2+54wKUzh5E39SvmMtM7A9+VRWjMEReP00Qb\n+mkTe9WVOD9XKLxi1ub0dMN6MLzrekElLZM07Lc+J5LBW/mM1/UKCZZx5LuLWABvt0eU2xmqXh6Q\nftZ7OCDvod5TjPNUTuVUTuU+5eHWcYZJkJ1IOFVgiRHGOemIz1AHy28QbMicA8xcxszmcc46+HA9\n8m+qmv9856f5reveo+wXNT9x+RXOpN6VN07xG3eeYfqLlwC4+lbFq3/uLK+MfGi9MCk7zXrsffWj\nO8wJBpbVUB08lf9h7UP1Imn5qfUX4uuf7O2/7+V7VMUhS4iEk7hm522uViOM1IK1wGoj4tjszbmd\ne4/cWSGdOoaHXvG7n+zz41df43NH3sNM3kx9NrfDIK3ydZkBg9QLASPUtb9PenlN/sQUM/MupKqE\n1ghl7fWydm7K4fPrbP2ef38eZuWYQHfYbLYnGZbU4+9pdmKR2AlXmYQr6/vsjv066r3UZ6lXqkWc\ndqjSr9POtU1e0IYPrfuIS8TznErP709nFMISGzdWYayKc9Wzu/g2LcLCpBwpv79S1TJSJZuB06Cy\nCS8enYs5iJ/Y/iafu+jQEx/au6SH6WeoQXj/zUOSwxwbetbR4ltMOxf4Hh1ED9dwSlfuAYjDOYmF\nznPjDWGXrFFY5jan6XrKne87j4YzGM3OMPVVhcZyJ1Dnf6k8w+d/4+OMfG6Gw4/1+P3BRTZyDx7P\n24yyTTj4Wb/w87zlB87cjpjJZjajtGkkm9hvh6RiomFeDUfBG9GFybgz89jblfV9CmkYBQPxtt54\nkCv5SIlzJ0N1WEIYXajeiXHqZL+/NqxlZZxJpN/SiAUVejibWcYoLRkN/AaoTJ9iIgQozXNn9i3l\nmWD49oXkSNOq0GJJn7XhgqOr/v36jQKZJlRdOWEhpOfnHE+9YR6/KCQl6HlHI8cKLkeknVPNu2+s\nx0FW8cZBUkOb8fQTvkbnjTuXgJWZQYnFZUuYUM8Vb14/w62R349mp+dn3ce1tH7kSZCuEF6rJYlH\nP6njqIzaJbRO0YakUWsVTZrEUP6VyTa3p0PODr1jlKsGc6aOGKdTQtvX2NTXfRYv38K+8RauDYWm\nSiNao0J5Uke4/u3koRvO7sQWcb6OKyzMcVtw1PaXnTra45xdAbqK2fYlplnadNlRFMg5btZ+Yfbr\nAT/1k1+l99Mh+SQGJS5+HsBaUjK67DeUEktl02gAUjHkqiELhjJXDQftgFwtr9c4HY3n3GQcNUVM\nzD012KOQhrHyhvNytvdAlvBRFBcqGlZlFdO8O6te2ixiWWWTsDMfYXf9+/OZYLVjds7r4dyFPYa6\nQoUN5RJI5o5AQoXt+cLrjlXLpkJ2JHGOkdGOCb1YBzrdTkh3E5pA7tDii+btBa/XySKj2HVxOiNG\nQNuT/J5A2jW1PcYOaCYtAx0KMbWPws71POfC9csL9Fs92nQlo5JYOgpr6wQ109hJ8PBmQj22HSTq\nPbsVQmmAkuXsICWOTLXx8axJmbVZnHI7MxmN01Rdh9nONvVxzqLyOY1frT9J77UcOfY8sLLZx64l\nmMCP6z56gWJtgHQE48aAc3HqJtbBsnHxW+QU4zyVUzmVU7lPecjsSA61EvZYK5jIjqI5aPsx6126\nNMxN9p7AmlpgVnrT65BR70J7jWNiC54rfBbvqfwOqbSMtQ/NJ7aHxsZQ3GfklwzuShybehox0/12\nyNQUsTMplRbjFG+WPquYq5b1ZBHff9j2mTZ5ZLzu65pNPV/BcB86EdVDk66LalVWy5GMkxPVB6VL\nuRWqDMa9kq1ixhvBk9Olp5qbPun19KHRIVos2wPvGXxzfZP+TSHfD+u67kuEOhegHjv6t4Q0dPZU\nfcHUmoUL44dHFe1ck+2G++iSRQ5yGPv7bPF0jZiM1Q5SSZb3rLOCrnz9J9w7+/pBFovEnEBpUz65\n9ia/Gej9njl/h5f3LyOmq59dmSUEuNzibOBHxU83daN22RnkOOFtgrcHnWOvlUXhYujeOo+Bdvup\nixznrfcwtbboQYN90UNl5bUhT/7eMfbAz+5IxiPqjWVZmskU86vr6DAnTKzz3UNmRa/vyJHv5aHu\nZhFIgmERCT82LIxFaJxmEoYtNU7TV3XsZZ2a4sSAtcZpUjHRMBaq5tD0GSf+ce30CWLTNV2SSsut\nxofyR6Yfw22Auc3oqzoS5o50yU6zxjxURm+kM/q6imMbJm3BwmTLlk7nD4G69UvaVzXnteGOefyd\n+rvLkYATyaLSZRwFMpWDQBmXxybmEJYdBMhlzzG7KJihX9dbszWu9PcZpiFkFE8YMXg7zGkfK5oN\nuyTIHVmqKiU7DIZ1TWO1W+KsGWQXZpiF32Ay09ihgSpANOOS+VXxA+LC5/lZuF2zupAfLAu5H+cC\neOck3u+5tPRVzYdHvvHgt+9cZfzkIYfX/X6Kw9dkmcMAYoE8iUXn5sSCOXt3UnH5XBeidzirdeJ5\nX8NrErFMmzwOd7y6tc84W/Dy33segLO/9go4u+Sn3tlj0LQsrobvK4KqbRw2t/Kj39PaPGTD6Tn4\nOjFmeYIYJ1gnEbNYmJQzvSWH5c1mfMLQNU6TahM91InpBWPqN+SxKZjYIva+p9J6NiTrDfNmMmWk\nypio2G+H3KzXo4e7rmdMTMGt2ntGe82AXLVspN4wbxazE3Pc31hscmsyip0TPzZ4ido5DoMH2x0I\nj6PcnVWHVXYk//duthOpJ509Cgfa3588y3q2oAgQsK4d9Th4kcDhvMeNcszXb17wz1fC8fMNNvF6\n2/qG5eYfdstpidpRnTUk89AZdFuxkCTOEDKVJt1qac8FAt23M5pRiw49zs4q+mfmzJ1PFok5OdNI\nLRR64SjD5AL3GJ+LqRjysJ8qlzA1RaxLvj7Y5CjpMd3293czy04SQCvnazW7ZI92caBoFCtLOxWe\nbAMKusDbi17WxKdtsBEAyiQs2pQ88d/vubXbHDU9Nl8M1RqDHiiFpP4+cWUFt/fINvx9Z3oJ2dvH\nSDcLTCnft94xwOt3V+x7VruIaBH5ioj8H+HxUyLy2yLyioj8iohk97rGqTx6cqrXx1NO9fqPVu7H\n4/w38MPtuxaY/xj4T51zvywi/zXw88B/9a4fpi3PbftyhmFaMU4XvDb1vaZddjr2qjrNxBasa3+C\npGLYbwfRw+xmz7xZ+/dPTMHlbC9mdxuXkIphLc6qSXi9OsuF0GK5pkv22mH0fEqbstcMuFN7zOO5\nwS1u1Wt84aavAz3YH3Ll4h5bhcfanhrs0dc109Z/3uvHW8y+OeZP/fQXAfh4VnG9TdgzYcztXVnn\nR0jet15Xy5FM7Bg6yWLVSSqGQjXcDCFW14PelccuthXtVk16x/9hPsnZGY2ojpadRZsXjzgo/Lqe\n+X3N2jdTjp/3nomba0gd5XagI7utyA4VodgCEkc5yVnb9HqcHqZwlGLGIZub+DK53hkfWSyOCp9J\nD1iergSESK/2bYdUfPfl/e9XMWwmPmLbadZ9TW7Q73PD23y5eYKLm74D643KY/+x3NCJ9zrVXaF7\nnOWkgncqy+c1sZ7JWokZcgCtHNYtyyurJjlRIbM/f5r9G2Oen4U67Y0RqmqQ0IsuzuGMRe/6KFZn\nKXI8jWxJ8cKBm+KB1HGKyGXgZ4H/CPg3wyS9nwL+bHjJLwL/PvdQxHY24S9c+n8BPwxtXVX8nf5H\nAfidw6eobBJDYY1lbnJGqiMBmXHQDmLIO2kLDqQfsbIL2RGNS5i0Hkub24xqhVx4tx3yjeMLXOz5\nHXQ2mzAxBbNg+JRYdhZr7C58iHanHLK7GLB/049kKDZKBmkdDfuNxZhBUkeM8+39NXrPHPGvbH4h\nfL4FkoixdhjfoyQPSq8GFX9nJ926rzYMgO/5L2VJjmKN53AM55XfR61icMPfuJM0o/dkg3RlL5Vi\n/9Y6JAGiuZxw4fMTyi1vSJuxxTXE3vK27xNOAYHB5L6FMmLro5bijYyyH8grnKWRhNHQH9jtQNFM\nM2i75FUoku5yHO9e7vddkQel10RM5HJoXMLcZnH/bSYz1rIyFqrv9BuqWYaE3nPbKH/YBD05K96I\nrsbqq9ixlRNPmUajVBuTx024T7pQfXZjRHKs/EEGJDuOD71URdIOs1agZmUMvd0otOimYUjbosIe\nT3B1uDHuY6Y6vHeP8z8D/hLQ3d5bwKFzrkP43wIu3esiQ6n5aOYV0d1vP95/GfDTDF+cnONi7oe1\nbaQzKptGj3CoS84kk4iVdXhnd+p8Y3qRvWrAztxvIOeEImk50/MnUKIsu4shR6Gz51bupyceh2mJ\nB2WP23trFL0wFz2tSbXhylXvIZ8fnBye3TrFUVNwVPnrDfsV/9qzv8l2OHEtwh0ziHWoX9q/cq/l\n+W7IA9GrdSqySsW/negcWt6UKSZUTHQnvI8yujrMdCoMX0vYeDGwVmU5xWcaJGxANVe4SrBhaNj0\nCeHsb1Wc+12vhxs/qfxd3fFvDiyqUejQ0WILwSXEzqEz54+ZXT9D/nZguVqztENFXfgN1Ssa2jqJ\nQ8ZUHYrzH+2s0APRq8ItpzBkcKsdc9AuyWqu9Pe5sfCOyLn1CdenW7HOldpPHl3FPH0CaemBivgp\novF5WBpWBW2rI+dAklhPvvI170CfecPRDIThzTDH/fUp+uYubr37yXgjupLscYMCF4iM9WSOa1tc\n+84THqLn+W3X5h4iIn8cuO2c+4f3eu23ef8viMjvisjv7u0/vmS+HzR5kHqdHTxyo4+/Z+VB6vXg\ndL9+W3mvc9X/GRH5GaDAYyZ/HRiLSBJOscvAjXd6s3Pus8BnAT72iczt266eT6Fx9EPW7o+sfZ07\n9Yi3St+a+JHBzTDuIngWpqCvluM/N5OZDx3wHuNRU/D2dI2jaS98LmSZiR7puFhECjvwXs5A12RF\n6G3XDRvFgs3QkjlIKmqbkAUoIBXLYdNj3obOhSbnqCqi5/SHLlzjB4pr8fp7xnfT3Gp9qH9cPXJZ\n9Qem14sfG7u7scxVL9PclXq2dz1urYrZ6cHbjvzYUrzpIw/9/FlKk+LagIFXftZNR2dWbxoOv2+T\njS+8CUDxkSssLpno+TgF7dBR3IlNyNRbjnLm8bNeXlM+W9J7wevHFIKrFYt5eL5f0xtUzAMPpa4U\nyQJC1RuPYHnuA9PrRz+RuSLsz7N6EqMn8NDTufQ4siflay1v3dnwc4UI9HtzFVmkbGFxiVt2Dmr3\nLRioKLeEPIM3GqfaKoP98joXvugjkeOrGfmhpbhdLb/7xhpS+T2uauPrMhce6pN+z0/RnATFJRr1\nxEWkG/PsHJgVD9UYePvbL/J7mav+V4G/6n+M/CTwbzvn/pyI/E3gzwC/DPx54FfvdS0BBkERhJrl\nwM3AZ5IStf0F/subPwXAK4uzXA6D28BjkHObnUhCnEmX5UpX+vv80Pg6+yGUOGx67FUDzgZ+vnPZ\nMZVNIkZ53BbcrkaxgHaYVDw12IvPL0wGqo0kB5Om8HVj4fW70wHTWcEPXbkOwJ/a/F0KMXSH9PV2\ng30z5JW5H2vblU08KvIg9epYlpG9k5iVWVFKXDz8wA/dap2OIxl0bendLCNW1fb8oebqsIFaPxOo\nu4RLHcdXFeP/z+tp9IZl/oQjmYUkVeFoR5YmjNLIDgWbatoAqUxmBWe2JuxveqghmQtm6Oe7A8xN\nTm9YkW/4DWjyFLEOFTBP+4hF7A9Sr7AcTaOlZVtPYkv0G80mR2YQcxK5anni7D5v3LkQvoiHXTpL\n2IwEU1jP4Ql+dOIJCgDxY3+6yD2xiIYs95832+tz5SsNNg20kXPH+stTJMxEsv2UZm1I+rY/cJOd\nQ2gNLpQbSa/wBicLDSsf22Dvn53TD0P+5mVGXaa4UMamSuXTa99G3s95+ZeBXxaR/xD4CvA37vUG\nhSNdudGMg27mlRbhR3LDi5svAvBfvPQT/ONPtLFzobIpimUh83FbsJnMYsF64/QJDHQzmTFOF/FE\n3KnXuLUYcbnvOwk2Us921GV/c9X6hFQo+K1sQq7aFb5QTzIwb/z1yjrl6XO7/Pz53wDgop6wpR3X\ngmG90WzwerXNtZnPhTEOBwAAIABJREFUNm733qXx9dGS+9brO9VxRlYbd/I57SyNWnqnzglVm1Cv\n+xth+EZJcrSA0EtebTou9o75asfC4zwDUjSctVBtOaqPPwHA+jdn3P7MgEuf9h1kqTZc29lCzvkN\nVhuFe7OPBA+yzRPMQMie8odw+/IIPVW03Vz1RrFwEqexltuWdKpoQy7srtzXoyz3rdcT2LRYFBKT\ntc9lO9w2o5gcfak5zyc3b3Bt4ImLs1sJ0i49c2mFZqSWROZwAvN0yndodYzw1ghJZmJ3UbqX0Bb2\n/2fvTWMsS7L7vl9E3O1tuWfW3l3V3dXd0zNDzgxnoUhaoLhYtCWBpGnTpmxCNmTziwlIkA2b8hcL\nEAzIsOXlg22BhgVQtgDLNimLFCQKtEgORYIaztYzPb13V9e+5J7v5XvvbhHhDxE37svq6q6q6eqa\n7Ow8QKHyvnff3eLGibP8z/9QZ+6a5t8co27vYDM33+wgdQrFK0a7sYXNi1B7rrrOE73zIw6Fs/Jv\nX+PfOvmdsDBoX4BTeQPAIPgv3+fZPJTitNb+PvD7/u9LwBcf5vfHcjjleFyPphyP64cnj7fLJYLd\nGZduthtiqgt6QvIXei7L/gdrz/Kt7TOc6zt3/VQ2JJPVu3CCjesgsQcqh7oSRiIL1PwayTSJg5u4\nV3eoTcuuMibFWEHk4RVz0fSAi5nKmkiYQH+1NBjzN5/6h7wQu/1TkfJWVbChXVZvT3fZrnrMxW6F\n/lMLl/i/H+GzPMxirAghlam+q9+81FC342eNW92jqXfla0N+dg7ha4brUyWryYjevIMHlWlCNBYh\nJmpTqOc0d77gXO3TX66xieHnznwTgP/98hcdJnDTmYidlQnRhRH5VTdOZhIx7qTBZdt7Ikdez1AT\nz/LjW4GHdsILNdUgaVE0R5wJPjBbWena2HgLU2E5Ge0FXPVmNWCn7vLsU87Sv3z7HKpwlWDgQixW\nigDf0kJgE2ZwsNbFsf18bWgGy9xZkEkhyJckTaRPlhrb6xzImqu8DiEelMKUFRhfETbaZ+fHnuTJ\nf+8tAP7M8hsM1DSwrj2sPHbFOfKucNPKt21+FrlkkQfc/c0z/5jfnTzDl3efBeCl3dOc6e7xZMfV\n5ilhiEUdFOHAu+xte17LiXgYYp4GwZlst+0RVMfBjQdCLDOaoe6fU5MDsbtRnVL72vn/6OLv80Ks\n6UsPZ9ITtk3Gru6Fe9UziliKo5uhtJYDYGQg8KzWRlHN8CimqiYSmrqh70trKq2oO24CbH+iRzUQ\nRBO3nXT3UcLQ922kN2MOxMasdEmGqtckGRzN3LxyAHfdBCEbtIsVrux3JmQ025JW3CdmKaQ95Eik\nRyfaSrZ0M38ksahZ9c819j24FqTzxb/Ue5s/3H+W854I/M0n1uhsZFiPj9QZIIPeRVaulNU2fdmt\ngytJ3244ijTlNA5wpuJsSTUfMfemX3Ajie2myH23oMq8xnQihDdshFTIJMY09IMXz7H3F/b56YWr\nbn9hKGcye+ohFehjVZyljXi7dDGQ3CYBpA6O73I1GnE+drjJpajm3+hf4gcyl3z5nfEL/PbtT3J1\n32Xdn5u/EzgzwdVCD1TbJVMjyUTJwFcelZ4NqZFep2C77rdAbAQSy/4MHjEWmljpcLxSR6SepKSJ\n9TQihSATdbB4FZZYGKb++yZ2+nGXpoa9acIlhCdwaIZGOAuviWEa48ZF3UVD9C5WomAYCahFy+Mq\nDipDa10NdFB+7zrOvS3IoFyF9cr5AW72Iy6ljbhcrQJwo1xkr+6w6IOWn+pcZzVqsc0SwxPpFrdy\nhyJ5+uwGl2+dDf3nrQAMVCveZKwEaqxa5mMDtm+Qfr6VeQzDmMhb/vVyhRXQv+m+F7VBlHXIigut\n0VmGbZJH5QIyiZHa7X/1x+d5cvkqVzy72ZOZY5FXMy/Awxg3R5ii4FiO5ViO5cORx2pxTnTKSxOX\n/bw729qVJQtqEj6bWIHCcNqb8r8w9y2+0HmHv3P7RwF4ace1wWjagZ5O9yhMG8NsrMsm656JEmgt\n3F1PK9dcwsQkxLImnaGZM03fI5wpn0VVKNW7Uq6gu3fC9ce4nu2NpdNYw8pzKdxdWfNxEiUs7wXG\nktK4OHKTxRbigEXXtA1uYGL3dJMtreutXMZ9FvI0a0VaK1zmVjS8i46hx76f/32gTJDA5HPURVvJ\ngnfNb7DIpf2VgEe+szjHZ/pXeSJ2rnksapbVfgh5zSdTOs/vUn3DeYj965Z8WbB00sGFxtOUKu+h\nSu/KC9cpU1du/tn9iGxLYfz8n3s5YfWbOfGO8+GsdD2L0K0FGk0qTOrREks9IikpTrhKwv1nKkqj\n2CldrPt0use8DzPAu7HF9xNhH5B/7lGIEGIEvP7YTvjesgJsfg/O+6S1dvV7cN4PVYQQG8CY780z\nnZXjcX2Ecjyu7z2uj1txfs1a+/nHdsJDfh1HSQ7DMz0M13DU5DA808NwDXfLcYzzWI7lWI7lIeVY\ncR7LsRzLsTykPG7F+auP+XzvJYflOo6SHIZnehiu4ajJYXimh+EaDshjjXEey7Ecy7EcBTl21Y/l\nWI7lWB5SHpviFEL8lBDidd8s6lce0znPCSF+TwjxihDiZSHEX/Gf/w0hxA0hxIv+37/+OK7nKMrx\nuB5N+V6Mqz/vR2JsH4urLoRQwBvAT+Jo+78K/IK19pUP+byngFPW2m8IIQbA14GfAX4e2LfW/rcf\n5vmPuhyP69GU79W4+nN/JMb2cVmcXwTestZestaWODLVn/6wT2qtvWWt/Yb/e4Tr+nffXivH8sBy\nPK5HU74n4wofnbH9QIrzIcz5M8C1me0Hahb1KEUIcR74LPAV/9EvCyG+LYT4u0KIxcd5LYddjsf1\n6MoDju33fFzhcI/td604vTn/PwH/GvAC8AtCiBce1YU9ShFC9IFfB/6qtXaIa4v6NPAZ4Bbwt7+H\nl3eo5Hhcj64cj+2jkw9icT6MOX8DODez/Z7Noh61CCFi3AD8fWvtbwBYa+9Ya7W11gD/K8fM2LNy\nPK5HVx50bL9n4wofjbH9rpNDQoh/E/gpa+1/6Ld/EfiStfaX77FvBLyh5joX0jXH15coTT8qmG1D\nr60MxMHaCtfLxrPjaCvRWoTuWDIyxEpT1m5/W0rf/c0zVCuLkoaoYSuSBiXa7YaHb5aDT2LD9Qj/\nXcOZI7AYBFPPq3lnOofak0Rjz/tjLLoXUzkyFjrdgtV4REe0vEAvvVRvHnYyiO9mXKO57EJ2wo2r\nQYAldBTtKccka2l4OA0aGZ6rxCCFJfH8SZnQSCFm9nCNvCpP3BghqLGUns3I4piNZt9ijQrsWNKP\n22yTP2NF6KdjrUAJE5jMCxNR1JEjO6ZlZWqv5d3zZfTG+qEfV3jwsW3GNZbZhU4013x4kNhUzPBs\nMkNANdvHXIr3ojd91753Hw/PkmXvZpZ+QBJpYe86Pvc41n1kf3TjPcf1Q6eVE0L8EvBLgO734D/9\nhz8AwNlki54s2dWO5mlPd7laLHE7dwN1ezzHME8pPKNzVUYYI1GRU3xnl3eJpeb1y66rntyLMIOa\nzoKjkZvvTQ+0+11KxsxFOUuRo8nqyoJYaHrSMYtLYchEFVpxZLLy262iza1iZByt1u/tf4K/90c/\nzNnfcYMxeGOXarHD1T/rmkL1vn+b/+Dpf8mf7btE5EBYzp67feVRP9/vlcyOq8oSPvs//yIAlZHk\nVcRzS46Q+k8tXHKfe8XVlQUTk4aWDPNqSk8WnIxcE73n4j0GUtH1dHwSgRKSTe3GbV5m7JmcK75N\nc2UVuY3bFg/A2KTcrFwILJMVpY24UbrtrbLPVMdhgc6163w671uc7FUZr22uhaMNsoKoob6DQCs4\nK3/wE3/7aI6riPmh0/+u+0IpbKRCEz0bSZDygDISWiMqT+cnJTZW71JeB85Vt+147z6ejSUmUZjE\nn69plaIOKu8Dinu2jUbpGOpFbcK+JnlvB/terIJf/p2//p7j+kFc9Qcy5621v2qt/by19mJv8ZgF\n/SMgDz2u0XznsV3csXwgue/Yzo5rorqP9eI+SvJBLM6vAheFEBdwD//fAf7i+/1gNZrwHy+9CMCm\n1rxZLbOlnW870hnr+YBLu65956RIqCqFrt2KoyJNHNXM9xyR6XI2Zn0ygKa/dWaQmSaOWtf8bjdL\nCdO6bMhgXYKzKBOhAxFxgibBEHsXMfGunPYW6hd7b/Pq953kO7eeAyDd6RHvTMm23MuWlzG3ynl2\nvWs/UMUDPdRDIA89rkBo6ypw7m89QwwrhUHbe79qjSXX9J4ygEJgQk8FSW0rKm9NbGo3/rEfj8oq\nurIgt60FmomKpWjfH9+3f/Yhk1RWGFpXvTSK/aolmQ7toEt3vWlcY2c+/4jLw4+t8XNI3mU5Gnwb\nkbtd6bv6lLyPWCEQzT6Gd5lxd7v5wr4/f7SwreXYEGLbtG2XY6KD1qow7320+w33d604rbW1EOKX\ngX8GKODvWmtffr/f5FbwaukUiUZQWsW+dq7vm+M1Lu0ts7PnmkPV+zFElsT3s1bKEEWaXlKG4w3z\ntB3Q2BDFmki1zdbMzAQ2VlIZhRbttrsO36MEjUaEmGcstGd0b7ZBYxhQ+esZ8tOrL/LyZ04CMLoy\nx9LOlHjfXU8F7Os0uPZ8RBTndzOu7ncHY46ZZwKXwhxg185tzEhngaF9REZXFlQo/71AY8E2TP4V\nuTVMZt5xSRujHsjS9SSiee6Koc3CvrHQ5DYOMcxIGtf7xjePa96TUrf9tJWw1H7BLqqIWOkDi/Dd\nC/JHRb7bsZ05wLuUYaP47N0x0Ga/5rP7KFFhrSPyb/azroFbUG6i6YLadgIwsWhdd2Nd1wC/n4lB\naPuern0TP/1uh/IDxTittf8E+CcPur+xgrF1inNL99mo59j02ZT9KmV7r4e46tw+FVvk6Smxb7+r\npGGQFXR80mGv6DAtkrBKqcQpViWbJmBuQuQ+FjaUKZHUrj0tkFnlGrU1v8fQTjcOxMzA7ZbNtFzA\n1Dwdr/OT5x2h/W8/8wXmLqVEedO1T4Q2Ah81edhxBRfbBNBGksY1J9IR4BTXnklC65BMVgfaWjQK\nb6TduG/IDjET4mY+4JRp5ZWvszTf/bZnM8fMZMUcLma5q7uMTRo8jVhoKqMoveKcVZgAhU82NjOs\nqhXGiqAspbDBum62P0ry3Yyt/+GBTafo7mGWzSpKex+LNBIY4S1Cedf31rqGbL75GgZ0Ime6ZspW\nyQLUgpmGtKHZXxgeYwGLkAev513JrfexQmflmOTjWI7lWI7lIeWxNmuriLhdLwCwUQ94aXSW62O3\nfWVrEd7phuZN9emCTlaFFb2fFfSTgsr3Nd+cdCmLCNHARqRBqTbjaa3AWkHuLQpZpShhg7UTC40U\nBulXLYmhmmkhnImKysrQxjYWhhho7JpMGJAFn+tdBuC3LnyafC0NWUGlDPNqGiyqmdZhR06sbWFj\nZa1Y7E7p+9CEsQJjZWiPrIQhlRVVAzvzrnETIhmZDnewDKQLycTCoK0I41BZycRKSr/mJx7OlNvG\n1Y8P/N+Eg0Z61p9oxSDQVjKt3fEqraiNxGhvgeYxZVqS+Ni5seJAq+IjEvt8b5F3ud8h5sm7LUoh\nwvsvvMUYQttCHLRatUUYg2hc606MiVULN7JgE4n2FqdVwlmbwUK0B2Ok4q6MO/eOkaLvhpf50wV8\n3F2wqPeQx6o4CxPxRu5igreLOV7bXePWWw4m1b2mqAaW4inflbLrJk4/cxNwMXNJgc2Ji4FO8hSr\nBSLyuM3IEM0khGojEUK5mBZQW8VUx0y1m8CprN0E9hNOEZGbOPRFj60O2EEAZZ2b3pjozpU0PBFv\nA3BydY/p0omwfzctWYlH4XjVR8ujeyixQKV9/2sjiYQJinJkMiYmYaqdIstkRUpFJl0YY2IStBUu\nDIJTpGObhH7b0if0shk8bGVVCKVUKJS1YVthyG1M6cd1ZDpUVgX4UW2UV+YiXK+xgknlrk8bSVWp\ngBc2WoRFGHxfePMxdNQaBaW8IrvbBZdAZSDEHEFMckThcby1BmtA3wXnkg0uO0Iai/BwJzoZNkuI\nEr/AdmJ0NwoJHlmAVe7frLQxUefaNzHR5vNZBWkFwfVvfnPPv+8hj1VxjuqML9+5CMCdvQH1pT6D\nW01MA8pFiBI3QfqdAiVNUJiZqtjKe4wLNyHryq1ODa5TSnOgxaubzO1TrY2k1CpM4Dk/AE3iokKh\nkeSmhUwpLFrOxFiEpucVcatA3fWe6e/x2txJPN6b+bQIrVUB8odsP/pRk6aNr9aSQkeMamfhxUIz\nrLOwYPVVQSHaNs6prOjJsk2iAcjWYgSPofXPWeGUZGVbi1VbGZI/gI9pevxvWBjd9yURhYmofYyz\nUaB2JqZZ1wqrG9PGKVNjm37FEu6B5TyyMqsgpQwKVGiNRdGscKLGtWb2uEmxvYcZTzBj34LXaJCq\njTEKiVAOu9mI1fpAjFEoCbF7D6IkJh700SsO513Np+hMhgUOnBJtXgNRW2wsAv5TSIGRM1avcN9Z\neR8N+R5ytGfzsRzLsRzLhyCP1eIsJzHXv+UqfeKxoLvbZr905qxE4xvSx0pzYW47xL7WpwPGZUJR\neEujVKhEE3lXXUqLtiK4jOAy63Im2ysjSyQPRhsbF08iGZs0LCXaiBCfBDBC0pUFynp4FPZA5n0+\nzql70Bisi+kkVCV9HCS4vrViUsXs103ljw1WPjjXXAobShq1ldyu54NlWNqIBVpLXWHJZElpXFa+\nshHKV3k13yuhg2s+MSlD0yERTQlnRSHa8+u7glfdqGSn6IZMubYCrECoBh1xMI6pjTyQVT/SInj/\nrPjstnRZdLHr0BRmdw+rDSL2KsaoA/FSIQTEcYhxOuiR4V2OmXbz1eYGmxfIbVdhli0vUp1epFxw\nYyt8JMB4OIbwOM5mihrVxF7d9rvO85CG52NVnLKGzroIf0cTG0xr3RHojiXy8KNEaXpRcQADOCkS\ntFes1kKSVmSJm0CxMpS1ovbuuTGSSLUxzwZu0gCn7wUjMbataXa/MWFCAkhrmJgG12nQiAMuZd2x\n+EpB5uOcBTkJSY6jLYLaL1i6VuRVdBeoXAY8bapqjCzZ9/CkVNbs1D26/jkVJsZIGRZMJcwBV7yJ\nFTfPfagzMlkdWKSMFZQ0rrwM4PpGpDAkyinWBo4UyxbnaQ0tPriUlGVEFrv9tREIMeNeHuXk0Cxu\n07vUNmpDV9CWNIrxFGqNHbeLnshS8PPF1u75iaBoJWiNNSZsz/JmhP2UCtumKMJ1mJu3iUb7qDNr\nABSrXXSq2tirajSkV5jSMoNYcxhPeRcIfrZ0/j5r42NVnKqA+Xd8TLKyqMKSL3pL4YTAdjQLAxfT\nPNEdsVX0KH1Q31pBXUvMxF9ybDFGvktRRn5CBIU582JLYYMCrazCWIkKsTNHPlE2sTMr6ckCE6IZ\n7rqbbG5pJcZKRsbhD0d1iklsCFb3IlcL3+APc+6KYh8hsbaNcVoLZRmxV7rnIoUlkoZ6JqFSmOjA\nAtUk6sBZiLHQZDMLjrYyWP+xqKlsdMDaN/ZgbLqyUZgE2hN86JmolBKWyCviiZVoH/+GNi5uK79/\nKdH6oKLU5ggrywMyc5/GgGljmDaSWKUQIxfDtLt72Ko+oGiFaClRhBBBCYJTpEII5IIjhyFLMVs7\nUFXh90CwOI3W7hhe0QqlsEWJuHLT/bw6wfSJefx6fEBJugNwQEmGDH0T8nxIJ+I4xnksx3Isx/KQ\n8nhd9crQ2WgtiaofMV11urtYNfRXx5yfd/AeYwWjMmMnd5bL7rDrzO2siXkoyjyimDiXzU69lZG6\nFam/OGFtsH/AJc91HOJtPVU4qrqZGKexksJbiFIYYlvTxbMned+kLdUUaGRgd8rr2Fmc/vyL8YTc\nxuH7OZk/mod4CGXWXZXSomvFqHBLfyw1maqDa6zvCocUJqKryvBcB9GUWNTBvZ7NljeiEYFTQEnr\nsaBuv7FJqKwKrv5EpxQmCln1WBiQdSi5BBdPz33FkDEzMTtAaIGpJW3l38ckvgkOG+nhQcLYlvEI\nsEmEqLRz0QE9zVv32ouZ5iGuKaLIWYneghRJ4rLmjRV6V0jA7SSCxel2sQG3KaII4ghbOgtVXL9N\nFknyU64S0SQSK9ssOx561MKRvNVpw8Hdfw9IPfdYFScWROUVUKrIFxTTVXfByZkxn167FZI320WP\nYZmyO3KK01rBoDvl6TNbgCvRvD0aBOD1NI2p9hOidacYzZsLXO/NY592rsS51R1qIxn7pMUgipiY\nJEy4plQzlOYBxrFFHriFRtE66FKrGGsrsX1NNnCKtq9yNuq5A4D6oyyB5EMajJGBDnASJVgrwriO\nqoxS1aEcVQpLbmLmlZuAxkomNg2x5QU1wSDfE85VWUVpFROcotZW0ld5wJEWNkIjA4/qsMrYLTvc\n2R+47XHm4uWJu766Vm4haFx1P7GakNDdJZdHWmbca5s4pWlSrzKkAFRQdCJJEFkLKbOjEUJJROKe\nu7XWKc1A6mGwWmOrPbetNXYG4ylUUwvtFbeLB80kowRULbbXliXi2h0y//30dB+iFo6EFe/2xy0h\nGmERByIT90MPPnbFKb3i1FlEsSipnnCW2I+cvUI/Krk9dS/0+rjP9l4vWIxxUmOM5PVNFwxe7E4R\nwjIaOsUaxRrV0dSedtRGEdmmRH7NAeavL3bh4pjzK86ijYRLHN3LommktJHLtIMLahhCEqKxYBrF\nmMiatF/QSZ1FPdEpu7obcJ53K+AjJcK2lprPSodKIq1QM3yWBkFlFIPIjftKvB+quIDAltU854l/\n/o0izWRFIvSBhI8S1qVU8YB5k7JXuwXt+nSRO/nggKIshynxpnv1sw1BNLHUXY8KOGuwC+2EbOJg\nVcPSpQyZeu935shJA3hPIkyisGom3hsLVGORRhFIERQlRYEpCmTPjYNIYszmdrA45bnTmMU+cugW\nTLE/gTTBdJ3ylaMxdm8IkVdRde1iqPLgPApZ+TjGFgXitjOssliRr3VotGEg/JipTII2C/8uuc/a\neIRn87Ecy7Ecy4cjj9fixILPytU9xe6nav7cC47VKpUV74yXuTZ0TN17ow5Wi5CNrfZSpjOm9Xi0\nANIST90Hg3egmhP4ghXqnqVYsjTJ2WRXUL7V4x2/kkwX40ApBlApRSx1qIlGOmuyxRcqBtKEiheF\npRIRAx+7nE9yrBWhlQc4yExjcd7NtnSkZKYksf3ffVXWCiEspcfzdaOK2kpuTl02dVRnRMIEuFKh\nI1JVMx87S6QrSzQyvAfnsm0KEwf4Uixq9nSX7dp5FrtVh8ujZTbGbnvn1hzJekQ0cdeV1JCVEOC8\nxv2dbftS3a5k2hMQ+5hXbWESMc29xTmoSKIZF/Eow5FmxAb+ypmsuhSYefecxSTHTqbYkeNBRQjU\n6grDL5wFoM4EC68OUN4i3Pv+NTa/TyGM8wSSvYPlk/FokXhiybY8m9ntCWp3H7vvK5HqmlmgitAa\nqxR24t4bdXuHaJBQ9ZrQAthoplLIurjt3ZychzLGWQ0UN37cTZjJacNPf+Fr4bvXRydYH/cZ576W\n3BN8jMdeE44l2bpE+nd24e2a3jsj9j7hjpfu1HS+dgnWHBFycWqO4fmE8WmvGAduYKpdd7x16XoS\nyRlcZ2x1UIyN0ryhnSLf1ylS2DBh+6ogkxV7ng7tznRAlUekqQdmC8O+zhhIXzJ6xGOcdqa2W0gO\nKNJJkYSQy63RgJ0ri2S3PKF0Zqn7Fln4WvNCoHKo+27/8nSJSjW9rnPdLyxuE0nNhZ6bgJVVrOcD\nXt10PAG76wPUnqJ7yynak7cM6U4dCCDKgWS6Ipmc8jHtvkVWkOz5pGAFaqQwq77GWkpELbAeF6iH\nCVW3CBwIR10CbhP8ajgDYrcgCj8hqxJblgFeVD9zmus/3KX8AadI53o5b+z2MKMn3f6RYfHELs8u\nuxYrHVVReR4BgFuTOa7cWiZ9y83XhTcHDK7GRJse8D7cx5ZlKNG01rq4aLNdVUT7VVCcOpGOdq4h\nITHuXmZr2w8kj+4jj1VxZgs5n/7ZVwGnqK6OFxlV7sEUdYQ2IsQIs7h21T5+wk3P1Yx7HaI9j7cb\nRExWFkhG7vvh+RhZXUD6APPkZMzgagme/7PuCcqBQKfeshmmrKs+i74n0Yl0RCrrkHUf1h22ii7X\nR469aTRxSYSFvlOEn1y6zfP9W+zVTnFe2V7ETiPiJad4cxNTCRXILI6y4nQ46ba229QCmzQVHBZr\nBRu7vovdpR7Lb7aEtCYCG4mAu1OFIcrbwojRuZR8GYYn3Di+VkYs9KehR9BYJ1wfLTAtfCGCFiS7\nkmjsWa/8vG6smXIgKJacwp79vhr4WPpIIIxARjOsVv0aJu4A0b5Cr0piT5h9pC1OIbBNciiWnhhD\nhO+ENi42CTAYMP4zz7P1gieA/sSUn3j2m/zs0jcAuBhvcUJF5J6g+pWqx67usqDc73MTc7NeZKN2\nFujFfsZXVM0bu85iLdYl8UpCnHpDyVrE0GKLFqVjdcu2RFkhd8fEfc+SNR9xMPvDQT7P5pZt+/37\nyXGM81iO5ViO5SHlsVqckzzlj19+xm0oy2B5zKmBZwpXmrnsIJ+msSL0EJLSsPjkhOHEWaiT3Q7F\nBYP1PIpqO2bn01FYVOJdwbKO6d1xJsV0OcIogSxbl7KuW9q5J9JtKqt4OT8NwOu7a6zvDKiGPkuo\nBaJXE825krKBt3ga136hNyWfJPR8Caixgq6sjzR+sxEhHAwJQCAxlQxZ9tq4Rr/VyGXHB5uCugu5\nRz+YyKKmgmToj6Wh6rX4OqEdFk8UPtZdRJSZ4sbEWR6VUUzKOPSmQlhUDrE3hGRtQbaVJMm+RV0h\nsFjpRFB3oFjwrvyCpZ6vQwmmFhZbSpIdd/y6a9FaHohlH1WxgpYmTgqskgfa96pxG+sdfe4013/S\ncvqp2wD80Nomvv2XAAAgAElEQVQ7/Ojcq3wqcSGVJZnQlQnSuAf/fDxmV4256S3M2/U87xSrAS0x\nrDMqo7De8s9XBVU/orveBDYXSK/ZUGnUuOlNaSdaIyc5svADbyOkBjsDSbJCIGf5OWdLPu8Tibnv\n6AshzgF/DziBe51/1Vr7PwohloB/AJwHLgM/b63ded9jlYLOFWc6131LvKaDy5OK2tWKe7xc09qg\nqYEWwpIqzcWVTQC2+13u7A4w/nv5REkaaVYHTrHtTDpsmQUW3vAlm9K7a42nkRqW5sZ8cnALgBey\n61yrlrk6djHNW6+uMfeWpLvuXTIlyBdStlccn+hvnlwlXp1yYmEU7q8/yOknbc10VxUBOH/Y5FGO\nq7VgffJGAFgRxiWNNMaC8K5u1YfRMzXpyjTsbwU0T21vJyNZj4j3GxiJoyyLxj5WnUXYOREmWIOr\nbBR1shkRjy0Nvl34idEQ6vZuuonbtIotFiKyHYP2+MTpGYPs1cgGcqQschSFtgymYzBGhJ5Eh00e\n5bjOurZWOCLhA2TBxoR2wZNVBZ0yzN9hnXGjWmJBuhXMRBO6tmLkY4ojG7Ghe7xWOEPlRrHIRjlg\nI/cAdgR5HaHmnWKcZga5GxFN/AI6UESLPaKJM0zsZHqQ7s9abFkhp75G3qQH5785cHv+PXnwsMuD\nLJs18J9Ya78hhBgAXxdC/A7w7wP/3Fr7t4QQvwL8CvCfv9+BZlv2YF0cs2nqFUlDXscUtLXp2sgD\nPYSEsHQj9+JfXF0nXtNsVS6rd2s6z8akx86k0xye8kTN0PcciqagU2fhAMjYcKa/xyc6rjvqqhoz\nNil7ubNouzcl85cqupfcu1Wt9pmudOlfd79f+6Zh81N9rj3rLFIRG2RkyJbc/WgksdCHGb/56MZ1\npgCj0ymZGIEu3QTqpwXWCnYa9qGuBWXRl90ESXYE8RiSPff9QmlRpaHuNMkcgUwFosGBxhHjuZRP\nrjrL5uneBi/tnWa078a96luGz0C24Z57lEumq5Lc5QxZ+wYgYPcp/54pyDYFpS+Zpl+TZpXjewWo\nXXIozKm7uz0ePnlk49okTIJIDuAgRaVDsqVYEFAodocOt/lGssZUx9zoOkPk2ew2J6NddrWbrxv1\ngJHJ2PHzd6MccGs6x7jyrFrCuk613rDSZUw0FsS+a58qrNMlDfFxFIE1gYDF1jVYgyyqcL2zxMUm\nAlXOWJ9KOGLkB8yq33dWW2tvWWu/4f8eAa8CZ4CfBn7N7/ZrwM880BmP5VDI8bgeTTke18cjDxWo\nEUKcBz4LfAU4Ya295b+6jXMN7vWbXwJ+CSCaX8T45KdVkEU1g7ipBbeBoaaRWGlyX7oncRboxJdM\nFiZiJd3nfOZcd9MXbNYDbhYuC355f4nLtWLq+65H+8q1FO04cz5LahaT6QE6smW1z+fXrgHwT1+Y\no+6mpBddpVLVg8mTNdkt3297KIkmQOnXnlxh+hX9uD1eTxYMPbP5YXXZ4RGM68o8xsea82nC2vKQ\nOxvOhHNeg4EFt/LXMkaNFHNvueN0tjSqsHSvuiCn7qfU3YhizlsepYOOlD4GaZWlLiJSnw6/kG4w\n6Se8GrkQSh1ZdGYY952lUixFLvblcZl7FyJkBZUjEsfElnwF6kWPfuiVRJFuGZHuUaZnjcTcLwh2\nCOSDjmuWzB/sOTTDMGSVQEwLzJyzME0Com5bkpRacWcyF/ozaStRHdNm0VXMyGQBNbMQT4ilZrvs\nht9v5z2qbTd/+pcj1BRU6eGDpUGUNTRZdWtceaaYDRlZbFMSai3CtGWXVgrM3RbmQwAkHlhxCiH6\nwK8Df9VaO5wt6LfWWvEeBbzW2l8FfhUgPXvO1h3/IDuG5WxMz0fpDcL1DPJOX1OmF2rIa0UuIvZK\n9yBvyvkDBB7zasKpeJfFyMU4e6pgUiVcm/qYqsfhya6bcN2soKPKth+3lVQ24hNd9269+cQqV7uL\nqK6LoXx29RZPdzdC069v/OlzbO3MI/3xzTgmydoa7K4skRiulCsATKI2FnqY5FGMa/b0Gdu0MJDv\ndNjA9YACNwEGUc2pNUdAu93pUd7okQ79eGjLzT+tmHvbuXRzlyt2n0nY/QH3XiQ3YlQpKJZ9rDkx\nSGUCbKy0EX1VMPDjlCcZaAGpd/HWSkcR5+9i/zzIXITgfz1vYFCRpL7XVOxKe0OeQAuQtu3QoA69\nqw48mnGd65+xs4pFzPYLsgIbKUzWWELuvyRpW8mspfss+CzdhXSD8/EmJzwnQR7tsKqGbPsS2y3d\nZ19nLMVu/t7IF7iyt0i66UM+1w2ydnA1dzFg0qh1mZVyNHaVN1yEBCEw3ZYv1/VSb67f4zZnQfSG\nNkF0H5f9gRSnECLGDcLft9b+hv/4jhDilLX2lhDiFLB+3wNFlnrZB2tTzSByygsIzbRUk521lqKO\nQvIIYFrGQVnuiC6ZqkNWWwpDJupQ6VOYCCEssZ8QlXDMPbEf2E5cB6sFXFOxocmY932CfmjlEoP4\ndMCZaivoq5xn0jsArMQjXumdDozi+1XKW9srgeUnFpqR6fDavmO8L2YH8JDIoxpXa13M2G2AeqdD\nedItIEUvYiGbcqLrFo75NOeNMmLrU+65qmmEiQw7n3LjOj6dUHctatu9D+WKRg6qlrm7lvQGeeBV\n3awGjsg4ce/RTs+dN828hVtLtK9eAueZ6EqGGSQTTZZVdD1+2FrBOFeYGe/Htq11XIb+kJN8PLL5\nCgetsJnblqWLbzaPIsrBSkvqCZ9PZkMudtZZihwAflntI4Vh4udn5blsG8PijfEJDCKQ8FwbLbCz\nNSCrvMeYe73QvGYCdC8m6rrYNsMRVsywLUmF6HcDKYmVd/UYEu5Y4Za8UhUPaHbeN8Yp3FL1vwGv\nWmv/u5mvfhP4S/7vvwT8owc647EcCjke16Mpx+P6eORBLM4fBn4ReEkI8aL/7L8A/hbwfwkh/jJw\nBfj5+x1IKEs671yqKDKkqrX4Gkty1v2elDFPzDsXL1E137pxprUcrCCWvWA1NpZmYyHems6xX6TB\n4hbSIqQJuNDU1xuvexzZmXiHJ6IWnbES7fPjK6+1XTD98TdqFxwbyJzne7dZL93vU6l5w8jgQsa+\nJcTL2yffdV+HRB7ZuEIgJ6Jc1qiJDLRsZa3Qtq0AW8n2qU4q1nvORZtOE+xWhvCWRbFWQ2QRnuYt\nTmviWBN5eFAa16z19kMsbavqsdiANnF40iyrAj54kORs5T32pu69cNCltvZdCks3LZnzMLK9IiOK\nNEXuPQRlsWImmW7duyf0g1km3wN5dON6r1ts5pN320XpQxxDi9CC0sO0xnXK2/kq39EObtRXBRrJ\nfOT5O63ktdEJvnnlnDvOrQxZu8otgHTbcuaOIdtwYytLje7FmLiJWXqIVMezlw1Hrn7dsymJQQ/T\nz5C+JFRNJTqJ2pC1j9U2CCbjmZOarz9w6wxr7R9y70cI8OP3+/2sKGlCyWKiNJ/o3uKWx4Fsln1K\nHQU4QiJbFxwckLoqohBDkcKyV2SBkLYTVczFOTfH7njX1hcx4ygQH88vTEjjOvBEjoqUqU4CIe6W\n7nO5XOV84mpn/3z/ZV6pVrhWOhxL48KfiZ1yVVjeLteCQo2k4YnFHU5ljl9wolOuTpfYGblgd2ft\ncPUeepTj6o7XVB4YPOIEgKqMKOoo0HfFwvDc3DrziXsPro8WGMa6paXD1TU3IRtrBUudCSc6ThE2\nMfAd35pjX6fMRTmdyPN7SgdQn3oY2nI25kxvL7xP0zpGz9DeJUqjZEsyMtvsz12Ax5NWM+QQHF53\n/VGPa6jt1sZRswVYloQ4Cq00+rdrimsx1Y4zLP7gzU9jYxvwr7arQQtk3xeITCJ6l2Iu/EtfSLLt\n5tWB1hxpHBSzyCvU9j6kvoR6LsOkCuP7rqssw+Z56MveuOSNgo8mNdUgCiRAsvZhBtvG2u9F2fle\n8ljLHxbTCT/3xDfD9sX0dlA83947w7DIWPOxsMVkynw65WTmsq3XJwssL+2z3HUKbC7JyVTFuufv\nXErHDMtOsCSER1afWHOK7MLcNivpPrU/31THfH7wDl/IXBZ9RSkqawJAd0kpztudoDgTofmJ7vUD\n9/NkNOQruVsxLxVrZKriYsfFQHuy4Ft7ZwL/Z9Nn/KhKo0isES4e6JMoxkjyOiL3lrghZyGesJq4\ncV5Ox2zk/eApgLPoxqWbIOfnt/nU4GbgBBjWWeiJ7vZ1jdyWPOfA7WxAWUcBoTGsMubinOXMvTel\nUYzKjL0iC+caTTpIr6grrdBahi6cBkDYNvZlhLvXQ6o4PyyxwmmVQIqhLWgTGNqzO1PWpoZo4hew\nvCEJ8JU/p/psPx8xOeX5a8eC5Zdr4k1vUU5yzKDD8AWXJByfUFgJiU8iZnuaeKgDny+4PEi9kPrz\ndRF13RIfVzVUUUheyWmNrG3LJ1pbB3qfTarfBYp/Pzm06OxjOZZjOZbDKo/V4ixMxFsTh4tUwvJU\nshG6G25OegzSgrNdF9P8xuY5plWMXHQrzsnOiNoqXrnhYobPnlpnv0rJfJz0xTtnyF9boCEhUs+O\n+cHve4dd79K9eOsMShl+6Mw7APzs8tc5E+3yL6ZPATDSHVJZseN5HU/FO4xMh30PP3ohu8GesbxW\nuSxgjOZ8vBus0L+2/WlevHyO1cxlEX9h+Ss80dvh965dBOCtW6uP/HkeKhEz/wtCiARhKaqI/dJZ\nBt2oZD9OOZU4T+CpziYL8ZTNwsU8d8oO4yrlk0uuMujTA/d8G3xubVToHArQUSVdWTLnuQPSuGY8\nTQPdn7GCuYWcnq84kzqmjGqErxqZVhHTIg4hIGMk9UwWnshApVoX1Tis4sfC4phxZRFglXSWHCDz\n0jG+e1xlsdJh9+kY5Wkho8LS2ajJbrj5kF0fkf/IIhe/eAWAt+6sML7VQ/gcg9R9hudi8lX3oPvX\nDd31OvRDz5cVu09HYRzSPcvgWo0sG3iScP98rbqtLPQ64VaE1uikbaVhorvq0R+wYqiRx6o4ayPZ\n8QBXcCS0DQB9OMl4an4r1Ipfu+Fc5MYz+LEzbzKtY7qel/H63jz71+ZITzpTv7zRo7cuAsC+FpZP\nD27w9b0nANfyQAgbXMJvTs5zLR7xUz1Hc7ckJf/N5g/yz64/D8AnltdZStoe0bfTeRK0az2Lgxvl\nVrFnfJJpOkAqG+5vbBPOZ5vkxQvuAB8Xzy4yiCLCFk0pnCOLbpqhjcqMdTkI7nYDR+tFRfi/oypW\n4hb3uq/bWLZBMCw75L4f+lQnTExCJFqat3ISO/wlLoSQD6KgOBuy6gaYba0gikyr94VFShs4EtxJ\nW9hNE+s80nRyszLz3gprncIERF5iuxnUDZeD+1csuecyjQVWxljlFGOxoKgGLXG4MZJ8STA56SZs\nNbDUSy314ukvV0TDHD1wC+5krUe+0sZYZS2oO5Js35N8TAvXo71p3palmFiF0ILupdRZy7dpIofl\nbQitHanxDM7zPsP7PaN4aR7gSLerws3xPE8MXEww8RUcTy86dpUXd84yiHPieXenr75zGlITYlO9\n83uM+j0iD3A/MTfmd9ef47l5F3NcPDNhVGU81XOVRpmsMFYy9orwaZXRVSXbGy64/ZJWXFzeCP3B\nTyZDPjl3m11Thd8D/Mbo+wG4trOAinS4r1fyM7y2f4py5Fbg1VN7XH50j++QiQhExkJabGQRU6/o\nMk1dKyo/TtM6Zrvosl/72BSOf6Bhm+qrgrPJTkgKFiYmN3F4rht5PyQQAfaqjLRXMRfNsFAZgeo2\nFqRgXKXMJ+33kdR0Yjd+Fqcs6xncphD2AMkHwrpmXnjFacXHYx0UBM7KAITXMxZeVYc+5zqVTE5a\nqjX3XJM7Mdm2Jtlz28MnImyqGXnPAyuo5iz6gksSvnDGeRjbU2d4vPmLK/Qv9UKf9Py0RsyVyFu+\nEq8EWdlA4oK1DgCfeMspTRwJs7/uai4+2HNIOEUvKs+FYRzRR5NlnwXG30s+Fh7HsRzLsRzLo5TH\nanEmUnOu02Il52QeesUoZbi9O2Br7Facs8u7nOnt8vaeiynevLQCkSWecy5d3C2pJq3lkUaa7und\nsH1zfQH2Yt5acLHFTz9xk7PdXb669aQ7nzT8zMkXmXjf/v8d9/n28Eyg5p+sL/DKMypUQlwZLPFS\neprbtYM7nYu3eU2f5rdufJ874dfn6f3gVjj/O9NVfveV51n8mmeU/7GjnVU/IMIG19ZogTEiVFg5\ntz1m4q3GBnbUuNIAez7eDFCZyGW+vYW6Ne0yn+YBFzosMzJRs5o5z+I3y085N72pmZ7GDMuU1Y5v\n+yz1ge6msTSUM/i9xgVX3uIUd5VYCusY7u/+/EiKPciOJKc1wrvCVDWiksHixEJ1quT8WefR3RzM\nc73TRVbOY1MX9jnRn/LCohunm1eXUbT45hPZiB+ce5vcuvnytYXzbLzQDzR1AFe2FsPpGktYlg3/\npmsdLDL3ntg0AdPSB+qOb53RhFwMgTHJfeDD87q1QN9PHm/PIau4kS+E7d/a/QyvDluAuDGC/dsu\nSTAeZdzqzjHdbUrzJMmORJUe1qJAdiyDk05ZVlqyeXUpEN4C2Nhg993+3/72eb6VmqB45/s5v73x\nSdYXnGt+Id1wg+gfWPe2INcD9s74Ur7lLl/dv8Cdwu1fDFzDsJvfcVwJJ94ydH98ElzK/Tohu5Iw\nf9m9aLv54Su5/NBEuPI7ACpX993EFJuJ0ihSOaNQG8lNzES3ZC67VZedwpM/1Irr0wUmQ/deDBYm\n/F70bIA77d+YY+0rEuOB0Juf1y7u2fC72hb8PiuzMUshbODbtNoBkUKpn3FhCXH46eUeiTTwnwP4\nzUbqtoAlGdaoxPC5JQfv60QVk8WEi/MOF72UjHl9eIILHadYo+0IWQryPafo3txb5UQ65GziQnWf\nG1xFzhk2KxcjfX3/BO/o5dB8URWe8KMZl04KNgHvqptOjEkU1cBtFwPfbM8nBWXt/g6hCNloTtrt\n95HHqjjHRcLXrrhkDVawe6oTLA/wZLg+G5t1S7fq+3GSlSDeh8U3Wn690bmIrcxZlLprQFqs/72o\nJWraDrKJLUSWJGkrh052Rny+67LsJ9WQ63NLfGX5afeDWzGyElgfq3ttc418MeZUx2WDpTD88e5T\nnPl9N3Kjs4rVqAzsTQDZJnSu7vmt/gd9fB8Nsd58C8BxSV1E0HFvvLYicC2CjycKE7gKhnWHwsTB\n4ixMzEbRWh6TPMW80Wf+pjv+5FTCi3NzjjMTSEaSyYm2hxASOnFFqdtX3dASIZv3SPIERvkmyTWr\na837T6qjJGamWZtJgL73nAYd5GgKvqtkvJ2jR72Ay/6R5bf5k53zbPkF7/XdNU739/j26AwAumNR\npWuMB3BrZ443umvs+0qgVNYsRWMmxs2nS3vL1JsZPU9wHY8NaqrBX5+Z77pr9QpPlhqrpO815LLo\nsgLPwYOsHSa1UZBWHmRKuh8v53GM81iO5ViO5SHlsVqcIpckL7sVSFgYLackqimtdLXkkc+iZUl1\nIL4hS4j3Lemmy44WKxm7z1vMwPc531N0bynifWdp1B2BTqGa867hYs3S6pALC84V+NLiO3yp+zbL\nvn1vZSVPJpssnnCVSsWlZWRB6Kq53+0w6k045UEAlYn445cu8sJLLhu4/rmzJKoO7C6liehszlQ5\nfExcO2sB2XaPNAhsocJYGit8GxTPMWAUxsqQRQfnng99TFMJy/neFqbrSyKN5Ha3F1o4DC4DyMAY\nb5VjB9epZ9WZK9nc7wWDf5AUlFoFd70yklq3PZKEcFAZc3ct+kwyGfsxgSPNuK5YVwbZPAc5mWI7\nacB1qt19ko05vr3tLMq1kyOe7m9wberghVJYJJY7vtLPxgZZRKRu+jFZSjBWBK6HvarDdtnjTu72\nv3N7gc4dRbbhK4m2KmSlg0VslXD9kZra80iSryTU/j0QM1yi4EJ9RDJ8ZpTrP2SiBxvXx6o4VQmD\nqz74ai03ry/x5BM+5qEMcawRoqWRm61flpWg6sH6F9yDnL9c0bkj6T/vfv/MJzf540sXyF52mi3d\ndU27VO6D/ZOE7WIB4ydMrmNeyU4HfOCrW2tM8jQkBaZnNMmWQvl+39oKOlHFydQp1iv5Eif/QAYi\n1arvMGq39lwM9JnlTayCesFdT6d7uGrVH6lYQtM8h+9p8XbCuHhnWXh6r8zzrs6ULNZ3AdoLE1Ga\n1G9X1FaFCTWf5tzsaUchBkRTS7arqbOGeBjSnZraJ4N2Jl0mZzKurrnjLS2OSaI61KprI0O8FZzi\n13omW+Ql0NrNhCE+FhJYcjyVm8dVCmsdHKkByNea7i3BzW33/r/WP8lCPGXg8bk3zTzDKgscBSiX\nQGya5qU3Yt5eWSFbdYp4u+gyqRKubzjFm9yMSfYgHbX0ckJbTNcvyEqCAJX79twnUvIFGRZwYQ5W\nyZrYgeFl3XIQWCnC/RzorXQPeayK0yoo571lIATZ9YTJKTchlDSBAQccWN7adgWxAuouVPN+hYhj\nBlcN62+4rPvpz+3xhQtX2D3tFNWd0YC8jClzf4tbKaJbk/kulFJYpjrm7R33e/GPllkYW7Y/5WMk\n53NKk2ATX7l0Ypfz/e1AlPz/vPUZnvzaRqiN1T3NK3dOko+dxfmd/BTntuoQnJbyCCtOaN9KIwL4\n3H3u/pkZRWWsaAHtvptp6WOcDRtVM+GMFY7Nf2sJgPJyn7VvCTrbHocpBPGwJtmdCfID2cg971Ob\ngqofMzzvYnN7z2TUpwoiz9OapjXWilCbXlUKXat2ITC8W1F+XOrUfYM2oFUoPkttOjGyKMHXftsk\nJhlZdvfd+395uMRzC+vBsxgXCZE0rHkDItqJ6N1oa8XVVDB6usPCaadYh1VGbSR64t6LzlCgCsvo\nrE/yZYLBFUOdtaQeUa6Jdn0TwKXknrXnjYWpCqccmyy6rL1eidqF4v3kOMZ5LMdyLMfykPJ4LU4B\nuk06071p2dp2wae1lSFJpCl8NjO0X/V4OZ1ZdAZ1z5mg+08ITCKJfEzzxXfOcWJtj8+uuK6V/+ra\nqzyX3Qwlkuv1HN+XXqPrs7UDUbNhUv769OcAuPIc6IFBTmdczoWK73/SHe/iYJ2VeJ9vjRwbUvz7\n8+glheg5SyZdmRL/0RzTi56fcD0i3RoyfNrd33Kv5Yw8iiJaj+fg5zVQSYxniC9qF+9s8JuN296g\nEdatOJAB35j2uHlphTnf5nnlck26VVH33HbdF1QmIh65517Oez5U30647iiS3ZLF15wLN7gWsf18\nxugpd36zmpMkNdZbunWtMJWEuomNCWQN0odsjO/SGeQoG5/WtqbVXUgC3YvRvYU29muss9o8D2sv\nLj16wXsAScXV20tcv+M6Ipz6E0PnToGNmnGK2PuSCGiKi/11vl2fIVtwOY3xk5J8WWJ9SxZVCKq5\nGaRELCBvXexoool6bR94YZ1VGY98TqQwAYoUjhHJEOIxCe8rj91VL5Za0oB4DOqGUzzjQU4a6XdZ\nyE1LBu17FdnM48p6lrFq+2/baUStFdcnDicaCc28mgR+zfPZFqejmnzmYf3T4fdzZ+hipn/+x75K\nXxX8+pufASDfT3jmiXV+eNl1FYuFZl9nfPm1ZwF45utj1M6Enc85V7/Y0axdqhk+74PXG1AupIGP\ncLWz/wGf3kdEJC5e5EMcaiQxpcD6IH1RxEwjTRK1GEAlZIAH1UYyLLIw4W5fXmb1TxRzV9wEqjuK\n4fkMzzJHOS+ouyrgNhGQbQiSoXfhIogXFNl2Gzufu6aRfmHeTRPMkg7wI1NJ14DPtCuBqNseRaER\nvD3KGrOVAMu5S1MIYx21nGjgPIJ4ahyJNQ5mtlX0AofAaJrReTWje6dxlQ2i0ljhQ12pIH0n4zeK\nHwAgW8x5cnmbyBOPF/2KuiORwxllGYngYovaExvHnh93VNIrDWrqQ3PTCjHJsbH7fXVijulaQjHv\nk4R9gU4g23bH666378u95PEqzsRSnW1jfeVOSvem+3tvYQAnRwfIFqCt4Kh8d8qGGVzFhhqoG82k\nLNoItnytq7HiQE8hlawj9SQw61yuVnhpeJrPnHQW5Y/OvcYr0zMhITW3OOFLy5cZSDdhKxvx/91+\nnqU/ckvR/hMxPSVJfLA62Ygo5iF2SXvmrtboTDE+/f54wSMnwgKiBcALV7xQJ96TiAyTKA4kGiap\nsFYEC3RSJYzylOFtt6Atf13Rv1lR+yTAZCWiGswkDWsXr2pwnNEUsh1LPPEE2KkgylslZxWo3LDw\ntvt+fDainlNY3S7AohLYyE9ILVyC0Z+yntcOIdGQTRzlCiILsmhYMMDGslWkBqc0bVNpY0l2a9TE\nk3JUCXltA7lL/Z05sjFsfsEdb2+hJH5pQOoVlSph5Vsa8U2fjE26vP0DfWrPTSGnEpuZNtlbgNC0\nWX4zC3sAtTMmqma7YFr02VV2PuHeq8lJQd0FnbrzxyNYfEMTTRpD7f2jmA8c4xRCKCHEN4UQ/9hv\nXxBCfEUI8ZYQ4h8IIe5j3B7LYZTjcT2acjyuH648jMX5V3DN7X1Hav5r4L+31v6fQoi/A/xl4H95\nvwMIaVHJDNwodrAhgM61iP1uh27fZVOtFVjblraJTg1WIBtLQFiirEY3348j9t5eZGfeW5mnt7mV\nzIdzDXxb0hu1gze8PDlDIjV/auFtALqi4J3pSuBl/FfOXOJEPAy1sy+NzrL5z0/T89ZL2RMsbE8Q\nntl96ZUOO88Lur6ipffGNqMXlpmedCtYUxJ4COUDjyvMeK53ZdWt9L3RSx8jTBT5NKGOvSUhDdq0\nPYmEsORFzNzr7tXs3amxos12qsoihtA8TqMEsnJVIeDeqdGTAll5pvFdiypbXKeD1QjSXd8Ncytm\n/0TUxjRLh7tpUHFqKki3YfXb3vPoRexdSJme9LH39NBanB98XK0Nri64sQsM6uLdZYnxzpRs082H\nUivGReWnw/QAACAASURBVIL+ugud9W9bqh5kt9246h1FNGGmxNG569Nl36V2AZIhdNZ9DyEL5bzE\ng1qIx76Vh49pSn2Pcag1tvKcB594gjtf7DBd8yG/yGAFZBvufpZe06jcUPUfzJZ80PbAZ4E/B/xX\nwF/znfR+DPiLfpdfA/4G9xkIWwvqYbvQJaKlb8q2LfWNlOk5d2NJWmNt67JHqVOcs8DjNKvAt4Ed\nT3qkewo7cjPq1niV24vz9Pruhb+xusALg1uBEFdbwXP9O3wyda76jXqRraLL50+5WtvnurfJbcTX\n9xwpyNf/8DkGe23rgMXXc8T+hMjzEaaLCasvSoqBj5msDah6Ak658zchhMMkj2pcscAsjnP2K2WR\ntSTa988lshgtqLxyHYs0LFbgkkVVHrF0xycBptrDStyBi3nB5KRgcsrHuhdLfOcud0+RQUob3pOp\ngV0tQ+lsNFJk64KFS/4ZGKAWjrAChxc2M7NC5YLuhiH5pltg1XCfbhIjF9yibOf6vPO+D+fxyyMb\nV9oYpzDGtQTGve8miw667rUBbRlcd9/f3JxDRYZkhqYtGVniJtTvE8XNglZ3YeeTlrXnHQnIiTTn\n9TfOMP+K578duTFWhXftK+v6BJkmpGIdNnOmRBStmXzBEZVvfDamWLSY1F2QrAT9qzJcr5VQLLaE\n1TNRvnvKg1qc/wPwnwEDv70M7Fprm8NfB87c9yiCNiMpLOWcDckdlVt6NwT70q9Yp3PitA7ZWgeO\nb0HxShkiaZh4xmnRr8kTg8h9z5FSwHrKeN3FXP741oCvzj/JmRVHCvITJ1/ji923iYW7hV3d5en+\nZmAmr6ziX2xd5Ob/cQGAMzdrdi7GVI1iUAKEoDrpHkndkXTWSwYvud9vf2mNvackHV+j3XT/O2Ty\naMYV2jaQFk/829YAA0RTb3HGCj3QWK+oijqlSiPU/8/em8ZYkmX3fb9zb2xvy5eZlVlZW3dVT091\nT/fMsIczw+EG7qS4mKBkQCYkWYJs0CIMg4BkSoAofzD0wbIkwJYhw4aMIURYsgVRlkmLshZL8sii\nRFIccmY45Cy9Tm+1V1aub4sXEfdef7g34r2XVdVVNV1TXZ3zDlDIevnei4iMG3HinP/5n/8JRYBW\nVqJiy/hkqM5edew8nzF4OmBP3QrdrWYzjgqNupWQ3prdMNN1h23VQ79ccKz+vapnGLWE7pUQqZR4\nx1nUrwUnbgEz7b6dYydhOuvpLVxV4WqBi92ZItdjZA9lXefpqqadeMX3MoTi1iGVazyIOHCxpnXD\nZ4ztr7YZPTvFfdhnelNxmDxChkFsY6xQpUMXs44v2684HPv7f2e/ix6q5vop+j4LiAI5RU8sTkkz\n3K055vr4RDj8zvPc+FR4YPcrUK7xD51Lis5123QWOSWNmDHcJYKds/uZq/6TwE3n3Ofv9dm7fP9n\nReRzIvI5Mxjd+wtLeyT2UNd1uFzXx8Ue5roW1XJd72b3O1f9p0TkJ4AMj5n8TWBVRKLwFDsHXLnT\nl51znwY+DZB+4KyTdA7jTBwmCalA5cPwGiMcqYzyVE7a8qm41pZYG7Kgj2mdsD9sY0J1NslK0pWK\nJEQuSVQ1CjzgO5NOtw/5ZP9NAJ5Pr7CiZqrgq3rMk+kueeB9/qPLLxD9TxucfNXTmQ5e2ECMTzcA\nRqdS4usJ+bqPeG0k6LxCwmiBZGDJz1g+uOJHQBzkj50e58Nb1wvnXEPfsaHCXWNXgZaU3appKMIo\nUbOM3oXxKEGjoIwsJo+IJuE8n044eM7gWuG6UWAOY6KgqtPaF9rXHStvhk6jWDj4QEyxEuhFMVRd\n59Wx8Nec0w6T+usm27WMD/Qs0ij9eIU6E2rddMTXD5qU1OU587NtJDu+67rSOeOa0ErARdLQh8S4\nMHo30I+MBe3vAYD1lyqqVkr5AR9xKg0UimjkP5/uCVZDGOlF1bGItoz3azEIhVI0tLNo4idepoeB\nXeN8NiMBZ7UCUW6oVoJu63f22f/Wgrjt73FlFHYU0b7q99++YbF6FlVLoDU1ozTemY10X3PV/xLw\nlwBE5PuBv+Cc+49F5B8CfxT4ZeBPA792r21RKdibYZw1tcAfqT8RNXWkfV0YS0p+0n+muzJhJZs2\nLVz7eRBIDXSlODb0sikbLf+UPJGO2EiHrAc0ua/HZKpkXXuQZUXl9FTBIDBdszDl7Re//N0APPGL\nMdFnfofpD3le2eiUWji+bLvArrQajCY5NKj9kdcFBKYrGpxhUnrMtZM8Xi2XD3VdBT/UDO9TpF3B\njj8Pa18RTnxpSHTDQxijD52kascNn9fFDoqZyEYVWeKbMf03/Hrc+ESCy8qGWE3kkLlecqe9c6zH\n0tpUo6q4Gblg2g4bOVQ5S8WZmy0T5Y50VzWNGeIgNtKISbR2DDIc40JrLdZ5mKY+j9U9wLBHbA93\nXaUpBkllgw5B/R64OW1OpzyHUoXUObsxZeNLwrb2nrE6n6O6JU980IviXNtfYas/4MOr/vWLB1tM\nq4j9sb+vx5d6ZNuKVr0OuxZVzGoMYj38UtQ6m1NH3tbsfiiM//6QD7oafu5hzOpXIk7+rg9kVGEY\nPtWbFQ3rv63R53znU/NueJx/EfhlEflvgN8D/vY9vyEOl8yiQBnopslfjPNPkHrUSw7ZLUUeWBNF\nVmJaioNQxTZWobVtOj5ibUijipUgInA6O2AjHjQ8zEyVxFI1UWZPFYxcxNuV74H+zP7z/Pr/8zGe\n/hWPWcnVa9g4afiD2Y4FgWTf3yjRwQTTy2hf93+AHpdIUWLWfRGzWBFQjitX/PY/cP7m/Z/Z99Ye\neF2lFJLLQdF9Kqy+aln7rCfoVm++jcoyXMcXxzovC/0Tp9h7NhDeewF/9AEjZZXSPhCmq0EURINM\nlHewgBQKFzmqVb8OVV9wEjVzvJ0I+QlhulUPEXPIVM0J4HqsbL5rJBrROASrId3zUxQh6DQauyjg\nO09+f/8Q4R/8foVG31KMQ4qq4U0SKWykmmKMC0pDpq5yF4bumyOSIDh95Xsy1j6xzZNdPwFiLR1z\nMhs2nUJKHId5yviy77Trv6LoXa6Ih6EYFfmaQjSazWs/+GCL/ER9fDA6Z9FPhKma2jLZbdF91Qcu\nJ75c0nnpCu4wDAEUoTeeMnwuDIWMBRuJ70Di4RWHwrG6fwP8m/D/14FPPcj3l/Z42nJdj6ct1/Ub\nZ492yqUTVD57cqtCUMUMW7DRnBCN821UKlTdprstrkwjsqCuksYVsTZU1Ux1B2bqOgAa14wf7ukJ\nMaapou/YFi9Nz/B33/oOACb/1xZP/9O3wYRIpSxQq/0mlNeF1+qrIxUxDj2cElV19Vb5uSfhiWtS\n/LTFvdDxcuax5XG+a0t3DU//bz6ilnGO3dtvWtuiJ875qKUeI3s4YO0PMqrM82lHZxQmm0VtcchC\nxpt+HfUUWtc1Ra2KFXiTajVg35EhjxL2n/eRvliYnLIzTNT4dkkbsFZVCtHIT0gEmggjXBbEOaR7\ntknVnBZfTa7pHUr8NSLfHPo4DbYbe75sM/Snsr5xSNdVaYVUbhaBOsBY4n1//53+LeFytslnn/IR\n6Eo7xzqhHZVhc4rB9R6rr/j7pY425xvu4kEZKFGw/fEue99icTX/t1Requ4NP8Os+wac+/KE+E0P\n5brRyKM7cWDhaIXbOyQ59LSyoh9h9Wzu+jcyVX9wszNHCISUKbyof85zauch0FKwkwibhZQsCOK+\nG9N4ShO8w4maOy5PF5w7qDulabVjdSxgQuYOc26OjVUVUjMmtEad3JjdYNPCp7rONu/LjV3WXg2o\nv2RMNoQgv4ma4gtGAXNUFWFm9wwTVasF7U6AYOKKaVqyfzHoNu6D7ZTocJ2YcYTNLPG+brY3P4gr\nyi26nPWiJwNHlDumK8FxFw6JImy9rg/rnL3fzAUZtrpaZK3HGfUslUfR0IOchPQ93CLKOHpvCofa\np+I3TyTcvNlH9n1A0b6iOPOWJbs1bXZpY2kecNG4xClh5yP++7sfr0A7skv+Qll53bH68gj9hsdM\n3WCAcw7XCtWn6A6uTknTUiommt2zwL06pN+zuerA4lV4Jx/o7vL7u3z06zHdOM47n6lGwPZu+513\npCIzDMjScBkBzHGeUyPSDMkCoKyajg1JEiRyuGFgPmsNxhBf9cWi1nqCU4rJxqyzxyazCLBz3WIS\nIfejpXCBlTGd+v1lcUUrKZmks55nfaBxrbCBSiGFakjtUvnP1BhWfGhIk9n7Ue6xdnf0zjA1fzFa\njDbvMZvmfW3OzaZI1pFnHVEm8YJzkfmAoTbrKPvesR1ciChWZp060VsZrR1L52qYw747welZMcpp\nRTR2C7zM6UaL4RN1MUfQ+7oh1KeHBlUYpP6+Un7NatV3301z25+oJoEdYRNwbnbP3mNZj3EYtLSl\nLW1p3xh7byNOZiHxfT23j4R9d0rVH0SFSIslqnM0YfGJJMqnl0d30TzwjuznSNouR0L+Yz2jxgHF\nrKfZWYvUqZFzC2NkAZ+uB76rOEe6P5v1Ml3z0WBy6E9gemCpWgop65ZKhxlFGAlTMcURx6ahGyWH\nltZNxbATlPcnqqmkg8dM2zcM3bd8C4rpxOjCNt9HoGypGb/YgSvKGfTwzWri+a0N5llnaEdOS3OZ\na2F8MmXwpIdIir5nTyR+8gzpvqNsC9e+22M05//voNzetFBWjTp7vV09Nc14cDEej6wzBZMESbn6\nuguZjbsLxFL/Xk1rkQMWU/V7hJTiHiGdQkQGwMuPbId3tw3g1nuw3/POuc33YL/fUBORbWDEe3NO\n5225rg/Rlut693V91I7zc865Tz6yHT7mx3Gc7HE4p4/DMRw3exzO6eNwDEdtiXEubWlLW9oD2tJx\nLm1pS1vaA9qjdpyffsT7u5s9LsdxnOxxOKePwzEcN3sczunjcAwL9kgxzqUtbWlLOw62TNWXtrSl\nLe0B7ZE5ThH5MRF5OQyL+oVHtM8nROT/E5GvishXROTPht//ZRG5IiJfDP9+4lEcz3G05boeT3sv\n1jXs932xto8kVRcRDbwC/Ahetv93gT/unPvqN3i/p4HTzrkviEgP+DzwR4CfBobOuf/uG7n/427L\ndT2e9l6ta9j3+2JtH1XE+SngNefc6865Ai+m+oe/0Tt1zl1zzn0h/H+An/p3fzN0lnY/tlzX42nv\nybrC+2dt35XjfIBw/ixwae71/Q8Be0gmIheAbwU+G371cyLyByLySyKy9iiP5XG35boeX7vPtX3P\n1xUe77X9uh1nCOf/Z+DHgeeBPy4izz+sA3uYJiJd4FeAP+ecO8SPRX0a+BhwDfjv38PDe6xsua7H\n15Zr+/Ds3UScDxLOXwGemHt912FRD9tEJMYvwN9zzv0qgHPuhnPOOOcs8IsslbHnbbmux9fud23f\ns3WF98faft3FIRH5o8CPOef+s/D6TwHf7pz7uTt8NgJe0Vn7qWTFz+BxBIHauFY6BcShwnzuVlyS\nqoo4yNposcicVNFsZpRrfrp30Fg6+l4zmym8tk4WPuPwr828pqZTFDZM+QuDHOv3rROm05i1jlfd\n6asxuYsxQWalcBHbL+7eetzFIL6edY0le6oV1SO876AapWT2ewEX6UY53A/9ElyYhWZicIkjSbyi\nUicuaElBEgQ0NRY9t1ICKBEk/MaGFbVz17UDTHjfOIVBsVt5pfDRICPKZ4rwtRDvTGDbLWg5Oq0w\n2Wy4m9NQXL782K8r3P/aNvdrq/1U0vX3q9hFAWgcC3Obau3c234XVJRcuAQaVaX6s/U2lZ8rZOf1\n2u5wO7v5hZ/N7Gtez77rFn8nzi9hWFh1RFnNOcFWcypcBvIbd1/Xb7isnIj8LPCzgJEk5cn//OcB\nsLGj7DncCS8vFqcVIo7zJ/wwp0+sv83p5IC+9sriKzpf2K4KZ1yH1dQ4DNI4KotqPjP/uXJOodbM\naUeVTlM43byfuxiNZWC9gvQ4jE3cKf0Nt1t0sE6aBbiVd3jt2kn+ixd+HYAXWm/xtWKLcZAyvzJd\n42986z986+s4hY+lza+rlojv7P5UeEP5myU4GoljSBNc6s9DtdHFxqqRDKs6Efm6ZnjOr8Xw2YLn\nPnCVj676YW9Ppjucjfc4pb3w8aae0BaIw/ZjUbQlIQ5ja6euJHcV06A4XzhH6WA3rMPAZlyv+vyv\nV74LgDd+60nWXnJ0rnl5sXg/9xJjQUZOisqP/Yj89ssTHXY/3GJ8yu+/XLG88fN/4Viuq9Ipz/3U\nfwnUyvmu8VSqAlU5lKnl2RzxuELKIAweK0yqmzHNTgnRxDYPKFVYxDmma14mbnhaU/QXj2V+eCNh\nHHB9+9rI4eKZ43RxGAFd++XEIqlFwvRVrS1xUpEl9XA4r3Fc+3ERx+Eow7zuFebTfeHFv/rzd13X\nd5Oq31c475z7tHPuk865i7rTeRe7W9ojsgde10Qeu9niS7uz3XNt59c1ypb3693s3UScvwtcFJGn\n8Cf/jwF/4p2+4BRMT8yiQNs2ROGJoJSj35nwXJizfCG7xaoekYRUXR1RTJ2PNGfvK47Okddz+UWM\nQc+F6EZkMQJFAdXCd9th2NuBdMhdRFv717EYtosu3chHzMMyZXP9kOczfx1eKk+wV3U4n3gZwVPR\nwTudmsfJHnhdUYK0wgwh51iAf6IIF0fYto/YXZjzYtMw7zoS8lXF8AP+vD9xbocL3V3aYZ5vJn6s\nczuMkY1DtJmFCDOVGItdgFQ0Qlyn5jhKoF3P4lA5I53wgd4OAC+vn8Uk+u5/mz2S0kVB5LiObN5f\nvXcPvLbz6blTMhMedw5nQU3CyJKp/6DJwljnSCi7GhsgmXhssdFshlDV1kz7irLr359sOUwC0WSW\nys//FBeOxc5eW5itg/YQz7zwuEQWHXmPEEW2gQHBR5ha/Fjx2lppyf5K+PzknV3j1+04nXOViPwc\n8C8ADfySc+4r7/glBTYLKZARJLFImPkTxxUfXL3Fhcw7mlU9oqOmxLe5wpnZOwTMtaM1LDrW2SHY\nhe9m4m/IAr3gZI9apkr2TQcdvt9vT1iLVygDOGeccKZ90DjaLwzPc2vapb/mMc+L6fW7bvtxsq9r\nXZGFueMCMzX9SINSzewatVNi20njOIueYvikY/2sn2f/dP8W6/FoYS0yKYnnHpwWGLt6nR3WOdph\n92X4vQr7z1BoceiQumtXkrsxn+i+CcCLF7e4efks2Z6/FfQ4Ito+nM1QqvHNWpm8sv4mVbO56+8X\ne9C1FQvRZA4rnkudVeXQhUMVswkKVStawCDFOJJpPbzNv1G1/AkrO0LZkWYuerliUfkcaDlfgCAo\n8Svmpo8Cam6IX73fuB4K6BDl0OF9rS0iDhuGJiqxzbyxendKWaTtr5+y984L+64wTufcPwP+2X1/\nQTnEzJ4oUVY299d6e8LFzk02Iz8wPhGDxs0iTrELo38NsvAaFqNSxe045+2fXfy+caoZJwwsFHcA\nTugho4CVaRQn48MGw4zFcC7ZJbdx87oX5w0GOqrHOL4P7IHXFWaOs44250eLWAsh0nBZjFOCSf3n\nB+cV6qkhZ1f8TIWNZEhP53QDpt3TEzSOccgMtCuJcWipi3IOJYKpRyGg0CLUo+NyKoydzzocGseq\n9g+079x4g79/4SS9t7wjj3sxepCiDvwUMNdKF4pD0X5O+2bGdD28nsz9ne8De5C1FUeDYfpizlwR\nzTqcCGXPr0uDXVau/jiqcjOH2VY4gSoLjrIjVB0oV2aOT0/DCGL8uHAIU0/xDlwczUiTqiNUbSh7\n4fupRVoVOjjOuvhbj9cR8QXFSIcHqPKOs85ArROSyJB1/Q7ze0zQfR89L5e2tKUt7fGwRzuszYEe\nel9dnSiJIts8EZ5eucXpZL9JnWOpiGWGN1qnUGKb1Lh0UUMxATBoNG7hO7gZxllHjvOvFbZJ2RMx\nC+mhQcIx0OwPoBOwt7raXtOlUlXSU7PKf0uXvDo8yT8afQyAlSQH/uDBz9n7xeqoro4068izMogI\ntucx0HKthTjH4AkfE46fz7m4sctm6iO8jXjo06iQKWRSosSSh/MfO8uqmsE3JY7YwZgyfF6j0U0E\nap2PTsvwujzCcTmb7vHcxSu89eYFAJKhIlpJUaMwPKwocXGES/3+xThaN0vyNZ9BjM4dY1lG5xYx\nTqGhjTklTfQHNIPOqtjfT/M4MPihalYLZa9O2aFqz7LxaCwkh7MhfdHEoQuIR36tk/0SVRhs2H7V\njihXIvJ+oPutRCBRQ2cq+o6ybzHh/axTEEWmgazFCeKEWM0iUIymlfr7W+t3Hs73SB2nGEHngdfV\n8ifk6Q0P0n+oe40VNVlwXqWLqGcnxlIthMexVMT4dBogtwmxVI0zrR3wfPHnTvSk5C4Yqgrv13BA\nHpbYBMdQOo1xChv211M5sVSU+CvrxnSFL79xFoY1WH68bzBXT7lUgoj4KYMAcYRtZ5i2hzSkshSr\nCbsf8+f36bPbbLUP2QiOU4mlp/ImldbhYVk/sABy58jmoIAS1zhKjfUFoYBp5s4xdkJd/imPPEAz\nKfnhzZf4Wx85CcDkeguxKWrqaSn61iFSGdzcfRSNKto3/brWdJtjaSLN9FGnYLoijM761zqHeATt\nm/7EVFqwepZK19SherooAiYWqlBDtBHgIN0LkMcYepcNnTf9daAPRn4uer3OlYEkRrX8A0uPFPEw\nJtn393/V1pQdRdmeB1kVReLXqUorosg002aNneHg81bTkyL1ODnOCmwSCO7tKU+v7/CptTcBGmyz\njgyNq7HDUFQ4WlUPvM26+BNLhUXdhnvOY5TJHOCsxROpVVOdv337AEV9bh0L+8sCGFNjl1osWmyz\nv6datzh3epdrO56cZopjfIMpQdqBkmQ9Ydxlfv1cO8UlEXriz5eLFDsfadM75/m6vTinpcvmfFqn\nyF1MEUKb3CYYUXQkRAI4BlY3IJjCw6e6WafFkc6JCJ+bbrGu/Q15Vg8p57KZ2kH/+DO+RvKvXvo2\nulcdNgvjhbMUyaeIqUE3hcorsl3//dat44t2mQS2Px4ixJ7lky+8yo+e8Ofpr/7ej1G+3UKq8CAq\nnXecaeDvOh+hzkesNmbWB2Eh3YPeFX9e21cn6N0RMp5lba6VYrve05pOTLkSM+0HNkbsxwPXjrhY\nEcquowqYp80MkhnizF9XaVotYJ7gcc0qFItqRxnpuxej5+34rvrSlra0pX2D7JFGnE4BF/wT/pOn\nL3GxfZON2EeadURZp9rWqQY/BJpocgHXdGrG5zxSdQcfneiwjTqCuRvl6DbaUthencpbKX2VfW7/\nSiw9PVncTtj+Rjzg2zbe4o3WCQAGZcaxaS+5zWadQk3oF/tLy7YTxDhMy0dwo3MZo6dKNuMZFp2q\n2f9Lp8HCWHwkv6JzMikXznssMyJaEvDLco7GYhx0VN1i6djUhwtHm7uogXKMKGKpOJt6OlTv27c5\nvL7B+sv+mFwrQaaFTxUB144Q50i2fUdbuv5oywSP0k5sHPI//tFfAqCtpryQTJqOrL9SKR/th05b\nN/ERYGiww6mQFMzdVvPtlPEI+m9UdF73552ihDShOuNbPKcbGfmapljx61hHlK5miYmnIplu4IF3\nS5RyJHFo0dYW52ZV9GQO3wTQyi1wOOsuQHWXlsyj9mhXvWX5iZASXchukUmJDZhDGQ4luctXa8d3\n1MxdKEl1oeioQ2wI83MFiOa7c0513unOvz9PN4pFL2CoGtfs/2R0yDDNuDTx6ld1SnAszTkPGtVW\n97Phiyk2VpQrfmUPz2tUp2iwpnZUosSxXfg7sKUK1uJxg12/nJ8mVWXTQNBWUy7Eu02xB0DhGqzZ\nYIlx5OF94+CUHnPdtAEY2JiC2bVkA8+zpj/98JmX+fsfW6N3OdCfhgUohZgZH9FmEXrgaSt1yn4c\nbUvn/Fjb/52lM8TS4u3KQx6ym9C5vMi7nL9FbRxS8/pt5x1nfYvJob82qtVQNFzpM9nQ5Os1z9O3\nddad1um+o3vZ0drx96RUlnIlYrwZWm3XIsqOo+iEVH21Im4XzfN8GpZp1gBj0UoWG2KcMIeQvqM9\nUsfZTaacDBGmdzyLjql0UeOIYqm8I3OLh7hQNWdGZK8daO38DEIxx53029bN+4kYYqmayCOTEsXM\nsXr80zWOHTEoLEnA1go0iTOY8P06Go3D9tfVEJMo/q25CMDl7WMsDeksbuwzCUSQKIKAeTotmFbE\n8LRfx/E5i9aWJPLreHm4yu9dO8tkGDqLrEChiHdDUU2g2izZ2PJR4/n+Lj+1+UXOxh4jPaMHJGLJ\n5xoRYnHsmhDhujh0hHkr8FlEfd3EUtFRNA/Erp5y5gO3GJ7ZAiDd1bhII3XEGWtPgq975Q9nRavj\nZjKfXYX/Xw2gYu9ritVXZ3972dNMe4piNWSMCZhkMWixySKBvWrH1CFk1YWy4xqRkOymkO04qlDs\nmWwINhY61wNmeX2IqjqMtsJ1I8FZZ7PWIms0ZahZZqkljavbIsm642y+8+x+7BiHQUtb2tKW9o2x\nRxpxpqparJ4SN1Fn6TQa27y2KHIbN51D4HvJax7n7Z1E/v91Z0/uEvaqDgfhCXljukKkDJuJTzXO\nJbusR0PiEEEaUb6XnRnGEWOxDS+xprGE43G+4m7C8WRSLsAGGsuO6bKb+xTR2vdXh8kDmQiS1Dpr\noctmLrWtWpp8M0Qi7QpxwvaeT82tE8wgRh/WHSi+gyQahU07KMcJ+9seK761sgofhR/f+DIAnbSg\nrWaQjxLHwMa8WW4A8BuHz3B10udE6jfY0iW7RbvRGNhMBpyMDxfoT8+sbvObT/uIc+XtBDUukMOa\nGAeSVw2WK5PZ74+zWRwa+Hx+AYD2tkUcJNse489uOFrdhNE5n2kMzs2k95ptJA7bDff3SUPhpKH7\n4upMI9zfJUzXhcEHfWaydvaAw2ELG/v7aWUlYryp2P+Iv85Wn9hnM5s2kNi0ihjlSQMJARgrDVau\n4Ug11gAAIABJREFUlVuIGkWcl5a7z8jzkTpOJZZ0znFa5ynoMKMDmbnUO5NiAdu0qAb7mv+s354X\n7LhRrgBwLe+zPe0yKHwo309ynl25wenEg9Grekwis5TNH4ta4E/YhUKQayhJ4KEG4+Q2MKRxnuKP\n6VzX728lzXnzQU/Y+9HE963Xqa2elJgso+iHO8QI5jAhO+kd2WZvSLRlmVb+UjzVOaQf57w59EWC\n194+CWbuPFfCtdEKN/qe5tXTEy7Et8iaB7DietXns4OnAfj3159ilCdUgTZT7makt3RTxDBbBWsn\nBnz8pBdn+XDX/zRPeHCt7CTE7QR100MDalyAtdggk+fSb46kTSEYZxuseXxSEQ8V0y3vyKSyqMqR\n7nlHV3RjTCpNS2StU5Gt+vO63vPrX4R1H05S8kGKqXvZex4/rfUxDw7a6MhyeNFvf/iEgpM5pzf8\n8Wy1B1in2J/6QGlkFEo51FyzhLWqKRbFelHwpzCa0qiGx3kve8QlQWE6V1wBFjDN0kUN2BxLxYHt\n3MazrD9fOr1QaZ3amKvTVb526CONg2lGog1P9vwFf7Fzk9PJftOLXu+/dsQ1dloER6qdwzKrsmlc\nqNjWRQgJXNKZzb8uXcSH0ms8sbXTvP7nX/d5e5+ZMf4fXs+ySoWqU/c4C047+m0fqZzIRrSjgiKU\nXCOxvHa4wcHERy69tTGxNqxkft16yZRz7f1mV77AqBqmdXyENaGVJR+mM2Vi8dw/EyIfpS2TacK/\nv3IBgK+2t+inOeur/sY2SfCwgdAvwzG212kI/Y0g8zE3LQrjLD/avgnAb/3p3+Yff+bbSQKBvXPN\n0b1aUnb9eepdKuleEwbn/LruP+sgciSBTdGNC9Koah6YrbhkP64YJX7dpy4lmgg6D4HUXkKZWdSK\nD7w6Z3JWsilpwMoPihbTKmJcBMzUqgURDyXO96vX97M4WlHZBEc2RJv1/S7LXvWlLW1pS3u49p6R\n0GYRW6Aj2XQhgiydXqiCx2KwboZxmvD/Wp3o0niNNw7XGU/9643uiGf7N1mNPHZlEV6dbLFf+tSi\ncor1eMSpNIT60QFn4z16sqg0P3+8MKu6z17PRTgC2VyEPN87X7rjy/fDOlweZGyUQBQ19B1EmK4p\nbC9UYI0QdUtK49fx1qRLrA07I78uk7B+RR56wxUobdBBxm2rPcA44Y2JzyzWoyEn9eC2dXki2wXg\nu7dgf73N5dFqOBzHoEjpxv54PrJ6lbPpfvO9zx+c5/NvPUkU+IDdjqCGRcNLZVogxqACv8W+k5bn\nMTMtilYgDP63pz7L9/yHr/Dn/8mfBODk7xl2nkso/Glm63cs8UHJ5k1/P002ekxWK4rSn8dJFRNr\n00R2rahEtWdR3mASUaFnI0wEUG5BU7OyClPOoLui0s11VVWaKDJNR1Adbc7zNCuniGSWus/HmI8V\nHQmO9IAv9KXrxVEW4WczCkNCz3hI9S3CQdXieu4xzatDj3mdX/Op+YXODkocrwx9D/L10QqHeUo+\n8QtfDhMwwvkP+NTjz5z/d3SkWOB9mrmhJkeJsYmzGHEL5DV9h773ZntyfPl+RBrpeMeHc7iqakQ+\nqpWM0TmHbvm/3+QRSTorqAymCdYqDg89NmUrRaef8+y5GwAMi5TL19e4NfXFpMootHJMqyADpwzf\n1nqDfsCyXq+6/MHkyaYoOLUx29Mub+14Oth0lBC3SsYt7zi/Fm0SKct6qEadyg45uX7I9W1/PVUt\n8QT4+kGgFDZLcNpfj/fI6I6daalrAo4faG3zvd/pedlffO2jDC6aRqd08GTEiS8VFP0AaYTe9PkU\nuDSaKtzfkViyqGQlC6Id/YippFDNJcV67t40ikkRL9CL5ilFtdOsMc3aaUZzoh618wSawpC5T771\no+0ccjQRo3UK5pxleYTgrsWi5pxY7Vjrz01MzKDMGJYeg4q1YT0bs5n5qvnNaY9XdzfYve5vAH2g\nSfYVve1akBZ2vr3ij5z9IgAfSq7d7jTnrK62xU2nkkPN9a4b5Lbv3OnvOo5WrMVc/o/OAxCNHKf+\n+aXGcRZrCeVmSTs4y0p7HqcJLANrFfu7HeLrQedUoLya8MY0OK62g5bDdUJRYJRRDhPU0J/X342e\n5I+dSEgCn/b3J+f5zI1nmxtgVMTsXl4lu+Yv9eyjA06tHlKEyOTqcIWDIuOZ/s3m7+nGBaJnupNS\nGVzhHa1kKVIadK22tPbNOTYkFk1fWvzXpz1y/5M/+CTZF/rNg6TswK0X2hT90PmzGnrBgyK7Vl4Z\nLZrL2EqrG8zyZH/IflI1gU6NP0otIO2EysyJZ4t3jnU3UKS9Y6xxTsH7iNpxKvx79XUytRHOSVOF\nt/d4IC4xzqUtbWlLe0C7Z8QpIk8AfxfYwieun3bO/U0RWQf+AXABeBP4aefc3jttyyLNtMj69Xx6\nPs+hMqjbWiINimmovk5MzMTM8I1UVyS64lLAsl67vglXWqxcDvy+Elq7ljx0Nhz+0ISf+chv83zq\n6Scjl5Bg5qr47rZ2zXlTOBSOUupWCO4cscrt6fvjYA91XTPH4UcChlkoTnzpBPE1/5Xh6Yi4PW4i\nThNXGKsaLGoyTsneSFl7eTaCobVdkr7lMcrp+XWufVdKOfVrXTqBStBBeX2U+3WrWyy/PDrD1d0+\nNkQj1WGCHmqmWyESqRQHk6xJ4ZwTDvOUS5FP5ddTj4lnQVVHlS3fp17L5rUyHxbXEWf38cKuH+a6\n3o+tB7bBT37gK/yfb38HaVCLKrtQrM6NGIkcoh3tMGWyFZW0o6K553MTL3Cd06hitZUzCRHqtNIY\no5rRF84J1spsQktkiLUhqWcMKbsgDWebSHLG97VOFiiHQBPF3ovPeT+rXgF/3jn3BRHpAZ8XkX8F\n/CfAZ5xzf01EfgH4BeAvvtOGHDInRKwbCgDMOJm1s1TisCymuaXTDW1lYmIKqxewR+uEGwOPhbkb\nmZ8xEmSu4qEjGRj2nvE34Pc//SrPZNcYu+DIbRAznSO6H23PmneMFkHhmlk49qi2Xy2Pd0+Y+T2z\nh7auQDOG1Rlh70Nt1oNjmZ4QkrSim/riUaorpiZiVIRGBUkWcMIqE/L1iOHZU3574tP19lV/Hoex\npv/0HnvKY9vdpKRAsx+ui72izUZ/yO4gTGg80KR7wsa/Dq22h8LOh9fZv+DfLlcN6caEcRCwrXGv\n1UCXysXvR2reZqSpVjKiQ1/0UOU9crpHbw91Xe9lmfjz/onOG/yzC88z7HusW+/EKDPXYhk7sLLg\nwJS4poVZiSM3MVMT6IbG+4c61U4jMHOp9XzNCOpRGDO6URSgAHfEAS5ioqohzNf+o/7+vVLxezpO\n59w14Fr4/0BEXgTOAn8Y+P7wsb8D/BvusRDGqaaqXVstLFvZuiNoToRDXINz+uhUms9VwWl2o9mM\noEiZWSShHbI1ZRjUa8zXEna/RfP8C28Anui8bzpkQedxNR7TkfI2ZxkfiXrnn1B2rje9wTrnsFCD\nNFjY42YPc12lFPSNeoqlY7IlHIaOqaLnSJUl1R67Ot0+JFFVo4j0WnuTl6YR1zfrS9HhMosk/v32\nSo42isN1jyVGvZILq7scDvz207gitzG7c0WGp1Z2SQLWdXO/R3LgmITtOy1EE+he8ntTb2h2P9Kh\nWvHFIeuETlywFiLP17JT4BzmtK/iizG4SDCdoBd78Hj1qj/Mdb0fi0Jws6rGPmKs/PXvYi+84uYK\nOjKHbU9N5J3nXJV8PsqrrFrI9yJtiLSvnPu/TRqmRbP9uap5ZdWC2lFdDGq279TC/mo81Nxnh98D\nYZwicgH4VuCzwFZYJIDr+NRgae9DW67r8bTlun7j7L4BGhHpAr8C/Dnn3KHMpabOOSd3odqLyM8C\nPwvQ3upyWNWK6berlMz3ntcR5ztZpktWQsQZKUNhI872PC/zVtrHlorz5/y44fFWzDPdQ55dCTQX\nk1E6zamgw7iqJqRiFiLKOKjEw7xO6Ds/kepj1rjFeaqPqT2MdY36a0TDgFWdMoyeMqjQwWHTxXQp\nURWr8YRziYfXWrpkUsVc7/iUWGvLanvCma5fR+uEvWmbtVP+nh9XCV++cqahNLXjko6aNkr8qa4w\nTnhu1a9z50cLdiZt9kKEenO3hcpdAz1HQ4VLTdNxcqZ7QD/Om3Wu2kBV4cKsG9uOiYZlM4625nM+\nbvYw1vXJs/eP3zY6t/UU2/qyr29p5THOusVyVPhosBP4tCp06dXaEXFqKK1mHHiapdEL0aBWbqHy\nnUSGeC6qPNoJNP/7+uf8dTkfrd6P3deZEZEYvwh/zzn3q+HXN0TktHPumoicBm7e6bvOuU8DnwZY\n/dBJV9OHovBH1gH50YOurKZilhofPbGdqKATTelHHovq6pyxSRvCe/Lhisoq1pJJs30ltikotVXB\n+eRW03sbN0T7WertRwzPzDhBvUPB6GgxyeDe8fPvtT2sdU2fOufyJ/0N8MQTO1zb6eN0cJyxu619\nra2KZv78M9l1Nk4PuLXhsempjTib7jWtuQrH1ekqo6AYocSxuTZoGh168ZRNPWFgW83nW1HZnPdu\nPKUbT7m4ug1Afibm+miFUTErLH58fZuLXf9ndnXOQdXmWu7pUDYC1+81OKxVgkxKVD2czjx+D8aH\nta6ffCG774vXOF+4keDcxAHKzWTetNd6qJ1VXkZURjENM4FWswmZLhccXG7ipiWzcEJldIN5RlG1\n4Ph0cHzNtXaHAOdo0DPvLK0Tj6s+LB6n+EfV3wZedM79jbm3/jHwp4G/Fn7+2r22ZZ0wKMN0SGUC\nOOyf2JmuFvQvcxNR2GihCpaoin7iHWdLF/SjCWuBuLyuh2TJjFj9qe7rHJqMW5WPZHIbE6uKdR2I\nzvE+m3rQiEPcycEdvSXuFAHXGK0KvezzEeq9Iub30h7muopyZH3vCA8mGfrVNuH5hYscxqgG9LdO\nkanZjKETesjTyU3idiDIo1hVOdcr70ivV33aesrQ+Ovma+PNhX2vpWPKuckAqa5Yj0d8MPMR58im\nZDLbH8CN1T5fGp71x1tkXOze5FOdrwG+w+t1TvLVIhSnNJSnekiYF66mFWo0mRHgHzPH+TDX9X6s\nJsRrscRx1cwjd1r8gMIk8Ci1RbSbq5wrnLiGTzupYhJVNZXwyiomVUweHGdlVMAhZ/eUPjJQbf4B\nfTQQu1OmGKkZV7xw3inX2gP34nHeT8T53cCfAr4kIl8Mv/uv8Avwf4jIzwBvAT99H9ta2uNjy3U9\nnrZc10dg91NV/w3u3rr5Qw+ys040q0DWEYiKa9deESvDqPIp2EHRYlQkzZMi0YZuMm2qpR1dEItp\nFNw7quCEHi7MNjeRUCY+IzFhZlHdOx6LWUitSxQaN0ePulMEevtpmKcbWSfN9x7naBMe7rq6UpHf\nCtMI9zUnv2TIV0PKo6AsdUMjsU5uU/5Xc1hyR6Z0pOJUmHqaiCFTJW9Y3zo7KFNKo0mDyk4vygMt\nzG+zhmpqfc11PWTftOkpD9lcjG9xEN/k2ewq4CNS69Rt46TrzMi0HPtPZ/Tf8BF1sue3K+XjiW0+\nzHV9EOtIQS+bMoi69XHgIovULBcrODuj+9Q/a97kzUGX67bXsGLagR6Wh972soxCv3kZvq8w0PiD\nWB+hD4ojnstgTVBLqnvTa6pSNVdXSedmEN2r9fKRsnc39JDn+tcBeOXwJIk2rMTe0aWqYq9ocXPs\nU7RBnlKUURPax7HXv6xD+fVkTCymwcpW9agp8IB3hKWN50ZhGBAzExVxmhIWZtfAHeYOHcFg56GD\no4T3BUfslG/reswd6MOwaAwnPudTroOLHl5KBjXWBNZoJgHkn1qvmToTb6lQ2CbtUuIo5i7mTEo0\njlulvyFvTbqUleaJVV/U+0jnSiOsAtDWBXtlu2msuJhsY+LdBlJJxHImmrDlvCMtEQY2Zj9gpLmN\nyW3M/iT0zseOwQWhtRNmYl2uoJz14nOH2dzfjNZTBZutEdcS30jgHB7XnDs9ohxa17xMg1a2Kcrl\nkwRrhLqfZJLHpOns4WStL+ZMpXZZFZG2C+HNvONUeLzT1kMalW3gwdrKueusCLzRO23rTvZoFeBF\n8ydP/BYAv2i+f0Gd5NJolf28xTQ8YYxVPlIZhydOrhnFbQabPhLYygY+4gzYVRwI6/NRYSZV4yhz\nFzWVV/CiyEfJ6fNqRvXM9ZqQHx8V8DjSKVTrdS5sT9wDzzJ5P5rOLWsve0c0fLLN6LQmGoUHzkRg\njaYielhmdKIWbeUjip7KG43U2koU41AcOrQZA5txq/CO8/p+D60tp1u+qPd0coOekgWd1f2yzY7x\nn8+dFzle135/FoihWauj/HUlltJpDob+Okt3AoYdMM4m0mwmAxz/B+P92LoyPN3d5svJaQCMEUQ7\nVN0YoYQkqeiESHIlmRJrwzQNs6iyKbGyTa95aTSHedqoZWltQ8Tp96eVI4uqhap5rEwTKVZOEWGb\nYjL46PQo1ll//n7FPWpb9qovbWlLW9oD2iNvtP1U6iOJN9e+zK9uf4JXdmZV0nZSkgSl771xC7nc\nYuNF/148dmR7jmvf4Wki01MRqSqbSENj/dNk7oFSoLhU+lk1V8s1dqtO816myoVUP1OlTxnDE6yj\npgvjhRWWRMyRVH4xrY8x2CPY6ONMR3pYJvmU5JJXum/dbFOswOicf08XUFYzua7KqkVdVRTGqabl\ntnSqifYhTA91ikGgsVWVpteeshJ5iCcWQ08l9EIE29U5gyrlZhihsp+0wgRT//mOsgGi8cc3thH5\nEa3UoUkp93zEufG6xWnIbviIOgzr9uk6gH28qurvla3rlOfbV/lX7WcBGJbKR5x15VuELCnpJn6d\nYm18FV1makV13QPgZHuAVpbRJHSkOSHLyub2rjOYdjxrlZ1n5RylOd6pyl5ZRRmuS63sYywrN+dE\nfqR1jf+9SprU/NzqAa2obIabTV5fYf0rsP5lPxbWxRopDdMNf8OtJ6MG/6pt5OImpS6dZmBbzQ2a\nqpLSab566Gkm4yphNZ3QCSlcL87p6im9MMi55hrWUICntBTEzm8/ERPmCgWdUISMkmwu1Z/HUI61\nOXDDQAt7ccqNT6XYMBpWjOByTdnx6zAsUgZJymYy37qqGp3VRBnM3CA+i2JVjxuNgnZ7ynpr3NwI\n29UKr6vr6LlZUJ2oaG6cjhQosSThBh1Z1RQCoR7KZxoYZ2xTdosOyS1/vO0bU6qWRl/xjRRkAe5p\ncsbjLxt4P5ZKzIfTK5zrewjllVGGc+CCI5LQZ14T2sdlTF5GHBz6YEauZGS3hLLr1+VrTxZE6Yyr\nmaRl038OXi/bzGldZDrQzZrlMAsEePA4ZiMbh+dt1leh43apuneyR+o4JQx8AljTbT619iaX9mfK\n3KMq4dKbvif43G86pivC9id85NDasVz5Ece3Pv864OdfZ6pshrmVLgpzi/zrgW1RON1UV3t6Quk0\nX3ZnADjbPqClS67nvhh1ebRKrA2rgTC/kQ7pRxP6ekawX3GTOT7glASa/ddD3xoeZ6gUv5PC0rEx\nrRriW3JzhJMZluwEMNIMS4NZM0NthdNkoSqQScV+WDv/ugSBKBT9zvUPiJRlUPmIcGQTBi7meuUz\nkbFNOJkO2Ih9Vd4gKGgKTiVqQRUnDk66nj21b9q8OVwnOQg3WKJI96a4MHxOrPWk92VR6DZ7Np7y\n7etvAvDW7lpT8AHAaEZWNQrwWluKaYQpwnWxXjLcdOhk1oFU5hFJu2w+b0L/OUAcVwsYp71DkLLQ\nm259ZlOrctXanfVrYxUirmFr3Mu+SUKipS1taUt7ePZII86xs+zYEMFJzM+ufb7pBHllf5NBntJ+\n0z/5ey9u4z68zpUfDnSiXslHz12jCpFIV0+9NF3w/bFUZFIxcrNhzpmUTQ9tYVP2qk4TaZxr7dHV\nOSfCnPU3xie4Mlrl5shXY1+TDVazCU90PO1lKz1kIx6wrv3nlba3VeZVmBUPHhP9prIk/N37A3Sx\nju35J7dUEeIEE1RtijAuYVFecF6joObBzmY3DWxrRkOLxnzx+llevemvm61nDsldwr/e/RAA+9MW\n337iTU5GHuLxXF9DWV8nWBCYNvtXHNqMcZ2qm5S3b64j6/44hqdjNl+8jisDB3mqfHoepniilrFH\nbSsq4wd6XwXgs+sXeOXaSUxez2pSiBFq/oRLLFG3pLc2br5flhFVGXJt57U269f19VOn6pPIULYU\n6+1ZS/W8Ha2eK3FosUwCJJRGVYNzAmRRxbiM2X3J10TqscR3s0fqOC/l6/z1m98D+Fkw51u3eLLl\nBWu/snOKyTglnAduftcGhz885qNnfOtcN5qynXeb0Rg9nbNbdRvCe+kiShdxaH0Kt2/a7JouXxr4\nKsWgSilMxFbmU7iuzumpvCFjxx1DS5e8FeZ5b486XDnoszP2GMz5founOhE2mWFvbTWd8UTFepJ9\nuEGVs83vj73NXbMuzzn122NM4rHqsu8wsWnmVYu45mIFn2IVTjep+b7NFh5GsXj88UqYKbW936Xa\naXmaE7B9oUcshs+9eR7wWNiH+9caQnuNNdettTXWWTvS3GlKNNuhNfel0RbVKCabBuxsv8IdHOJc\nTdwWSGczh5Z0pJlpUbwQoK4f2HyZS/urDKfB4RkhGip0HsRTWorKCoP6ffFaro1ICIByuOAwm0si\n/KxEUxYRVUi1T/aGdKJigdA+XyyaVDGRzOhO4Ntz6wfyGzdOsPqZFs/+S6836IqC19/hb32kjrMo\nI371ix8HYOVLCf/0WwqeOe8J8eutMYNxxuFz/oJ/7pkr/KHVy+yU3nFt511OZCO+tf824LGra0W/\ncXw7pkvpdCMOMbYJXx2c5nNvPwlArzvhwxvXOZP5CLIu4tR8wrYq2IgGnAlTL39t+FH4zVXaL/vP\nvfT8Bm9/7zYvbPiOk/OtHTaiQVOVryvu89MsyzmHcKxNQNRMYDZ66W3O3/TY9ZWfPIU5VzVTzYxV\n5HPq/bmLwHR8sQ2ayK8XsOXSRf4hGISJ1ctd3GaFWfeff3u8xsTE9LpBeLiI+fL+GX6k74eI9VTJ\n2EaM5tbF45rS7G9kU25VPtN4e7CO5KqZrZfuln743Ly6kJIlAf4u1le+ceBHu1/hsxtP8cXxEwCY\n0uKUmmlviI/qZOKvA6dAIoerI8dax7P+gvHfaRyoAlcp8jAZYJgmpLpqikS5ib2m51znUOl0I+4y\nzlPynRYrL/nr4uL/uwuvvYS5zwfhMs9Y2tKWtrQHtEcacapcOPMv/C6nPceZM7vNVDuF48zaAWrd\nR4Qf7G2zU3YaxfenOjs8277OSug5vlquUTrNjcDX2y07DKuk4WEqfBfRE5te93GrNWArHTQRZt0h\nND+649d3n+EL//4ZAM78pqH74k3My68BcP4rF/ha+wz/7jkPBby6usnF/jbnW56/uBENFnqwD0wb\nJbap6hfHea66Uk0EJlGEK0rMqz7Rad84yWhO0cYFikg9O2poMsq5Di/w6XnN6zROGJqMpzc9Hegr\npzLivagZH10Yzc6002Bf1vqKeZ0JGCcUKPZNGOmgRxik4W7u2zZXyzUuT3yr4PagAwqSQTiWG4c4\nESTQjpy1XhGpiTSXqfqd7NlY87H+ZV5ue42BkRFMWzWzNFyQmVMBS5QKqg5Qy9Al1p/iGuoSUNo1\nmYstFSpyzdTMymhG5UzbwjphUKTc3PX+IXqpzfqLhpVD//mT14bwxpvYgV9oG9ZYWq3ZHzGTvbjN\nHundHA8tSTjwqz/meKE1ogiOMVGGVFfNH75ftthKB5xOfOp8Ltmho6ZNKlzfGNuhFe/SaI23dteY\nhtA9SSr6nQmbbc8v7EQFSlzTw3yr6vHW5ARf3PbyYvtfPcGJ33ec2/MONV/T3Pi+TVbPhvHCb+/S\nvu7YP++LT1ftCoNpwvaK3/+TnV1WopxhGEZnnfCD/Rf5eOqhCHOc76+j6Y0S9AmPFScDiy00Opk9\nVOycaHVpNUo5rhU+tc9UyVo0ahzdNPSOn237B+rk6ZjLO6ts9YKYRzrhZDporqNsdZfvPfFqU3ya\nhuJT3ShROu1TtlBE3DdtbhYr3Ai0tMkwZf0LipO/7R+I7OwhSUID0lYVLtKeBO//mHd//o6hpRL7\nwl8gqqvIYiLXjNJw4iUHG0FoAy626G4IpJQFcc1oDRfmAdVD+EyhMaWjVEGvU1uKSDeY5UGeMfjd\nTZ7+p94xyktfwo7GYP11aJVGtEZ1QlOMcw/EyX20PM5pRdUOs2FuKX7fPUHvhHdsq63c964G/T3n\nhM1k2DjI2uar1YWNeH3geZ/7kxZVpbFlOLFaLQglWydMTMzv73lH+fJrZ+i8HtO56t/fGlmqTDh8\n0u8/PyHkpw0HYbjb1u9soQpQcajurvgbd1L5969O+lylTx6wu+/beIVPptc5rRdnLB1Ls24WgYmA\n0hCKY9HI4CYa1SqbjxqrGoxzaFLGNuGg9E/6WvWqzgxulR67rjOJzdaQtTPj5jzv5B368YTvOuEj\n3FSVnIoOGl7mofN6nEV4PbKxJ9w3r1P2qzajMggl30zZ/PwB3AiE9yiCqvI/6z9gf4DUxaHoGGcS\nX4eZpiiqSKViMpibOy+OOvGyiYXIec1O8EMVFdiqjhgjXyyqak2A4IBzf97TA4XTjrIXMpd1RWUU\nA+0Dl+GVFT74L0fwB6+EfQuqM7sXfWZULLxGCY3KyD1siXEubWlLW9oD2qN9XFpD70VPP9L5Kre+\nJWEQQvGt3pDNbMg46HHemnR4Y3SCU6HK3XM5I7vYIdDR00b9RMSx0R9iV2ayb2vZhHbQAN0rWvz6\n1y6y8u/8E/Di749BlUxO+idUvqaYrgpVgDjKvsO1DdkZj6nuDvu0r7k6kOJCf5dhmS4o2O8XLZ7s\neEz1+zovsa4Spu7x1G18qCbM+IwiSKRxeWg9nVTocUwc5prXc6/HIVKPVYZxM7X8MnA8axk2TGOu\nAAASgElEQVS5sU0obERpZ2nUqWzAB9uepnZlusZGPOSp1Ouu2tD3XrdQahw5cTNaY2AzFDP2w17V\nYb9oNR0k2S1B3TrA1ZGHWVTFkm4bt7PnK+tw3xHKN4vpufPxg92v8ov59/nfDzRmYzZHXQpBpqqB\nMG3k0AONDq2uqhDEeVk/AJPN/g8wPV2iO9VsqqYT36k0CaM4vqqJL+1gkzDWuSiQsvSwC4Ca4dYA\npKlP4+8zg3ikjtN2M8ZPeSxreDZi/KEpLzx1GYCLvZteEqzy4bRFuDXp8trYg8v93oREdINRgifB\nbwReZy2zn4ViUysqyXTJ7tRv7+WvnWHjtyI2f8c7bpwjP9OjZgs5BTaBqhMEVruGKKtIY59iHnQc\nZUdwZiZWUVlFGTDNdlSyno74ob4nAF+MSiDCfjMQ4edhPq2ACIyHMqLdEXrcbrCuWjy27j2fmggl\njvXQiFBZjcKxEfvXnzs4z9VRvxmhUBrFW9EaV8Nwt4+vXmJsE/7tgSfAbyYDTif76NCIkNsYLa7B\nPOue+IOAod4quxRWN/J/3SsWdzhAQlrnSrt4M+VT2NqYjcywFnbf/Sk8jvaJFEj9g6f9asTolMUG\n3ma6o1HFrPbjFMQjGhpY1YHpmqMMtDNSg04NrVYQc8mmOCdMAr1okseUkxg18NvvXa68s5xfO2sh\nnnutZ5AS7sHaaB8tj3PdceM/9aWqpzZ2+EOrl1mLPcY5tTEDk9EK2Na5UAy4MvaO9kQ84nRysCBE\nbBG6IaLsJVMOJlkzzbDTmrLaytmf+AhTjTRiwbb9E8ekmulaRNHzjrDoCyYFW8/wUj6KnQZRAnFQ\n9IEQIV8Z9huBEvBqL59Ye5uPpZ7nmUpCeVTD8zjbvEqQktkFemObdP8k4yK8bgeMs6pFPSpOpONm\n6F5uYz6//yQv/8ZTAEQjwWSOMKsN07bQL9lr+XV+bXeDlWzazK5JtOFU55Cnux6jrKdp1tZWU3IX\ncxBSi8JGRMpyOPbXybnXxv74ww0n4LuiQq86xiB5MSsWLe2OZpwlFt10BnWuxpikVRfVyXYcNvH3\nHPigpZyJl1H2HOVmRdr3/kIpX0Gv9Twro6mMakQ5rNEw0SQH/nX78gCm06bgI1Hk+bi1Iy1mM6jq\n9+1oPMOu72H3nWeIiBaR3xORfxJePyUinxWR10TkH4hIcq9tLO3xs+W6Hk9brus31h4k4vyzwIvA\nSnj914H/wTn3yyLyvwA/A/ytd9rAZmvIn3nuNwGvtG3dYq93WxXY8CSPrFf5vjHxu/vq4WnG3aSJ\nTIxTTG3UqOasxDknu5obLozeGLYYjrNGqp8TUw6fzkgPfaQSjwz5miLfCBFs12FTt4CjVKWmPPTX\nV2sgTNctUez3tz9sYyrVvAb4ltYlNnStlvS+SdHf9bouYJzGLkRsZneP1dcqxh/357moNK24bDDF\ncZVwqjUgDTnaTtXl2mCliUxUCSYVJFCe0lsadV1TdXyoMuo4hgKqlseM4Kra5PPxBwA4e+EW37v1\nGicT37uuxTI1MYch4iytpjCayVWPqUaXLnl8s44osxQXaWTqIx1XljCdizgf386hd7+uD8FOdHzE\nWU1X2PrdKXvPBk2AM1C1LRJaLE3mUKXHNsFDZrq9WB8wRjEKivDCIkJkCoWeKFo3Ao/78rbHn1VN\nG6sxgPDTWdzchFIRAWtx96mver9z1c8B/wHwV4CfDyNIfxD4E+Ejfwf4y9xjIZS4hiSeuwjr1Nzs\nGeOJz/W4XeUgnhWD3h6u8ZX902y1PC+rE00X5vm0dMnp9iEbmU/9K6cYV0mTwhmnuNZZ4Xrmr6P2\nVQ3/f3vnEiPZdRbg7z/3Ubeqq/o53eNhPHKCsYwXeUEUCWXDBglZPCWEiBBiRzaRwiIKhFUWWQKC\nrVGyQEJYQiCSrBBCZIGIEtuJ5WQS7NieJHanPZ729Ez3dD3vPT+Lc+6tW/ZMustTU11dcz6pNV3V\ndes+/rn/Pf9bncDADeWyma1McVTgMCE58qb8ukW3xs5tO4yde8QfQzsZ8Mvp9aov5N2GvS0as5Lr\nhPKIjAsQ+fdMs0n7f69R/LarJc9XTDU4q6RXJFVpLcBTW2/xww+53/d315DcIKtOcTU7fS60j3lj\n37lw7EGGtPJxfmA3JtmPaV53+99NNhlsx5WP02Dp2rRKhzKi3Oyv0HnNP/Bu3UayRjUvXRs+uFD5\nNHXSTF+w8cAwQ7nOgE7q0gn3E6HzkwM6bZc+ePSLhqJTID2v2IxiM6qYgyjYg5RB5H1nkSJZQZw6\nxZf6vOCi7J85iJCR0N5z72u3h6RJZXrbfg7WYg+d71zSxAX+Ev/9qkiaVgnxJ3HaFeffAZ8HOv71\nFnBLtQoZvwlcPulLTK2zd0ZOIbUBZ9UMGD9cSa1rkOENil4z4drhJlfvuEbEnWzAZtYli52vIjU5\nzWhUNSZumBENk1cVKL0iYS3tcdVf6MN2k+QwwveCcE86HUf5pBBMDnnLH9/2AKxU3V4ksmhhXDUD\nbnjcxchifFCioMAufgOImcjVFR7XVmAiY99So4EeHbH1LT+s7WmhN0poN8b5ucd5WkXNhzbizqjB\nauZ8W8OLEYc3V1AfLe2nCWubPbav+GDSZcPBoMX+Had4j02DUWJZ+7C7AX5t4wbXB6vs+FKgvdEG\n+6N21U2nVyT8ZHeLJ77tHrjlDUStiYcMR+MoehyPAwoA0UKuOGck1/untAhLC6Lzkst+WNu5xOHj\ncXXfSyFITtUERCxoDHnTL2xaio210gcluY8zSC6YEWT77v53K8haxVp/gCQx6rMkRGNnJfnXZRMX\nzU+XBXOij1NEfgt4W1VfONU3vnf7PxOR50Xk+aOD0ckbBObCLOU6tN2TNwjMhVnK9cY7D1Fwc0pO\ns+L8JPA7IvI0kOF8Jn8PrItI7J9ijwK7d9tYVZ8BngH44IfaWs2v9gkjRU13R9hqRWrUVq3ZAC43\nb5GYgqvvuBXn7o113opWq644m60ea2mPLPLpSFFMMxrSMOM56jvZHboXXCnda/YCwywF34Ha9IxL\nSfK1slIIeaJIs/SNGFfJUJ7XIILEEvm8xO30iJYkE5F0I7LIq86ZyXUte0Srssu8mCzBjN2Tffs5\nl4/7f7/SJv6Fw3EU3BRVJxtwUfG0Nq1wp3OHjVaPd46dbzrPI64dbFUukzQu6A0TBv3E767g4uYh\nv3rBtQcrZxOVlsztvMlx3qDpLZPXj7ZY+26D+Eeu6xaddnXMAJIXMBhWrge3wjTVCmUBmZlcP/6R\n7L5PsuUtQo1Amyn87AYAF15aZbjerkZliBWkAF/QRZ4pRarjdMGmS0cal2C698tKIwohGgqmW1uc\nGRnLyTgfZlVy2R9gmhk6cJaPALKxRnRpm2oHP7j3eZ2oOFX1C8AXAETk14HPqeofi8i/AH8APAv8\nKfDVk74Lxs01wCnNxLdrqBSoV5YWg0Vp1Mb/rkU9Nn360ouNR/nx3hY3d52v62a6StYZsN52q5+N\nrEc7GVRtppr+382G+/vh2h3eMStVfuGoGaODCPGt+yW2bq5J2do/N84bbUvbQkmaoyr41I76JBIx\nsOPzMyKYBQ0ezFSuWiu5tNaZP6WpHhmIY+SWM61XX1mnt5WQlM0ZYoMUET1/xzSsaw22kZUlmkIn\nHvDhTfcf/OZwhX4Rk/rCh34RM7RxJee1pE8n6bMROzmvxV32huvVXPeRRiSmoOfzm15/5RGe/OZR\nFTSQlRZEpuq3KXnhbj5bNjEp+0c+BHKdAU+sONP85fQpNI0xvolG9NoeK7/0OAdPjoNBmug44iPj\nskwAEle7XraJy/PIzzTypr0o6W0wR976Md5lNKiVbEdR1UNBmk3sZgdS7wJab9B9JKG/4eWu3J/i\n/Dn8BfCsiHwJ+C7w5RO3qD2/EslJan9KYKKGuEBcwMj/vRDXGOJyw+V3bu0cc61zgReuu0bFB2+t\nkl9rs29ddPT6isVsDVjzzSA2W72JRqexsWRp7emUDTnuNhiV/QGHkWuqWu8ELVSCjFZGNGrDpDLJ\nMchEUOi0vf0WjOnlCmPFmeeoqpvNg/MdqWoVlW7vWg4PMrTlm24U0bu6dTslmFaWgmWkhnbkPr/T\nPqJvEw79zKGNpEvLDKugYrmybPnPd32iYPlgztUl2H9z9wMAPPqfgvnpdaTlS8aSGPKiiuKTF5MB\noTRxr8+fbN+fXO+Tj7TcSv7fW4JNIkzTJ27ePmTje7c5fMx1pRptFKjRKsouhSAq4/6cVtBCKMoZ\nXyODxLaqYZdciI8VbrsHNEmKtFvYjpNrsZox6iT0N32wuCHkmWDLPNLY/XDK5+FUilNVvwF8w//+\nOvCJabYPLCZBrstJkOuDY6Fau9xtTk/p8yw0wvjJkeBm/jy1ssfqZefjfK7xGG/k27SvuVNqvGYY\ntVrc2XFPnJs7Oa3NblUrXfrUtLbaiWKLzXyfzpFB1YzHjUaKpJbUm5BJUpBEBd2+r63P21iUkZaj\nNBbTlHsw1Hy/pVlbrRTKaKW77s23hzTfzDjacI96WXETL1f8vO1ILLkdzyE6KhK6ecqtoR8bnTt/\naGmqb2Rd1pJe5cvciLtkfhQ0uO5LvSKp+n82TM63336M5tddWlrnf151fq+yg31kkFEOQ+9yMcal\nrngTXdut8kTdvwuYjrQIlDXrTybOVB9sgG3U2vElMfLTt1j5mXO19S8yGaq2uK7v5cLeCnYUIWVe\ntihqxa06AU2U3o6h/zGX9jbsRBxfjFyPT8YVgWX6oRTOp1pNtimzEKPJ1/dioRTn/WBVECvjE1ZA\nqLXq11PlKpdpKmoUNVopTkktSSMn8QnvsbGoSuUjvTHsYLFVaKhQJX2olKenVJSV974cauYLG45H\ntPYa3NxxCqh/JaeVjqrrnkZuBEnpUsmiEbk13B56k8sa2umAzcZxtctekVSmPLiyza51D7SBjbk1\nalY+7je764y+us3Fr708cbwlVZPiZq0dWjFWrM50r9U1P4wynoJyOKLkjN0fNarWE6e5jPXNq8tf\n3q+ubHOw7lRab1PoXlKK5jj4ZIa1zXMmFaeAjWrHcwILrTjNKQad1TuFY2sXoqQ+40Sm9EupTAio\nvr14R3UZ5St9cgHeW8dtbRVM0cg96cu+iqoyMW0QnB8y9kHCZjSiHQ/Z8kG9xBTEUozna/vCiZaP\nkg80dvOzy0bGfqlRKs4fff0Jrvzz98fHFkUuZ7Ps8J6laBpXnadlMIQ4wnYyf/zGLaZtmX1x7nyd\nZ8I9b2V517/T3qLlykjvsq1QWznNltATKxAIBKbkzFecZdlk2darmFKXlxFZ9ab6hM9iwlQ/3ffp\nFE8o62c/g/OdndMo+mwoz10tEL13pERZwx8bbOp8UuBW7sb/1BnPV1eaZsjF1Pkw12IXRc/ErTBH\nGtO1DW4X49rzkUbcHDrn1u1Rxkba47+edXGRK//4KrbXx5SmuFqIkomplTKsWQ9xhDYSrE9bwUg5\nEHryvAN3pexFIQVMhDDs2MR2HzjFl53iM/e832csJplnIq+IHAEvz22H9+YCsH8G+31MVbfPYL8P\nFBG5ARxzNte0TpDrDAlyvbdc5604n1fVj89thwt+HMvEIlzTRTiGZWMRrukiHMO7CT7OQCAQmJKg\nOAOBQGBK5q04n5nz/u7FohzHMrEI13QRjmHZWIRrugjHMMFcfZyBQCCwDARTPRAIBKZkbopTRH5T\nRF72w6L+ck77vCIi/y0iPxCRqyLyWf/+F0VkV0Re9D9Pz+N4lpEg1+XkLOTq93suZDsXU11EIuAV\n4DdwbfufAz6lqj+n491M9nsJuKSq3xGRDvAC8HvAHwJ3VPWvH+T+l50g1+XkrOTq930uZDuvFecn\ngFdV9XVVHeKaqf7ug96pqu6p6nf870e4qX9zmbXykBDkupyciVzh/Mh2XorzMvBG7fXchkWViMgH\ngI8B3/JvfUZEXhKRr4jIxjyPZYkIcl1OzlyusNiyfSiCQyLSBv4V+HNVPcSNRX0c+CiwB/zNGR5e\n4H0S5Lq8LLps56U4d4Ertdf3HBY1a0QkwQngn1T13wBU9bqqFqpqgX8gdMZ+vwS5LidnJlc4H7Kd\nl+J8DnhCRD4oIinwR8DXHvROxTWB/DLwQ1X929r7l2of+33g++/eNnAqglyXkzORK5wf2c6lrZyq\n5iLyGeA/cP24vqKqV+ew608CfwJ8T0Re9O/9FfApEfkortnUj4FPz+FYlo4g1+XkDOUK50S2oXIo\nEAgEpuShCA4FAoHALAmKMxAIBKYkKM5AIBCYkqA4A4FAYEqC4gwEAoEpCYozEAgEpiQozkAgEJiS\noDgDgUBgSv4fhGb6AX2xpJkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRB8BZvdrZdJ",
        "colab_type": "text"
      },
      "source": [
        "<br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkTSozjkyzVB",
        "colab_type": "text"
      },
      "source": [
        "**VGG-Like**<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8cACem_1V03",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1122/1*_1DEx3bHlnBApCWWQ0HgcQ.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YAPiTZhD0Fx",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "92438421-8cca-44f9-f469-7fbd182d0d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "#@title\n",
        "# Adapted VGGNet Implementation\n",
        "# 100 epochs => 76% validation accuracy\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.name = 'VGG-Like'\n",
        "\n",
        "model.compile(optimizer=SGD'sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 48, 48, 32)        320       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 48, 48, 32)        9248      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 12, 12, 128)       147584    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               2359808   \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 2,647,779\n",
            "Trainable params: 2,647,779\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSMuMDFSskS7",
        "colab_type": "text"
      },
      "source": [
        "**CCNN**<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpW6Z5BqCy-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHXcLIpV8A-M",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://docs.google.com/uc?export=download&id=1JmzBI5paU5cNFwtTir4o8agnPTIr8vnB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTXmyLxEsYyJ",
        "colab_type": "code",
        "outputId": "4afeb320-5c84-4a41-caab-7fd697a035fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# Initial configuration\n",
        "# 100 epochs => 77% validation accuracy\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(32, kernel_size=(2,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.name = 'CCNN'\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 48, 48, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 24, 24, 32)        6176      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 1731      \n",
            "=================================================================\n",
            "Total params: 63,651\n",
            "Trainable params: 63,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1NTR24X8h3l",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://docs.google.com/uc?export=download&id=1lpIx7N9sV1Fbn23nDxT9Y_eqSZW2xNTq)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-G5V8EPsgj2",
        "colab_type": "code",
        "outputId": "3b0049a0-9a47-43bf-8d4b-56c06c3def52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# Doubled convolutional filters\n",
        "# 500 epochs => ~79% testing accuracy\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, kernel_size=(2,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.name = 'CCNN'\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 24, 24, 64)        24640     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 3459      \n",
            "=================================================================\n",
            "Total params: 250,179\n",
            "Trainable params: 250,179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbib312bdb4Z",
        "colab_type": "text"
      },
      "source": [
        "**CCNN w/ Batch Normalization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUTL07OX8sib",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://docs.google.com/uc?export=download&id=1LvSF3VD4_b7ejwU8hH1XHF7rI62xXo70)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAJjac2Zdaf5",
        "colab_type": "code",
        "outputId": "1549b990-3b24-410b-94d7-c748cf8cb86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "# 1550 epochs => ~81% testing accuracy\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, kernel_size=(2,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.name = 'CCNN + Batch Normalization'\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=(['accuracy']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_27 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 24, 24, 64)        24640     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 3, 3, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 3459      \n",
            "=================================================================\n",
            "Total params: 250,947\n",
            "Trainable params: 250,563\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnPR2Rcwdkby",
        "colab_type": "text"
      },
      "source": [
        "**CCNN Dense**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ns7W7Q-l86Xk"
      },
      "source": [
        "![alt text](https://docs.google.com/uc?export=download&id=1dkFVUvavR8ExkjqzDaH-sCzVvZctoU6i)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvEzhUP3dn8Y",
        "colab_type": "code",
        "outputId": "1c0d160b-4814-4898-aa5a-18158b4c3fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# Added another dense layer\n",
        "# Trained with data augmentation\n",
        "# 1400 epochs => ~82% testing accuracy when using SGD\n",
        "# 600 epochs => ~85% testing accuracy when using Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, kernel_size=(2,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.name = 'CCNN Dense'\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=(['accuracy']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 24, 24, 64)        24640     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 3, 3, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 395,459\n",
            "Trainable params: 395,075\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWijip9HfYLg",
        "colab_type": "text"
      },
      "source": [
        "**CCNN Fully Convolutional**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ltGDidA9EvM"
      },
      "source": [
        "![alt text](https://docs.google.com/uc?export=download&id=17dJJYISv4pflhKFvXCMLg-0e46HEnqGX)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJHHo3YXfXnE",
        "colab_type": "code",
        "outputId": "789e3464-b257-43fe-a1ef-4eb46f3ae45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# Replaced dense layers in previous model with convolutional layers\n",
        "# Produces same result as with dense layers\n",
        "# Trained with data augmentation\n",
        "# 600 epochs => ~85% testing accuracy\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(3, kernel_size=(1,1), strides=1, activation='softmax'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.summary()\n",
        "model.name = 'CFCN'\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=(['accuracy']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 3, 3, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 1, 1, 128)         147584    \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 1, 1, 3)           387       \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 407,747\n",
            "Trainable params: 407,363\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aiFcvmMWBuVw",
        "colab": {}
      },
      "source": [
        "# Generator for augmented image data\n",
        "imGen = ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=0.05,\n",
        "                               height_shift_range=0.05,\n",
        "                               zoom_range=[0.9, 1.1],\n",
        "                               horizontal_flip=True,\n",
        "                               fill_mode='nearest',\n",
        "                               data_format='channels_last')\n",
        "\n",
        "imGen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VvAj2Qm0ObJI",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# ~2000 epochs => ~85.04% validation accuracy\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, kernel_size=(2,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "#model.add(GaussianNoise(0.5))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "#model.add(GaussianNoise(0.5))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "#model.add(GaussianNoise(0.5))\n",
        "\n",
        "#model.add(Flatten())\n",
        "model.add(Conv2D(256, kernel_size=(3,3), strides=1, activation='relu'))\n",
        "#model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(3, kernel_size=(1,1), strides=1, activation='softmax'))\n",
        "model.add(Flatten())\n",
        "#model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "mName = 'Troika++'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gmttn0IE9keS",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# v1.1: added batch normalization layers before dropout layers\n",
        "# added more layers between flatten layer and output layer\n",
        "# Train using ~1409 epochs\n",
        "# Yields ~81% testing accuracy\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, kernel_size=(2,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(GaussianNoise(0.3))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(GaussianNoise(0.3))\n",
        "\n",
        "#model.add(Conv2D(256, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(drop))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "mName = 'Troika Noisy Dense'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jvkb8rxP0-3o",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=(['accuracy']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYq0DlgFa7kG",
        "colab_type": "text"
      },
      "source": [
        "<br><br><br><br><br>\n",
        "# **Training Section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THRi79Ps4sz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop = 0.5\n",
        "num_classes = 3\n",
        "batch_size = 64\n",
        "epochs = 1600"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFvWFtNCF4xA",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "model.compile(optimizer=SGD(lr=0.005, momentum=0.5, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUgMRGXUKeyd",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "print(mName, '\\n')\n",
        "history = model.fit(np.array(X_train), np.array(Y_train), \n",
        "          batch_size=batch_size, \n",
        "          epochs=epochs, \n",
        "          verbose=1, \n",
        "          validation_data=(np.array(X_valid), np.array(Y_valid)), \n",
        "          shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXTacEjIefi1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "model.load_weights('Troika Dense')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QSVg9IQ6QRI",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# train with simple horizontal flip augmentation\n",
        "print(model.name, '\\n', 'Horizontal Flip\\n')\n",
        "history = model.fit_generator(datagen.flow(X_train, Y_train),\n",
        "                    steps_per_epoch=14557//batch_size,\n",
        "                    epochs=2500,\n",
        "                    verbose=1,\n",
        "                    validation_data=(datagen.flow(X_valid, Y_valid)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AS8xrGn0EJ6",
        "colab_type": "code",
        "outputId": "c4ee1828-dadd-4a5a-ac17-081a7aefeee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train with full augmentation\n",
        "print(model.name, '\\n', 'Full Augmentation\\n')\n",
        "model.fit_generator(moreGen.flow(X_train, Y_train),\n",
        "                    steps_per_epoch=14557//batch_size,\n",
        "                    epochs=2500,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Troika Noisy Dense \n",
            " Full Augmentation\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/2500\n",
            "227/227 [==============================] - 11s 49ms/step - loss: 1.2011 - acc: 0.4213 - val_loss: 1.0671 - val_acc: 0.4592\n",
            "Epoch 2/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 1.0608 - acc: 0.4566 - val_loss: 1.0506 - val_acc: 0.4691\n",
            "Epoch 3/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 1.0173 - acc: 0.4877 - val_loss: 0.9655 - val_acc: 0.5192\n",
            "Epoch 4/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.9889 - acc: 0.5174 - val_loss: 0.9196 - val_acc: 0.5501\n",
            "Epoch 5/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.9493 - acc: 0.5426 - val_loss: 0.8518 - val_acc: 0.6069\n",
            "Epoch 6/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.9076 - acc: 0.5760 - val_loss: 0.7801 - val_acc: 0.6452\n",
            "Epoch 7/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.9030 - acc: 0.5724 - val_loss: 0.8551 - val_acc: 0.6088\n",
            "Epoch 8/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.8584 - acc: 0.6046 - val_loss: 0.7388 - val_acc: 0.6619\n",
            "Epoch 9/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.8384 - acc: 0.6211 - val_loss: 0.7276 - val_acc: 0.6761\n",
            "Epoch 10/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.8169 - acc: 0.6318 - val_loss: 0.8361 - val_acc: 0.6304\n",
            "Epoch 11/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.8186 - acc: 0.6313 - val_loss: 0.7459 - val_acc: 0.6650\n",
            "Epoch 12/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.7953 - acc: 0.6473 - val_loss: 0.7385 - val_acc: 0.6768\n",
            "Epoch 13/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.7910 - acc: 0.6484 - val_loss: 0.7115 - val_acc: 0.6910\n",
            "Epoch 14/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.7760 - acc: 0.6562 - val_loss: 0.7624 - val_acc: 0.6527\n",
            "Epoch 15/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.7633 - acc: 0.6513 - val_loss: 0.6518 - val_acc: 0.7108\n",
            "Epoch 16/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.7692 - acc: 0.6630 - val_loss: 0.6899 - val_acc: 0.7040\n",
            "Epoch 17/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.7376 - acc: 0.6725 - val_loss: 0.6412 - val_acc: 0.7299\n",
            "Epoch 18/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.7525 - acc: 0.6663 - val_loss: 0.6819 - val_acc: 0.7114\n",
            "Epoch 19/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.7283 - acc: 0.6809 - val_loss: 0.6783 - val_acc: 0.6959\n",
            "Epoch 20/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.7350 - acc: 0.6821 - val_loss: 0.6532 - val_acc: 0.7182\n",
            "Epoch 21/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.7219 - acc: 0.6847 - val_loss: 0.6600 - val_acc: 0.7114\n",
            "Epoch 22/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.7213 - acc: 0.6844 - val_loss: 0.6521 - val_acc: 0.7287\n",
            "Epoch 23/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.7235 - acc: 0.6859 - val_loss: 0.5986 - val_acc: 0.7336\n",
            "Epoch 24/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.7121 - acc: 0.6920 - val_loss: 0.6642 - val_acc: 0.7219\n",
            "Epoch 25/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6891 - acc: 0.7020 - val_loss: 0.6079 - val_acc: 0.7330\n",
            "Epoch 26/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6990 - acc: 0.6980 - val_loss: 0.6435 - val_acc: 0.7268\n",
            "Epoch 27/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6913 - acc: 0.6994 - val_loss: 0.5899 - val_acc: 0.7608\n",
            "Epoch 28/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.7006 - acc: 0.6958 - val_loss: 0.6958 - val_acc: 0.6990\n",
            "Epoch 29/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.6771 - acc: 0.7104 - val_loss: 0.5743 - val_acc: 0.7559\n",
            "Epoch 30/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6828 - acc: 0.7057 - val_loss: 0.5629 - val_acc: 0.7689\n",
            "Epoch 31/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6855 - acc: 0.7032 - val_loss: 0.6331 - val_acc: 0.7392\n",
            "Epoch 32/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6779 - acc: 0.7075 - val_loss: 0.5832 - val_acc: 0.7664\n",
            "Epoch 33/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6899 - acc: 0.7031 - val_loss: 0.5770 - val_acc: 0.7639\n",
            "Epoch 34/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6622 - acc: 0.7163 - val_loss: 0.5898 - val_acc: 0.7540\n",
            "Epoch 35/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6693 - acc: 0.7164 - val_loss: 0.5686 - val_acc: 0.7583\n",
            "Epoch 36/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6570 - acc: 0.7145 - val_loss: 0.5683 - val_acc: 0.7621\n",
            "Epoch 37/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6540 - acc: 0.7145 - val_loss: 0.6174 - val_acc: 0.7528\n",
            "Epoch 38/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6554 - acc: 0.7211 - val_loss: 0.6456 - val_acc: 0.7256\n",
            "Epoch 39/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6491 - acc: 0.7191 - val_loss: 0.5735 - val_acc: 0.7590\n",
            "Epoch 40/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6613 - acc: 0.7200 - val_loss: 0.5975 - val_acc: 0.7590\n",
            "Epoch 41/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6382 - acc: 0.7298 - val_loss: 0.5381 - val_acc: 0.7862\n",
            "Epoch 42/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6398 - acc: 0.7266 - val_loss: 0.5654 - val_acc: 0.7676\n",
            "Epoch 43/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6255 - acc: 0.7346 - val_loss: 0.5706 - val_acc: 0.7571\n",
            "Epoch 44/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6539 - acc: 0.7216 - val_loss: 0.5442 - val_acc: 0.7732\n",
            "Epoch 45/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.6393 - acc: 0.7299 - val_loss: 0.5747 - val_acc: 0.7744\n",
            "Epoch 46/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6406 - acc: 0.7313 - val_loss: 0.5801 - val_acc: 0.7571\n",
            "Epoch 47/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6225 - acc: 0.7393 - val_loss: 0.6468 - val_acc: 0.7244\n",
            "Epoch 48/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.6372 - acc: 0.7239 - val_loss: 0.5867 - val_acc: 0.7583\n",
            "Epoch 49/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6237 - acc: 0.7347 - val_loss: 0.5383 - val_acc: 0.7800\n",
            "Epoch 50/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6478 - acc: 0.7233 - val_loss: 0.5425 - val_acc: 0.7719\n",
            "Epoch 51/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6307 - acc: 0.7306 - val_loss: 0.5875 - val_acc: 0.7633\n",
            "Epoch 52/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6223 - acc: 0.7394 - val_loss: 0.5577 - val_acc: 0.7695\n",
            "Epoch 53/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6205 - acc: 0.7383 - val_loss: 0.5698 - val_acc: 0.7602\n",
            "Epoch 54/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6210 - acc: 0.7365 - val_loss: 0.5447 - val_acc: 0.7794\n",
            "Epoch 55/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6356 - acc: 0.7298 - val_loss: 0.6025 - val_acc: 0.7528\n",
            "Epoch 56/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6164 - acc: 0.7426 - val_loss: 0.5640 - val_acc: 0.7608\n",
            "Epoch 57/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6176 - acc: 0.7365 - val_loss: 0.5379 - val_acc: 0.7763\n",
            "Epoch 58/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6142 - acc: 0.7392 - val_loss: 0.5467 - val_acc: 0.7775\n",
            "Epoch 59/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6166 - acc: 0.7420 - val_loss: 0.5434 - val_acc: 0.7794\n",
            "Epoch 60/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.6159 - acc: 0.7411 - val_loss: 0.5202 - val_acc: 0.7855\n",
            "Epoch 61/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6074 - acc: 0.7490 - val_loss: 0.5921 - val_acc: 0.7571\n",
            "Epoch 62/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6148 - acc: 0.7424 - val_loss: 0.5431 - val_acc: 0.7689\n",
            "Epoch 63/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6087 - acc: 0.7456 - val_loss: 0.5862 - val_acc: 0.7664\n",
            "Epoch 64/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.6036 - acc: 0.7466 - val_loss: 0.5381 - val_acc: 0.7818\n",
            "Epoch 65/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6124 - acc: 0.7451 - val_loss: 0.5818 - val_acc: 0.7664\n",
            "Epoch 66/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.6025 - acc: 0.7459 - val_loss: 0.5457 - val_acc: 0.7713\n",
            "Epoch 67/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6049 - acc: 0.7529 - val_loss: 0.5583 - val_acc: 0.7763\n",
            "Epoch 68/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5977 - acc: 0.7383 - val_loss: 0.5748 - val_acc: 0.7824\n",
            "Epoch 69/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.6021 - acc: 0.7468 - val_loss: 0.5595 - val_acc: 0.7670\n",
            "Epoch 70/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.6004 - acc: 0.7429 - val_loss: 0.5667 - val_acc: 0.7682\n",
            "Epoch 71/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5977 - acc: 0.7572 - val_loss: 0.5836 - val_acc: 0.7577\n",
            "Epoch 72/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.6017 - acc: 0.7455 - val_loss: 0.5397 - val_acc: 0.7732\n",
            "Epoch 73/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5868 - acc: 0.7474 - val_loss: 0.5022 - val_acc: 0.7905\n",
            "Epoch 74/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5917 - acc: 0.7523 - val_loss: 0.5405 - val_acc: 0.7794\n",
            "Epoch 75/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5778 - acc: 0.7533 - val_loss: 0.5355 - val_acc: 0.7942\n",
            "Epoch 76/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5924 - acc: 0.7494 - val_loss: 0.5179 - val_acc: 0.7917\n",
            "Epoch 77/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5934 - acc: 0.7504 - val_loss: 0.5016 - val_acc: 0.8016\n",
            "Epoch 78/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5987 - acc: 0.7500 - val_loss: 0.5207 - val_acc: 0.7930\n",
            "Epoch 79/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5741 - acc: 0.7618 - val_loss: 0.5456 - val_acc: 0.7812\n",
            "Epoch 80/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5938 - acc: 0.7477 - val_loss: 0.5108 - val_acc: 0.7886\n",
            "Epoch 81/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5767 - acc: 0.7607 - val_loss: 0.6018 - val_acc: 0.7627\n",
            "Epoch 82/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5900 - acc: 0.7566 - val_loss: 0.5577 - val_acc: 0.7639\n",
            "Epoch 83/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5770 - acc: 0.7550 - val_loss: 0.5183 - val_acc: 0.7911\n",
            "Epoch 84/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.5844 - acc: 0.7604 - val_loss: 0.5554 - val_acc: 0.7602\n",
            "Epoch 85/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5971 - acc: 0.7503 - val_loss: 0.5117 - val_acc: 0.8047\n",
            "Epoch 86/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5838 - acc: 0.7583 - val_loss: 0.6395 - val_acc: 0.7355\n",
            "Epoch 87/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5753 - acc: 0.7617 - val_loss: 0.5294 - val_acc: 0.7824\n",
            "Epoch 88/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5818 - acc: 0.7565 - val_loss: 0.5216 - val_acc: 0.7874\n",
            "Epoch 89/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5796 - acc: 0.7627 - val_loss: 0.5015 - val_acc: 0.7967\n",
            "Epoch 90/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5775 - acc: 0.7627 - val_loss: 0.5413 - val_acc: 0.7763\n",
            "Epoch 91/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5739 - acc: 0.7632 - val_loss: 0.4967 - val_acc: 0.8041\n",
            "Epoch 92/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5835 - acc: 0.7591 - val_loss: 0.4966 - val_acc: 0.7991\n",
            "Epoch 93/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5694 - acc: 0.7629 - val_loss: 0.5270 - val_acc: 0.7948\n",
            "Epoch 94/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5766 - acc: 0.7665 - val_loss: 0.4951 - val_acc: 0.8053\n",
            "Epoch 95/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5794 - acc: 0.7566 - val_loss: 0.4993 - val_acc: 0.8053\n",
            "Epoch 96/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5797 - acc: 0.7534 - val_loss: 0.5133 - val_acc: 0.7818\n",
            "Epoch 97/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5716 - acc: 0.7596 - val_loss: 0.4979 - val_acc: 0.8035\n",
            "Epoch 98/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5821 - acc: 0.7548 - val_loss: 0.5548 - val_acc: 0.7744\n",
            "Epoch 99/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5673 - acc: 0.7626 - val_loss: 0.5058 - val_acc: 0.7880\n",
            "Epoch 100/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5753 - acc: 0.7599 - val_loss: 0.4914 - val_acc: 0.7985\n",
            "Epoch 101/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5642 - acc: 0.7671 - val_loss: 0.4967 - val_acc: 0.8072\n",
            "Epoch 102/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5771 - acc: 0.7620 - val_loss: 0.5881 - val_acc: 0.7726\n",
            "Epoch 103/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5726 - acc: 0.7573 - val_loss: 0.5342 - val_acc: 0.7682\n",
            "Epoch 104/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5656 - acc: 0.7611 - val_loss: 0.5257 - val_acc: 0.7905\n",
            "Epoch 105/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5697 - acc: 0.7623 - val_loss: 0.4939 - val_acc: 0.8103\n",
            "Epoch 106/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5770 - acc: 0.7624 - val_loss: 0.5398 - val_acc: 0.7713\n",
            "Epoch 107/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5616 - acc: 0.7624 - val_loss: 0.5069 - val_acc: 0.7973\n",
            "Epoch 108/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5669 - acc: 0.7631 - val_loss: 0.5152 - val_acc: 0.7899\n",
            "Epoch 109/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5601 - acc: 0.7698 - val_loss: 0.5205 - val_acc: 0.7843\n",
            "Epoch 110/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5687 - acc: 0.7644 - val_loss: 0.5369 - val_acc: 0.7787\n",
            "Epoch 111/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5442 - acc: 0.7731 - val_loss: 0.4939 - val_acc: 0.8022\n",
            "Epoch 112/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5665 - acc: 0.7664 - val_loss: 0.5560 - val_acc: 0.7763\n",
            "Epoch 113/2500\n",
            "227/227 [==============================] - 7s 30ms/step - loss: 0.5590 - acc: 0.7706 - val_loss: 0.5294 - val_acc: 0.7843\n",
            "Epoch 114/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5603 - acc: 0.7654 - val_loss: 0.4935 - val_acc: 0.7960\n",
            "Epoch 115/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5645 - acc: 0.7611 - val_loss: 0.4855 - val_acc: 0.8103\n",
            "Epoch 116/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5650 - acc: 0.7664 - val_loss: 0.4960 - val_acc: 0.8047\n",
            "Epoch 117/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5529 - acc: 0.7733 - val_loss: 0.5506 - val_acc: 0.7843\n",
            "Epoch 118/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5685 - acc: 0.7687 - val_loss: 0.5270 - val_acc: 0.7849\n",
            "Epoch 119/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5601 - acc: 0.7661 - val_loss: 0.5097 - val_acc: 0.8004\n",
            "Epoch 120/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5637 - acc: 0.7652 - val_loss: 0.5466 - val_acc: 0.7750\n",
            "Epoch 121/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5541 - acc: 0.7733 - val_loss: 0.4865 - val_acc: 0.8028\n",
            "Epoch 122/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5533 - acc: 0.7702 - val_loss: 0.4923 - val_acc: 0.7923\n",
            "Epoch 123/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5718 - acc: 0.7647 - val_loss: 0.5594 - val_acc: 0.7651\n",
            "Epoch 124/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5577 - acc: 0.7693 - val_loss: 0.4949 - val_acc: 0.8004\n",
            "Epoch 125/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5504 - acc: 0.7700 - val_loss: 0.5129 - val_acc: 0.7899\n",
            "Epoch 126/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5655 - acc: 0.7631 - val_loss: 0.5037 - val_acc: 0.7942\n",
            "Epoch 127/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5462 - acc: 0.7837 - val_loss: 0.4928 - val_acc: 0.7948\n",
            "Epoch 128/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5487 - acc: 0.7686 - val_loss: 0.4971 - val_acc: 0.8121\n",
            "Epoch 129/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5680 - acc: 0.7649 - val_loss: 0.4823 - val_acc: 0.8035\n",
            "Epoch 130/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5510 - acc: 0.7707 - val_loss: 0.5042 - val_acc: 0.8010\n",
            "Epoch 131/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5581 - acc: 0.7737 - val_loss: 0.4966 - val_acc: 0.7985\n",
            "Epoch 132/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5604 - acc: 0.7678 - val_loss: 0.5023 - val_acc: 0.7942\n",
            "Epoch 133/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5391 - acc: 0.7793 - val_loss: 0.4990 - val_acc: 0.7967\n",
            "Epoch 134/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5478 - acc: 0.7742 - val_loss: 0.5575 - val_acc: 0.7583\n",
            "Epoch 135/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5502 - acc: 0.7685 - val_loss: 0.5450 - val_acc: 0.7664\n",
            "Epoch 136/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5557 - acc: 0.7727 - val_loss: 0.4738 - val_acc: 0.8115\n",
            "Epoch 137/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5389 - acc: 0.7830 - val_loss: 0.4661 - val_acc: 0.8189\n",
            "Epoch 138/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5508 - acc: 0.7705 - val_loss: 0.4935 - val_acc: 0.7967\n",
            "Epoch 139/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5512 - acc: 0.7757 - val_loss: 0.5069 - val_acc: 0.8041\n",
            "Epoch 140/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5415 - acc: 0.7766 - val_loss: 0.5082 - val_acc: 0.8028\n",
            "Epoch 141/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5429 - acc: 0.7767 - val_loss: 0.4983 - val_acc: 0.7954\n",
            "Epoch 142/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5445 - acc: 0.7803 - val_loss: 0.5323 - val_acc: 0.7855\n",
            "Epoch 143/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5486 - acc: 0.7796 - val_loss: 0.5420 - val_acc: 0.7787\n",
            "Epoch 144/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5536 - acc: 0.7719 - val_loss: 0.4847 - val_acc: 0.8090\n",
            "Epoch 145/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5354 - acc: 0.7760 - val_loss: 0.4705 - val_acc: 0.8127\n",
            "Epoch 146/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5487 - acc: 0.7778 - val_loss: 0.5144 - val_acc: 0.7806\n",
            "Epoch 147/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5475 - acc: 0.7752 - val_loss: 0.5034 - val_acc: 0.7998\n",
            "Epoch 148/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5361 - acc: 0.7784 - val_loss: 0.4934 - val_acc: 0.8053\n",
            "Epoch 149/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5390 - acc: 0.7758 - val_loss: 0.5242 - val_acc: 0.7874\n",
            "Epoch 150/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5515 - acc: 0.7758 - val_loss: 0.4887 - val_acc: 0.8115\n",
            "Epoch 151/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5283 - acc: 0.7804 - val_loss: 0.5817 - val_acc: 0.7454\n",
            "Epoch 152/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5425 - acc: 0.7788 - val_loss: 0.4783 - val_acc: 0.8047\n",
            "Epoch 153/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5435 - acc: 0.7792 - val_loss: 0.4709 - val_acc: 0.8171\n",
            "Epoch 154/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5361 - acc: 0.7827 - val_loss: 0.5057 - val_acc: 0.7930\n",
            "Epoch 155/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5295 - acc: 0.7907 - val_loss: 0.4795 - val_acc: 0.8158\n",
            "Epoch 156/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5293 - acc: 0.7832 - val_loss: 0.5451 - val_acc: 0.7713\n",
            "Epoch 157/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5632 - acc: 0.7677 - val_loss: 0.5052 - val_acc: 0.7892\n",
            "Epoch 158/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5363 - acc: 0.7773 - val_loss: 0.4823 - val_acc: 0.8047\n",
            "Epoch 159/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5326 - acc: 0.7856 - val_loss: 0.5257 - val_acc: 0.7849\n",
            "Epoch 160/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5398 - acc: 0.7720 - val_loss: 0.5344 - val_acc: 0.7868\n",
            "Epoch 161/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5296 - acc: 0.7861 - val_loss: 0.4842 - val_acc: 0.8066\n",
            "Epoch 162/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5311 - acc: 0.7824 - val_loss: 0.5817 - val_acc: 0.7651\n",
            "Epoch 163/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5402 - acc: 0.7778 - val_loss: 0.4784 - val_acc: 0.8066\n",
            "Epoch 164/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5386 - acc: 0.7786 - val_loss: 0.4759 - val_acc: 0.8109\n",
            "Epoch 165/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5318 - acc: 0.7827 - val_loss: 0.4633 - val_acc: 0.8201\n",
            "Epoch 166/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5398 - acc: 0.7779 - val_loss: 0.5745 - val_acc: 0.7540\n",
            "Epoch 167/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5338 - acc: 0.7784 - val_loss: 0.5151 - val_acc: 0.8053\n",
            "Epoch 168/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5373 - acc: 0.7792 - val_loss: 0.4769 - val_acc: 0.8208\n",
            "Epoch 169/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5336 - acc: 0.7786 - val_loss: 0.4938 - val_acc: 0.8096\n",
            "Epoch 170/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5291 - acc: 0.7877 - val_loss: 0.4493 - val_acc: 0.8195\n",
            "Epoch 171/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5396 - acc: 0.7811 - val_loss: 0.4943 - val_acc: 0.8127\n",
            "Epoch 172/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5384 - acc: 0.7835 - val_loss: 0.5030 - val_acc: 0.7911\n",
            "Epoch 173/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5300 - acc: 0.7838 - val_loss: 0.4846 - val_acc: 0.7998\n",
            "Epoch 174/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5296 - acc: 0.7847 - val_loss: 0.4853 - val_acc: 0.8004\n",
            "Epoch 175/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5230 - acc: 0.7872 - val_loss: 0.4908 - val_acc: 0.8096\n",
            "Epoch 176/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5335 - acc: 0.7866 - val_loss: 0.4899 - val_acc: 0.8004\n",
            "Epoch 177/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5317 - acc: 0.7835 - val_loss: 0.4830 - val_acc: 0.8059\n",
            "Epoch 178/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5373 - acc: 0.7807 - val_loss: 0.5044 - val_acc: 0.7985\n",
            "Epoch 179/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5279 - acc: 0.7829 - val_loss: 0.4981 - val_acc: 0.8072\n",
            "Epoch 180/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5319 - acc: 0.7843 - val_loss: 0.5077 - val_acc: 0.7899\n",
            "Epoch 181/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5362 - acc: 0.7784 - val_loss: 0.4771 - val_acc: 0.8146\n",
            "Epoch 182/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5308 - acc: 0.7800 - val_loss: 0.4676 - val_acc: 0.8103\n",
            "Epoch 183/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5325 - acc: 0.7804 - val_loss: 0.4832 - val_acc: 0.8016\n",
            "Epoch 184/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5249 - acc: 0.7858 - val_loss: 0.4843 - val_acc: 0.8121\n",
            "Epoch 185/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5226 - acc: 0.7896 - val_loss: 0.4796 - val_acc: 0.8146\n",
            "Epoch 186/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5196 - acc: 0.7872 - val_loss: 0.4864 - val_acc: 0.8084\n",
            "Epoch 187/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5245 - acc: 0.7868 - val_loss: 0.4888 - val_acc: 0.8035\n",
            "Epoch 188/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5304 - acc: 0.7867 - val_loss: 0.4975 - val_acc: 0.7979\n",
            "Epoch 189/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5260 - acc: 0.7856 - val_loss: 0.4929 - val_acc: 0.8053\n",
            "Epoch 190/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5381 - acc: 0.7840 - val_loss: 0.4790 - val_acc: 0.8059\n",
            "Epoch 191/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5160 - acc: 0.7891 - val_loss: 0.4739 - val_acc: 0.8109\n",
            "Epoch 192/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5260 - acc: 0.7857 - val_loss: 0.4718 - val_acc: 0.8072\n",
            "Epoch 193/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5154 - acc: 0.7890 - val_loss: 0.4743 - val_acc: 0.8208\n",
            "Epoch 194/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5340 - acc: 0.7874 - val_loss: 0.4683 - val_acc: 0.8140\n",
            "Epoch 195/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5237 - acc: 0.7859 - val_loss: 0.4698 - val_acc: 0.8195\n",
            "Epoch 196/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5242 - acc: 0.7861 - val_loss: 0.4903 - val_acc: 0.8047\n",
            "Epoch 197/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5236 - acc: 0.7872 - val_loss: 0.5066 - val_acc: 0.7831\n",
            "Epoch 198/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5314 - acc: 0.7846 - val_loss: 0.5207 - val_acc: 0.7905\n",
            "Epoch 199/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5192 - acc: 0.7945 - val_loss: 0.4602 - val_acc: 0.8189\n",
            "Epoch 200/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5210 - acc: 0.7818 - val_loss: 0.4795 - val_acc: 0.8059\n",
            "Epoch 201/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5196 - acc: 0.7927 - val_loss: 0.4572 - val_acc: 0.8220\n",
            "Epoch 202/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5148 - acc: 0.7859 - val_loss: 0.4816 - val_acc: 0.8028\n",
            "Epoch 203/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5224 - acc: 0.7832 - val_loss: 0.4714 - val_acc: 0.8158\n",
            "Epoch 204/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5205 - acc: 0.7894 - val_loss: 0.4591 - val_acc: 0.8183\n",
            "Epoch 205/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5286 - acc: 0.7850 - val_loss: 0.4502 - val_acc: 0.8220\n",
            "Epoch 206/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5121 - acc: 0.7975 - val_loss: 0.5181 - val_acc: 0.7824\n",
            "Epoch 207/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5114 - acc: 0.7895 - val_loss: 0.4615 - val_acc: 0.8276\n",
            "Epoch 208/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5301 - acc: 0.7814 - val_loss: 0.4941 - val_acc: 0.7948\n",
            "Epoch 209/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5109 - acc: 0.7892 - val_loss: 0.5595 - val_acc: 0.7936\n",
            "Epoch 210/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5226 - acc: 0.7887 - val_loss: 0.5493 - val_acc: 0.7695\n",
            "Epoch 211/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5178 - acc: 0.7888 - val_loss: 0.4677 - val_acc: 0.8220\n",
            "Epoch 212/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5058 - acc: 0.7993 - val_loss: 0.4675 - val_acc: 0.8208\n",
            "Epoch 213/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5015 - acc: 0.8000 - val_loss: 0.5114 - val_acc: 0.8004\n",
            "Epoch 214/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5316 - acc: 0.7811 - val_loss: 0.4809 - val_acc: 0.8109\n",
            "Epoch 215/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5131 - acc: 0.7934 - val_loss: 0.4554 - val_acc: 0.8189\n",
            "Epoch 216/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5145 - acc: 0.7933 - val_loss: 0.4674 - val_acc: 0.8189\n",
            "Epoch 217/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5221 - acc: 0.7862 - val_loss: 0.4699 - val_acc: 0.8220\n",
            "Epoch 218/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5241 - acc: 0.7881 - val_loss: 0.4631 - val_acc: 0.8257\n",
            "Epoch 219/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5157 - acc: 0.7868 - val_loss: 0.4812 - val_acc: 0.8189\n",
            "Epoch 220/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5113 - acc: 0.7891 - val_loss: 0.4827 - val_acc: 0.8269\n",
            "Epoch 221/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5181 - acc: 0.7872 - val_loss: 0.5250 - val_acc: 0.8059\n",
            "Epoch 222/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5152 - acc: 0.7847 - val_loss: 0.4981 - val_acc: 0.8059\n",
            "Epoch 223/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5071 - acc: 0.7964 - val_loss: 0.4629 - val_acc: 0.8307\n",
            "Epoch 224/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5180 - acc: 0.7914 - val_loss: 0.4879 - val_acc: 0.8263\n",
            "Epoch 225/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5221 - acc: 0.7838 - val_loss: 0.4862 - val_acc: 0.7998\n",
            "Epoch 226/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5116 - acc: 0.7872 - val_loss: 0.4846 - val_acc: 0.8047\n",
            "Epoch 227/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5144 - acc: 0.7872 - val_loss: 0.4690 - val_acc: 0.8226\n",
            "Epoch 228/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5080 - acc: 0.7975 - val_loss: 0.4834 - val_acc: 0.8096\n",
            "Epoch 229/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5230 - acc: 0.7887 - val_loss: 0.4843 - val_acc: 0.8127\n",
            "Epoch 230/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5195 - acc: 0.7849 - val_loss: 0.4486 - val_acc: 0.8251\n",
            "Epoch 231/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5142 - acc: 0.7903 - val_loss: 0.4480 - val_acc: 0.8220\n",
            "Epoch 232/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5213 - acc: 0.7829 - val_loss: 0.4601 - val_acc: 0.8072\n",
            "Epoch 233/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5024 - acc: 0.7949 - val_loss: 0.4761 - val_acc: 0.8115\n",
            "Epoch 234/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5211 - acc: 0.7833 - val_loss: 0.4816 - val_acc: 0.8146\n",
            "Epoch 235/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5139 - acc: 0.7953 - val_loss: 0.4690 - val_acc: 0.8183\n",
            "Epoch 236/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5100 - acc: 0.7993 - val_loss: 0.4862 - val_acc: 0.8084\n",
            "Epoch 237/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5110 - acc: 0.7876 - val_loss: 0.4597 - val_acc: 0.8171\n",
            "Epoch 238/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5165 - acc: 0.7901 - val_loss: 0.4677 - val_acc: 0.8263\n",
            "Epoch 239/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4979 - acc: 0.7996 - val_loss: 0.5023 - val_acc: 0.8053\n",
            "Epoch 240/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5120 - acc: 0.7912 - val_loss: 0.5520 - val_acc: 0.7868\n",
            "Epoch 241/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4947 - acc: 0.7944 - val_loss: 0.4928 - val_acc: 0.8140\n",
            "Epoch 242/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5200 - acc: 0.7876 - val_loss: 0.4973 - val_acc: 0.7979\n",
            "Epoch 243/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5152 - acc: 0.7912 - val_loss: 0.4787 - val_acc: 0.7991\n",
            "Epoch 244/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5062 - acc: 0.7971 - val_loss: 0.4495 - val_acc: 0.8288\n",
            "Epoch 245/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5106 - acc: 0.7886 - val_loss: 0.4639 - val_acc: 0.8171\n",
            "Epoch 246/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5159 - acc: 0.7942 - val_loss: 0.4564 - val_acc: 0.8189\n",
            "Epoch 247/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5190 - acc: 0.7928 - val_loss: 0.4835 - val_acc: 0.8127\n",
            "Epoch 248/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5069 - acc: 0.7903 - val_loss: 0.4800 - val_acc: 0.8133\n",
            "Epoch 249/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4998 - acc: 0.8003 - val_loss: 0.4667 - val_acc: 0.8177\n",
            "Epoch 250/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4961 - acc: 0.7968 - val_loss: 0.4559 - val_acc: 0.8189\n",
            "Epoch 251/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5087 - acc: 0.7954 - val_loss: 0.4733 - val_acc: 0.8121\n",
            "Epoch 252/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5046 - acc: 0.7971 - val_loss: 0.4885 - val_acc: 0.8004\n",
            "Epoch 253/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4983 - acc: 0.7927 - val_loss: 0.4645 - val_acc: 0.8177\n",
            "Epoch 254/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5129 - acc: 0.7897 - val_loss: 0.5322 - val_acc: 0.7818\n",
            "Epoch 255/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5090 - acc: 0.7909 - val_loss: 0.5262 - val_acc: 0.8158\n",
            "Epoch 256/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5091 - acc: 0.7863 - val_loss: 0.5058 - val_acc: 0.7998\n",
            "Epoch 257/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5008 - acc: 0.7992 - val_loss: 0.4727 - val_acc: 0.8189\n",
            "Epoch 258/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5218 - acc: 0.7885 - val_loss: 0.4737 - val_acc: 0.8146\n",
            "Epoch 259/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4946 - acc: 0.8002 - val_loss: 0.4621 - val_acc: 0.8251\n",
            "Epoch 260/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5208 - acc: 0.7880 - val_loss: 0.4928 - val_acc: 0.8035\n",
            "Epoch 261/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4997 - acc: 0.7943 - val_loss: 0.4760 - val_acc: 0.8103\n",
            "Epoch 262/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4992 - acc: 0.7968 - val_loss: 0.4703 - val_acc: 0.8220\n",
            "Epoch 263/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4979 - acc: 0.8008 - val_loss: 0.4712 - val_acc: 0.8220\n",
            "Epoch 264/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5127 - acc: 0.7898 - val_loss: 0.4827 - val_acc: 0.8158\n",
            "Epoch 265/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5151 - acc: 0.7875 - val_loss: 0.4793 - val_acc: 0.8164\n",
            "Epoch 266/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5200 - acc: 0.7919 - val_loss: 0.4764 - val_acc: 0.8109\n",
            "Epoch 267/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4839 - acc: 0.8055 - val_loss: 0.4643 - val_acc: 0.8096\n",
            "Epoch 268/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5219 - acc: 0.7896 - val_loss: 0.4779 - val_acc: 0.8096\n",
            "Epoch 269/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4966 - acc: 0.8033 - val_loss: 0.4827 - val_acc: 0.8022\n",
            "Epoch 270/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4995 - acc: 0.7942 - val_loss: 0.4614 - val_acc: 0.8269\n",
            "Epoch 271/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4999 - acc: 0.7980 - val_loss: 0.4586 - val_acc: 0.8214\n",
            "Epoch 272/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4927 - acc: 0.8022 - val_loss: 0.4627 - val_acc: 0.8257\n",
            "Epoch 273/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5026 - acc: 0.7967 - val_loss: 0.4512 - val_acc: 0.8214\n",
            "Epoch 274/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5000 - acc: 0.7930 - val_loss: 0.4837 - val_acc: 0.8164\n",
            "Epoch 275/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5019 - acc: 0.7958 - val_loss: 0.4569 - val_acc: 0.8307\n",
            "Epoch 276/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5160 - acc: 0.7914 - val_loss: 0.4641 - val_acc: 0.8245\n",
            "Epoch 277/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5099 - acc: 0.7964 - val_loss: 0.4612 - val_acc: 0.8152\n",
            "Epoch 278/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4938 - acc: 0.7998 - val_loss: 0.4556 - val_acc: 0.8220\n",
            "Epoch 279/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4910 - acc: 0.8010 - val_loss: 0.4599 - val_acc: 0.8133\n",
            "Epoch 280/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5019 - acc: 0.7969 - val_loss: 0.4636 - val_acc: 0.8220\n",
            "Epoch 281/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5010 - acc: 0.7951 - val_loss: 0.4664 - val_acc: 0.8084\n",
            "Epoch 282/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4970 - acc: 0.7921 - val_loss: 0.4680 - val_acc: 0.8164\n",
            "Epoch 283/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.5108 - acc: 0.7896 - val_loss: 0.4841 - val_acc: 0.8053\n",
            "Epoch 284/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4991 - acc: 0.8020 - val_loss: 0.4542 - val_acc: 0.8269\n",
            "Epoch 285/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4977 - acc: 0.7968 - val_loss: 0.4774 - val_acc: 0.8109\n",
            "Epoch 286/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4923 - acc: 0.7963 - val_loss: 0.4543 - val_acc: 0.8208\n",
            "Epoch 287/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5000 - acc: 0.7953 - val_loss: 0.4542 - val_acc: 0.8121\n",
            "Epoch 288/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5043 - acc: 0.7953 - val_loss: 0.4557 - val_acc: 0.8152\n",
            "Epoch 289/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4980 - acc: 0.7969 - val_loss: 0.4915 - val_acc: 0.8121\n",
            "Epoch 290/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4935 - acc: 0.7991 - val_loss: 0.5579 - val_acc: 0.7695\n",
            "Epoch 291/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5122 - acc: 0.7972 - val_loss: 0.5101 - val_acc: 0.7892\n",
            "Epoch 292/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4903 - acc: 0.7995 - val_loss: 0.4886 - val_acc: 0.8022\n",
            "Epoch 293/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5029 - acc: 0.7960 - val_loss: 0.4929 - val_acc: 0.8115\n",
            "Epoch 294/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4950 - acc: 0.7969 - val_loss: 0.4830 - val_acc: 0.8115\n",
            "Epoch 295/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5110 - acc: 0.7895 - val_loss: 0.4716 - val_acc: 0.8066\n",
            "Epoch 296/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4907 - acc: 0.8047 - val_loss: 0.4903 - val_acc: 0.7985\n",
            "Epoch 297/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5050 - acc: 0.7942 - val_loss: 0.4598 - val_acc: 0.8152\n",
            "Epoch 298/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5026 - acc: 0.7963 - val_loss: 0.4852 - val_acc: 0.8072\n",
            "Epoch 299/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4887 - acc: 0.8031 - val_loss: 0.4780 - val_acc: 0.8084\n",
            "Epoch 300/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4901 - acc: 0.7997 - val_loss: 0.4794 - val_acc: 0.8140\n",
            "Epoch 301/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4970 - acc: 0.8019 - val_loss: 0.4574 - val_acc: 0.8245\n",
            "Epoch 302/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4891 - acc: 0.8013 - val_loss: 0.4575 - val_acc: 0.8257\n",
            "Epoch 303/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5021 - acc: 0.7974 - val_loss: 0.4801 - val_acc: 0.8127\n",
            "Epoch 304/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5012 - acc: 0.7956 - val_loss: 0.4485 - val_acc: 0.8208\n",
            "Epoch 305/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4873 - acc: 0.8072 - val_loss: 0.4512 - val_acc: 0.8294\n",
            "Epoch 306/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4905 - acc: 0.8098 - val_loss: 0.4990 - val_acc: 0.8047\n",
            "Epoch 307/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4959 - acc: 0.8015 - val_loss: 0.4960 - val_acc: 0.8127\n",
            "Epoch 308/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4800 - acc: 0.8033 - val_loss: 0.4589 - val_acc: 0.8164\n",
            "Epoch 309/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4838 - acc: 0.8082 - val_loss: 0.4754 - val_acc: 0.8263\n",
            "Epoch 310/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4893 - acc: 0.8047 - val_loss: 0.5033 - val_acc: 0.8010\n",
            "Epoch 311/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4911 - acc: 0.8034 - val_loss: 0.4701 - val_acc: 0.8183\n",
            "Epoch 312/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4774 - acc: 0.8088 - val_loss: 0.4828 - val_acc: 0.8121\n",
            "Epoch 313/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4938 - acc: 0.8037 - val_loss: 0.4723 - val_acc: 0.8177\n",
            "Epoch 314/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4796 - acc: 0.8023 - val_loss: 0.4638 - val_acc: 0.8183\n",
            "Epoch 315/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4940 - acc: 0.8041 - val_loss: 0.4610 - val_acc: 0.8269\n",
            "Epoch 316/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4910 - acc: 0.8003 - val_loss: 0.4532 - val_acc: 0.8269\n",
            "Epoch 317/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4872 - acc: 0.8023 - val_loss: 0.4801 - val_acc: 0.8047\n",
            "Epoch 318/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4866 - acc: 0.7965 - val_loss: 0.4737 - val_acc: 0.8158\n",
            "Epoch 319/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4829 - acc: 0.8047 - val_loss: 0.4702 - val_acc: 0.8189\n",
            "Epoch 320/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.5029 - acc: 0.7929 - val_loss: 0.4730 - val_acc: 0.8121\n",
            "Epoch 321/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4878 - acc: 0.8078 - val_loss: 0.4701 - val_acc: 0.8066\n",
            "Epoch 322/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4975 - acc: 0.7969 - val_loss: 0.4696 - val_acc: 0.8257\n",
            "Epoch 323/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4897 - acc: 0.8077 - val_loss: 0.4419 - val_acc: 0.8307\n",
            "Epoch 324/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4853 - acc: 0.8029 - val_loss: 0.4533 - val_acc: 0.8313\n",
            "Epoch 325/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4886 - acc: 0.8009 - val_loss: 0.4837 - val_acc: 0.8152\n",
            "Epoch 326/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4846 - acc: 0.8026 - val_loss: 0.4479 - val_acc: 0.8294\n",
            "Epoch 327/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4928 - acc: 0.7991 - val_loss: 0.4698 - val_acc: 0.8331\n",
            "Epoch 328/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5048 - acc: 0.7993 - val_loss: 0.4500 - val_acc: 0.8300\n",
            "Epoch 329/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4719 - acc: 0.8090 - val_loss: 0.4518 - val_acc: 0.8276\n",
            "Epoch 330/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4785 - acc: 0.8068 - val_loss: 0.4892 - val_acc: 0.8053\n",
            "Epoch 331/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4836 - acc: 0.8034 - val_loss: 0.4626 - val_acc: 0.8276\n",
            "Epoch 332/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4953 - acc: 0.8021 - val_loss: 0.5139 - val_acc: 0.8066\n",
            "Epoch 333/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4930 - acc: 0.8018 - val_loss: 0.4544 - val_acc: 0.8220\n",
            "Epoch 334/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.5001 - acc: 0.7963 - val_loss: 0.4813 - val_acc: 0.8146\n",
            "Epoch 335/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4929 - acc: 0.7998 - val_loss: 0.4988 - val_acc: 0.8245\n",
            "Epoch 336/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4881 - acc: 0.8028 - val_loss: 0.4475 - val_acc: 0.8294\n",
            "Epoch 337/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4995 - acc: 0.8007 - val_loss: 0.4551 - val_acc: 0.8263\n",
            "Epoch 338/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4972 - acc: 0.8050 - val_loss: 0.4638 - val_acc: 0.8331\n",
            "Epoch 339/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4780 - acc: 0.8082 - val_loss: 0.4577 - val_acc: 0.8226\n",
            "Epoch 340/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4849 - acc: 0.8081 - val_loss: 0.4505 - val_acc: 0.8263\n",
            "Epoch 341/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4854 - acc: 0.8003 - val_loss: 0.4628 - val_acc: 0.8257\n",
            "Epoch 342/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4867 - acc: 0.8001 - val_loss: 0.4666 - val_acc: 0.8133\n",
            "Epoch 343/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4816 - acc: 0.8051 - val_loss: 0.4645 - val_acc: 0.8263\n",
            "Epoch 344/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4934 - acc: 0.8013 - val_loss: 0.4807 - val_acc: 0.8127\n",
            "Epoch 345/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4884 - acc: 0.8000 - val_loss: 0.4531 - val_acc: 0.8214\n",
            "Epoch 346/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4759 - acc: 0.8093 - val_loss: 0.4660 - val_acc: 0.8263\n",
            "Epoch 347/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4840 - acc: 0.8064 - val_loss: 0.4417 - val_acc: 0.8319\n",
            "Epoch 348/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4827 - acc: 0.8058 - val_loss: 0.4655 - val_acc: 0.8164\n",
            "Epoch 349/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4883 - acc: 0.8013 - val_loss: 0.4517 - val_acc: 0.8226\n",
            "Epoch 350/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4725 - acc: 0.8135 - val_loss: 0.4398 - val_acc: 0.8263\n",
            "Epoch 351/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4900 - acc: 0.8010 - val_loss: 0.4647 - val_acc: 0.8245\n",
            "Epoch 352/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4708 - acc: 0.8089 - val_loss: 0.4431 - val_acc: 0.8294\n",
            "Epoch 353/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4795 - acc: 0.8067 - val_loss: 0.4647 - val_acc: 0.8208\n",
            "Epoch 354/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4593 - acc: 0.8104 - val_loss: 0.4750 - val_acc: 0.8127\n",
            "Epoch 355/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4881 - acc: 0.8014 - val_loss: 0.4426 - val_acc: 0.8257\n",
            "Epoch 356/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4797 - acc: 0.8087 - val_loss: 0.4702 - val_acc: 0.8158\n",
            "Epoch 357/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4779 - acc: 0.8097 - val_loss: 0.4960 - val_acc: 0.8220\n",
            "Epoch 358/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4813 - acc: 0.8058 - val_loss: 0.4460 - val_acc: 0.8288\n",
            "Epoch 359/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4902 - acc: 0.8020 - val_loss: 0.4409 - val_acc: 0.8362\n",
            "Epoch 360/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4909 - acc: 0.8009 - val_loss: 0.4523 - val_acc: 0.8220\n",
            "Epoch 361/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4791 - acc: 0.8101 - val_loss: 0.4447 - val_acc: 0.8300\n",
            "Epoch 362/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4891 - acc: 0.8029 - val_loss: 0.4713 - val_acc: 0.8356\n",
            "Epoch 363/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4783 - acc: 0.8111 - val_loss: 0.4588 - val_acc: 0.8220\n",
            "Epoch 364/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4811 - acc: 0.8099 - val_loss: 0.4714 - val_acc: 0.8152\n",
            "Epoch 365/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4824 - acc: 0.8012 - val_loss: 0.4394 - val_acc: 0.8319\n",
            "Epoch 366/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4739 - acc: 0.8106 - val_loss: 0.4410 - val_acc: 0.8282\n",
            "Epoch 367/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4818 - acc: 0.8033 - val_loss: 0.4576 - val_acc: 0.8208\n",
            "Epoch 368/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4732 - acc: 0.8100 - val_loss: 0.4735 - val_acc: 0.8158\n",
            "Epoch 369/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4912 - acc: 0.8024 - val_loss: 0.4405 - val_acc: 0.8356\n",
            "Epoch 370/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4793 - acc: 0.8031 - val_loss: 0.4520 - val_acc: 0.8245\n",
            "Epoch 371/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4789 - acc: 0.8100 - val_loss: 0.5408 - val_acc: 0.7905\n",
            "Epoch 372/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4749 - acc: 0.8048 - val_loss: 0.4560 - val_acc: 0.8344\n",
            "Epoch 373/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4792 - acc: 0.8074 - val_loss: 0.4888 - val_acc: 0.8121\n",
            "Epoch 374/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4804 - acc: 0.8029 - val_loss: 0.4354 - val_acc: 0.8362\n",
            "Epoch 375/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4712 - acc: 0.8077 - val_loss: 0.4694 - val_acc: 0.8164\n",
            "Epoch 376/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4754 - acc: 0.8075 - val_loss: 0.5857 - val_acc: 0.7670\n",
            "Epoch 377/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4814 - acc: 0.8047 - val_loss: 0.4480 - val_acc: 0.8313\n",
            "Epoch 378/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4654 - acc: 0.8132 - val_loss: 0.4652 - val_acc: 0.8269\n",
            "Epoch 379/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4686 - acc: 0.8104 - val_loss: 0.4696 - val_acc: 0.8059\n",
            "Epoch 380/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4848 - acc: 0.8002 - val_loss: 0.4513 - val_acc: 0.8220\n",
            "Epoch 381/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4802 - acc: 0.8086 - val_loss: 0.4330 - val_acc: 0.8344\n",
            "Epoch 382/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4769 - acc: 0.8086 - val_loss: 0.5255 - val_acc: 0.7967\n",
            "Epoch 383/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4764 - acc: 0.8098 - val_loss: 0.4439 - val_acc: 0.8232\n",
            "Epoch 384/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4647 - acc: 0.8188 - val_loss: 0.4377 - val_acc: 0.8337\n",
            "Epoch 385/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4864 - acc: 0.8007 - val_loss: 0.4614 - val_acc: 0.8263\n",
            "Epoch 386/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4836 - acc: 0.8077 - val_loss: 0.4341 - val_acc: 0.8356\n",
            "Epoch 387/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4805 - acc: 0.8066 - val_loss: 0.4520 - val_acc: 0.8263\n",
            "Epoch 388/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4765 - acc: 0.8165 - val_loss: 0.4446 - val_acc: 0.8276\n",
            "Epoch 389/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4767 - acc: 0.8098 - val_loss: 0.4402 - val_acc: 0.8282\n",
            "Epoch 390/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4782 - acc: 0.8077 - val_loss: 0.4367 - val_acc: 0.8344\n",
            "Epoch 391/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4712 - acc: 0.8091 - val_loss: 0.4680 - val_acc: 0.8158\n",
            "Epoch 392/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4691 - acc: 0.8090 - val_loss: 0.4604 - val_acc: 0.8232\n",
            "Epoch 393/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4792 - acc: 0.8070 - val_loss: 0.4516 - val_acc: 0.8350\n",
            "Epoch 394/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4546 - acc: 0.8170 - val_loss: 0.4931 - val_acc: 0.7948\n",
            "Epoch 395/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4783 - acc: 0.8060 - val_loss: 0.4419 - val_acc: 0.8393\n",
            "Epoch 396/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4879 - acc: 0.8081 - val_loss: 0.4695 - val_acc: 0.8140\n",
            "Epoch 397/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4651 - acc: 0.8117 - val_loss: 0.5192 - val_acc: 0.7880\n",
            "Epoch 398/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4924 - acc: 0.8011 - val_loss: 0.4439 - val_acc: 0.8245\n",
            "Epoch 399/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4609 - acc: 0.8165 - val_loss: 0.4705 - val_acc: 0.8189\n",
            "Epoch 400/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4703 - acc: 0.8094 - val_loss: 0.4951 - val_acc: 0.7911\n",
            "Epoch 401/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4697 - acc: 0.8060 - val_loss: 0.4853 - val_acc: 0.8078\n",
            "Epoch 402/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4475 - acc: 0.8218 - val_loss: 0.4756 - val_acc: 0.8282\n",
            "Epoch 403/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4828 - acc: 0.8041 - val_loss: 0.4830 - val_acc: 0.8152\n",
            "Epoch 404/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4708 - acc: 0.8088 - val_loss: 0.4716 - val_acc: 0.8109\n",
            "Epoch 405/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4676 - acc: 0.8139 - val_loss: 0.4456 - val_acc: 0.8325\n",
            "Epoch 406/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4696 - acc: 0.8108 - val_loss: 0.4590 - val_acc: 0.8263\n",
            "Epoch 407/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4777 - acc: 0.8059 - val_loss: 0.5268 - val_acc: 0.7818\n",
            "Epoch 408/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4702 - acc: 0.8088 - val_loss: 0.4852 - val_acc: 0.8084\n",
            "Epoch 409/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4828 - acc: 0.8017 - val_loss: 0.4508 - val_acc: 0.8245\n",
            "Epoch 410/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4701 - acc: 0.8087 - val_loss: 0.4537 - val_acc: 0.8251\n",
            "Epoch 411/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4690 - acc: 0.8148 - val_loss: 0.4945 - val_acc: 0.7967\n",
            "Epoch 412/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4707 - acc: 0.8056 - val_loss: 0.4672 - val_acc: 0.8208\n",
            "Epoch 413/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4738 - acc: 0.8077 - val_loss: 0.4612 - val_acc: 0.8226\n",
            "Epoch 414/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4736 - acc: 0.8082 - val_loss: 0.4549 - val_acc: 0.8232\n",
            "Epoch 415/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4623 - acc: 0.8186 - val_loss: 0.4637 - val_acc: 0.8245\n",
            "Epoch 416/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4591 - acc: 0.8126 - val_loss: 0.4690 - val_acc: 0.8152\n",
            "Epoch 417/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4655 - acc: 0.8095 - val_loss: 0.4721 - val_acc: 0.8158\n",
            "Epoch 418/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4791 - acc: 0.8039 - val_loss: 0.4546 - val_acc: 0.8214\n",
            "Epoch 419/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4724 - acc: 0.8110 - val_loss: 0.4480 - val_acc: 0.8251\n",
            "Epoch 420/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4585 - acc: 0.8142 - val_loss: 0.4603 - val_acc: 0.8263\n",
            "Epoch 421/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4661 - acc: 0.8121 - val_loss: 0.4821 - val_acc: 0.8214\n",
            "Epoch 422/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4717 - acc: 0.8103 - val_loss: 0.4571 - val_acc: 0.8140\n",
            "Epoch 423/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4693 - acc: 0.8079 - val_loss: 0.4735 - val_acc: 0.8171\n",
            "Epoch 424/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4758 - acc: 0.8113 - val_loss: 0.4638 - val_acc: 0.8232\n",
            "Epoch 425/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4694 - acc: 0.8110 - val_loss: 0.4652 - val_acc: 0.8269\n",
            "Epoch 426/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4576 - acc: 0.8143 - val_loss: 0.4545 - val_acc: 0.8245\n",
            "Epoch 427/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4738 - acc: 0.8044 - val_loss: 0.4399 - val_acc: 0.8294\n",
            "Epoch 428/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4628 - acc: 0.8106 - val_loss: 0.4596 - val_acc: 0.8257\n",
            "Epoch 429/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4759 - acc: 0.8074 - val_loss: 0.4511 - val_acc: 0.8424\n",
            "Epoch 430/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4593 - acc: 0.8164 - val_loss: 0.4513 - val_acc: 0.8307\n",
            "Epoch 431/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4824 - acc: 0.8096 - val_loss: 0.4575 - val_acc: 0.8171\n",
            "Epoch 432/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4766 - acc: 0.8023 - val_loss: 0.4748 - val_acc: 0.8245\n",
            "Epoch 433/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4722 - acc: 0.8143 - val_loss: 0.5154 - val_acc: 0.7960\n",
            "Epoch 434/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4796 - acc: 0.8033 - val_loss: 0.4467 - val_acc: 0.8288\n",
            "Epoch 435/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4706 - acc: 0.8108 - val_loss: 0.4636 - val_acc: 0.8276\n",
            "Epoch 436/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4640 - acc: 0.8162 - val_loss: 0.4447 - val_acc: 0.8325\n",
            "Epoch 437/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4741 - acc: 0.8093 - val_loss: 0.4804 - val_acc: 0.8189\n",
            "Epoch 438/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4637 - acc: 0.8101 - val_loss: 0.4579 - val_acc: 0.8288\n",
            "Epoch 439/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4743 - acc: 0.8019 - val_loss: 0.4859 - val_acc: 0.8022\n",
            "Epoch 440/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4657 - acc: 0.8080 - val_loss: 0.4882 - val_acc: 0.8004\n",
            "Epoch 441/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4770 - acc: 0.8069 - val_loss: 0.4826 - val_acc: 0.7985\n",
            "Epoch 442/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4728 - acc: 0.8115 - val_loss: 0.4675 - val_acc: 0.8146\n",
            "Epoch 443/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4939 - acc: 0.7960 - val_loss: 0.4828 - val_acc: 0.8109\n",
            "Epoch 444/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4737 - acc: 0.8083 - val_loss: 0.4489 - val_acc: 0.8239\n",
            "Epoch 445/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4594 - acc: 0.8164 - val_loss: 0.4511 - val_acc: 0.8337\n",
            "Epoch 446/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4731 - acc: 0.8088 - val_loss: 0.4581 - val_acc: 0.8239\n",
            "Epoch 447/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4644 - acc: 0.8169 - val_loss: 0.4931 - val_acc: 0.8053\n",
            "Epoch 448/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4600 - acc: 0.8176 - val_loss: 0.4760 - val_acc: 0.8096\n",
            "Epoch 449/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4817 - acc: 0.8044 - val_loss: 0.5056 - val_acc: 0.7991\n",
            "Epoch 450/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4727 - acc: 0.8078 - val_loss: 0.4735 - val_acc: 0.8269\n",
            "Epoch 451/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4571 - acc: 0.8177 - val_loss: 0.4716 - val_acc: 0.8171\n",
            "Epoch 452/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4810 - acc: 0.8102 - val_loss: 0.4525 - val_acc: 0.8269\n",
            "Epoch 453/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4608 - acc: 0.8092 - val_loss: 0.4414 - val_acc: 0.8282\n",
            "Epoch 454/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4699 - acc: 0.8161 - val_loss: 0.4384 - val_acc: 0.8232\n",
            "Epoch 455/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4698 - acc: 0.8103 - val_loss: 0.4430 - val_acc: 0.8276\n",
            "Epoch 456/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4586 - acc: 0.8157 - val_loss: 0.4406 - val_acc: 0.8269\n",
            "Epoch 457/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4540 - acc: 0.8203 - val_loss: 0.4356 - val_acc: 0.8350\n",
            "Epoch 458/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4612 - acc: 0.8166 - val_loss: 0.4384 - val_acc: 0.8307\n",
            "Epoch 459/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4674 - acc: 0.8100 - val_loss: 0.4715 - val_acc: 0.8158\n",
            "Epoch 460/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4618 - acc: 0.8114 - val_loss: 0.4652 - val_acc: 0.8263\n",
            "Epoch 461/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4745 - acc: 0.8134 - val_loss: 0.4975 - val_acc: 0.7998\n",
            "Epoch 462/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4793 - acc: 0.8083 - val_loss: 0.4405 - val_acc: 0.8331\n",
            "Epoch 463/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4575 - acc: 0.8181 - val_loss: 0.4477 - val_acc: 0.8263\n",
            "Epoch 464/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4756 - acc: 0.8076 - val_loss: 0.5341 - val_acc: 0.7973\n",
            "Epoch 465/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4625 - acc: 0.8118 - val_loss: 0.4567 - val_acc: 0.8282\n",
            "Epoch 466/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4695 - acc: 0.8148 - val_loss: 0.5044 - val_acc: 0.8072\n",
            "Epoch 467/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4697 - acc: 0.8104 - val_loss: 0.4334 - val_acc: 0.8325\n",
            "Epoch 468/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4636 - acc: 0.8129 - val_loss: 0.4318 - val_acc: 0.8362\n",
            "Epoch 469/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4488 - acc: 0.8183 - val_loss: 0.4449 - val_acc: 0.8313\n",
            "Epoch 470/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4604 - acc: 0.8125 - val_loss: 0.4853 - val_acc: 0.8177\n",
            "Epoch 471/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4721 - acc: 0.8103 - val_loss: 0.4714 - val_acc: 0.8158\n",
            "Epoch 472/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4585 - acc: 0.8195 - val_loss: 0.4442 - val_acc: 0.8381\n",
            "Epoch 473/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4586 - acc: 0.8142 - val_loss: 0.4428 - val_acc: 0.8288\n",
            "Epoch 474/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4656 - acc: 0.8104 - val_loss: 0.4406 - val_acc: 0.8368\n",
            "Epoch 475/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4625 - acc: 0.8119 - val_loss: 0.5130 - val_acc: 0.8016\n",
            "Epoch 476/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4702 - acc: 0.8076 - val_loss: 0.4575 - val_acc: 0.8288\n",
            "Epoch 477/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4798 - acc: 0.8089 - val_loss: 0.4327 - val_acc: 0.8344\n",
            "Epoch 478/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4465 - acc: 0.8176 - val_loss: 0.4839 - val_acc: 0.8189\n",
            "Epoch 479/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4726 - acc: 0.8047 - val_loss: 0.4841 - val_acc: 0.8201\n",
            "Epoch 480/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4650 - acc: 0.8099 - val_loss: 0.4364 - val_acc: 0.8300\n",
            "Epoch 481/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4537 - acc: 0.8126 - val_loss: 0.4662 - val_acc: 0.8158\n",
            "Epoch 482/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4452 - acc: 0.8240 - val_loss: 0.5314 - val_acc: 0.7960\n",
            "Epoch 483/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4759 - acc: 0.8104 - val_loss: 0.4518 - val_acc: 0.8257\n",
            "Epoch 484/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4641 - acc: 0.8194 - val_loss: 0.4482 - val_acc: 0.8294\n",
            "Epoch 485/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4703 - acc: 0.8095 - val_loss: 0.4684 - val_acc: 0.8164\n",
            "Epoch 486/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4519 - acc: 0.8223 - val_loss: 0.4588 - val_acc: 0.8288\n",
            "Epoch 487/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4564 - acc: 0.8194 - val_loss: 0.4560 - val_acc: 0.8239\n",
            "Epoch 488/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4630 - acc: 0.8130 - val_loss: 0.4589 - val_acc: 0.8381\n",
            "Epoch 489/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4587 - acc: 0.8209 - val_loss: 0.4470 - val_acc: 0.8344\n",
            "Epoch 490/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4495 - acc: 0.8186 - val_loss: 0.4377 - val_acc: 0.8430\n",
            "Epoch 491/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4874 - acc: 0.8044 - val_loss: 0.4464 - val_acc: 0.8344\n",
            "Epoch 492/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4478 - acc: 0.8185 - val_loss: 0.5231 - val_acc: 0.7960\n",
            "Epoch 493/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4509 - acc: 0.8228 - val_loss: 0.4840 - val_acc: 0.8232\n",
            "Epoch 494/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4600 - acc: 0.8137 - val_loss: 0.4467 - val_acc: 0.8362\n",
            "Epoch 495/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4599 - acc: 0.8138 - val_loss: 0.4448 - val_acc: 0.8288\n",
            "Epoch 496/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4549 - acc: 0.8162 - val_loss: 0.4664 - val_acc: 0.8201\n",
            "Epoch 497/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4531 - acc: 0.8170 - val_loss: 0.4735 - val_acc: 0.8109\n",
            "Epoch 498/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4602 - acc: 0.8171 - val_loss: 0.4524 - val_acc: 0.8257\n",
            "Epoch 499/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4542 - acc: 0.8213 - val_loss: 0.4693 - val_acc: 0.8245\n",
            "Epoch 500/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4643 - acc: 0.8158 - val_loss: 0.4393 - val_acc: 0.8368\n",
            "Epoch 501/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4585 - acc: 0.8158 - val_loss: 0.4723 - val_acc: 0.8300\n",
            "Epoch 502/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4728 - acc: 0.8138 - val_loss: 0.4516 - val_acc: 0.8288\n",
            "Epoch 503/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4597 - acc: 0.8114 - val_loss: 0.4569 - val_acc: 0.8319\n",
            "Epoch 504/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4716 - acc: 0.8111 - val_loss: 0.4789 - val_acc: 0.8152\n",
            "Epoch 505/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4718 - acc: 0.8145 - val_loss: 0.4897 - val_acc: 0.8109\n",
            "Epoch 506/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4558 - acc: 0.8181 - val_loss: 0.4589 - val_acc: 0.8362\n",
            "Epoch 507/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4582 - acc: 0.8140 - val_loss: 0.4426 - val_acc: 0.8337\n",
            "Epoch 508/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4411 - acc: 0.8184 - val_loss: 0.4737 - val_acc: 0.8177\n",
            "Epoch 509/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4576 - acc: 0.8181 - val_loss: 0.4629 - val_acc: 0.8208\n",
            "Epoch 510/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4516 - acc: 0.8150 - val_loss: 0.4505 - val_acc: 0.8375\n",
            "Epoch 511/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4669 - acc: 0.8113 - val_loss: 0.4531 - val_acc: 0.8208\n",
            "Epoch 512/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4561 - acc: 0.8152 - val_loss: 0.4671 - val_acc: 0.8263\n",
            "Epoch 513/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4602 - acc: 0.8184 - val_loss: 0.4479 - val_acc: 0.8276\n",
            "Epoch 514/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4681 - acc: 0.8115 - val_loss: 0.4951 - val_acc: 0.8041\n",
            "Epoch 515/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4596 - acc: 0.8172 - val_loss: 0.4366 - val_acc: 0.8319\n",
            "Epoch 516/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4582 - acc: 0.8148 - val_loss: 0.4752 - val_acc: 0.8164\n",
            "Epoch 517/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4509 - acc: 0.8231 - val_loss: 0.4837 - val_acc: 0.8109\n",
            "Epoch 518/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4634 - acc: 0.8137 - val_loss: 0.4717 - val_acc: 0.8152\n",
            "Epoch 519/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4655 - acc: 0.8087 - val_loss: 0.4491 - val_acc: 0.8319\n",
            "Epoch 520/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4501 - acc: 0.8234 - val_loss: 0.4527 - val_acc: 0.8195\n",
            "Epoch 521/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4551 - acc: 0.8133 - val_loss: 0.4511 - val_acc: 0.8226\n",
            "Epoch 522/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4653 - acc: 0.8097 - val_loss: 0.4669 - val_acc: 0.8282\n",
            "Epoch 523/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4622 - acc: 0.8147 - val_loss: 0.4816 - val_acc: 0.8078\n",
            "Epoch 524/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4599 - acc: 0.8120 - val_loss: 0.4377 - val_acc: 0.8307\n",
            "Epoch 525/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4601 - acc: 0.8143 - val_loss: 0.4616 - val_acc: 0.8263\n",
            "Epoch 526/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4536 - acc: 0.8223 - val_loss: 0.4798 - val_acc: 0.8294\n",
            "Epoch 527/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4493 - acc: 0.8185 - val_loss: 0.4448 - val_acc: 0.8263\n",
            "Epoch 528/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4563 - acc: 0.8171 - val_loss: 0.4479 - val_acc: 0.8245\n",
            "Epoch 529/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4581 - acc: 0.8170 - val_loss: 0.5367 - val_acc: 0.7750\n",
            "Epoch 530/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4427 - acc: 0.8248 - val_loss: 0.4579 - val_acc: 0.8251\n",
            "Epoch 531/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4642 - acc: 0.8113 - val_loss: 0.4994 - val_acc: 0.7973\n",
            "Epoch 532/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4570 - acc: 0.8172 - val_loss: 0.4519 - val_acc: 0.8201\n",
            "Epoch 533/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4485 - acc: 0.8148 - val_loss: 0.4537 - val_acc: 0.8245\n",
            "Epoch 534/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4552 - acc: 0.8213 - val_loss: 0.4468 - val_acc: 0.8313\n",
            "Epoch 535/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4568 - acc: 0.8204 - val_loss: 0.4391 - val_acc: 0.8232\n",
            "Epoch 536/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4606 - acc: 0.8135 - val_loss: 0.4512 - val_acc: 0.8201\n",
            "Epoch 537/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4623 - acc: 0.8187 - val_loss: 0.4825 - val_acc: 0.8127\n",
            "Epoch 538/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4593 - acc: 0.8150 - val_loss: 0.4484 - val_acc: 0.8214\n",
            "Epoch 539/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4443 - acc: 0.8235 - val_loss: 0.4406 - val_acc: 0.8269\n",
            "Epoch 540/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4599 - acc: 0.8150 - val_loss: 0.4462 - val_acc: 0.8294\n",
            "Epoch 541/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4448 - acc: 0.8227 - val_loss: 0.4451 - val_acc: 0.8269\n",
            "Epoch 542/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4581 - acc: 0.8160 - val_loss: 0.4568 - val_acc: 0.8288\n",
            "Epoch 543/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4577 - acc: 0.8221 - val_loss: 0.4685 - val_acc: 0.8350\n",
            "Epoch 544/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4506 - acc: 0.8190 - val_loss: 0.4509 - val_acc: 0.8307\n",
            "Epoch 545/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4460 - acc: 0.8225 - val_loss: 0.4434 - val_acc: 0.8350\n",
            "Epoch 546/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4423 - acc: 0.8238 - val_loss: 0.4651 - val_acc: 0.8152\n",
            "Epoch 547/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4550 - acc: 0.8187 - val_loss: 0.4431 - val_acc: 0.8307\n",
            "Epoch 548/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4680 - acc: 0.8089 - val_loss: 0.4915 - val_acc: 0.7936\n",
            "Epoch 549/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4578 - acc: 0.8148 - val_loss: 0.4703 - val_acc: 0.8201\n",
            "Epoch 550/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4454 - acc: 0.8179 - val_loss: 0.5310 - val_acc: 0.8053\n",
            "Epoch 551/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4533 - acc: 0.8197 - val_loss: 0.4784 - val_acc: 0.8133\n",
            "Epoch 552/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4462 - acc: 0.8230 - val_loss: 0.4831 - val_acc: 0.8127\n",
            "Epoch 553/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4550 - acc: 0.8178 - val_loss: 0.4364 - val_acc: 0.8356\n",
            "Epoch 554/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4503 - acc: 0.8197 - val_loss: 0.4749 - val_acc: 0.8226\n",
            "Epoch 555/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4534 - acc: 0.8161 - val_loss: 0.4852 - val_acc: 0.8072\n",
            "Epoch 556/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4565 - acc: 0.8161 - val_loss: 0.4634 - val_acc: 0.8232\n",
            "Epoch 557/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4455 - acc: 0.8228 - val_loss: 0.4538 - val_acc: 0.8276\n",
            "Epoch 558/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4405 - acc: 0.8270 - val_loss: 0.4708 - val_acc: 0.8121\n",
            "Epoch 559/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4617 - acc: 0.8158 - val_loss: 0.4488 - val_acc: 0.8220\n",
            "Epoch 560/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4510 - acc: 0.8184 - val_loss: 0.5041 - val_acc: 0.8133\n",
            "Epoch 561/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4661 - acc: 0.8133 - val_loss: 0.4549 - val_acc: 0.8183\n",
            "Epoch 562/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4327 - acc: 0.8288 - val_loss: 0.4359 - val_acc: 0.8325\n",
            "Epoch 563/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4628 - acc: 0.8177 - val_loss: 0.4647 - val_acc: 0.8158\n",
            "Epoch 564/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4367 - acc: 0.8301 - val_loss: 0.5610 - val_acc: 0.7695\n",
            "Epoch 565/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4628 - acc: 0.8119 - val_loss: 0.4534 - val_acc: 0.8189\n",
            "Epoch 566/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4423 - acc: 0.8247 - val_loss: 0.5414 - val_acc: 0.7868\n",
            "Epoch 567/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4648 - acc: 0.8173 - val_loss: 0.4641 - val_acc: 0.8177\n",
            "Epoch 568/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4447 - acc: 0.8212 - val_loss: 0.4972 - val_acc: 0.8220\n",
            "Epoch 569/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4590 - acc: 0.8172 - val_loss: 0.4371 - val_acc: 0.8356\n",
            "Epoch 570/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4557 - acc: 0.8181 - val_loss: 0.4878 - val_acc: 0.8214\n",
            "Epoch 571/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4438 - acc: 0.8276 - val_loss: 0.4382 - val_acc: 0.8368\n",
            "Epoch 572/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4539 - acc: 0.8213 - val_loss: 0.4319 - val_acc: 0.8350\n",
            "Epoch 573/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4543 - acc: 0.8157 - val_loss: 0.4385 - val_acc: 0.8375\n",
            "Epoch 574/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4441 - acc: 0.8224 - val_loss: 0.4556 - val_acc: 0.8356\n",
            "Epoch 575/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4551 - acc: 0.8149 - val_loss: 0.4486 - val_acc: 0.8325\n",
            "Epoch 576/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4481 - acc: 0.8188 - val_loss: 0.4343 - val_acc: 0.8399\n",
            "Epoch 577/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4504 - acc: 0.8217 - val_loss: 0.4498 - val_acc: 0.8325\n",
            "Epoch 578/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4493 - acc: 0.8182 - val_loss: 0.4350 - val_acc: 0.8362\n",
            "Epoch 579/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4460 - acc: 0.8258 - val_loss: 0.4873 - val_acc: 0.8072\n",
            "Epoch 580/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4530 - acc: 0.8203 - val_loss: 0.4543 - val_acc: 0.8300\n",
            "Epoch 581/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4643 - acc: 0.8139 - val_loss: 0.4382 - val_acc: 0.8337\n",
            "Epoch 582/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4550 - acc: 0.8142 - val_loss: 0.4346 - val_acc: 0.8393\n",
            "Epoch 583/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4596 - acc: 0.8168 - val_loss: 0.4534 - val_acc: 0.8245\n",
            "Epoch 584/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4497 - acc: 0.8194 - val_loss: 0.4567 - val_acc: 0.8337\n",
            "Epoch 585/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4404 - acc: 0.8221 - val_loss: 0.4459 - val_acc: 0.8325\n",
            "Epoch 586/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4363 - acc: 0.8282 - val_loss: 0.4510 - val_acc: 0.8337\n",
            "Epoch 587/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4508 - acc: 0.8260 - val_loss: 0.4561 - val_acc: 0.8325\n",
            "Epoch 588/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4497 - acc: 0.8232 - val_loss: 0.4454 - val_acc: 0.8263\n",
            "Epoch 589/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4611 - acc: 0.8129 - val_loss: 0.4680 - val_acc: 0.8164\n",
            "Epoch 590/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4397 - acc: 0.8220 - val_loss: 0.4375 - val_acc: 0.8276\n",
            "Epoch 591/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4549 - acc: 0.8207 - val_loss: 0.4436 - val_acc: 0.8381\n",
            "Epoch 592/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4368 - acc: 0.8186 - val_loss: 0.5065 - val_acc: 0.7911\n",
            "Epoch 593/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4500 - acc: 0.8230 - val_loss: 0.4379 - val_acc: 0.8313\n",
            "Epoch 594/2500\n",
            "227/227 [==============================] - 7s 30ms/step - loss: 0.4364 - acc: 0.8270 - val_loss: 0.4706 - val_acc: 0.8152\n",
            "Epoch 595/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4533 - acc: 0.8180 - val_loss: 0.4679 - val_acc: 0.8362\n",
            "Epoch 596/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4554 - acc: 0.8227 - val_loss: 0.4833 - val_acc: 0.8319\n",
            "Epoch 597/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4545 - acc: 0.8192 - val_loss: 0.4391 - val_acc: 0.8387\n",
            "Epoch 598/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4509 - acc: 0.8206 - val_loss: 0.4347 - val_acc: 0.8300\n",
            "Epoch 599/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4542 - acc: 0.8162 - val_loss: 0.4557 - val_acc: 0.8245\n",
            "Epoch 600/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4395 - acc: 0.8173 - val_loss: 0.4638 - val_acc: 0.8276\n",
            "Epoch 601/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4434 - acc: 0.8203 - val_loss: 0.5205 - val_acc: 0.7973\n",
            "Epoch 602/2500\n",
            "227/227 [==============================] - 7s 30ms/step - loss: 0.4548 - acc: 0.8177 - val_loss: 0.5023 - val_acc: 0.8171\n",
            "Epoch 603/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4567 - acc: 0.8143 - val_loss: 0.4433 - val_acc: 0.8294\n",
            "Epoch 604/2500\n",
            "227/227 [==============================] - 7s 30ms/step - loss: 0.4443 - acc: 0.8232 - val_loss: 0.4561 - val_acc: 0.8412\n",
            "Epoch 605/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4610 - acc: 0.8173 - val_loss: 0.4729 - val_acc: 0.8232\n",
            "Epoch 606/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4508 - acc: 0.8190 - val_loss: 0.4608 - val_acc: 0.8195\n",
            "Epoch 607/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4574 - acc: 0.8162 - val_loss: 0.4792 - val_acc: 0.8208\n",
            "Epoch 608/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4429 - acc: 0.8204 - val_loss: 0.4414 - val_acc: 0.8393\n",
            "Epoch 609/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4495 - acc: 0.8164 - val_loss: 0.4934 - val_acc: 0.8282\n",
            "Epoch 610/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4486 - acc: 0.8195 - val_loss: 0.4571 - val_acc: 0.8288\n",
            "Epoch 611/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4483 - acc: 0.8243 - val_loss: 0.4507 - val_acc: 0.8307\n",
            "Epoch 612/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4486 - acc: 0.8247 - val_loss: 0.4624 - val_acc: 0.8257\n",
            "Epoch 613/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4479 - acc: 0.8220 - val_loss: 0.4659 - val_acc: 0.8337\n",
            "Epoch 614/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4560 - acc: 0.8190 - val_loss: 0.4680 - val_acc: 0.8368\n",
            "Epoch 615/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4369 - acc: 0.8228 - val_loss: 0.4578 - val_acc: 0.8362\n",
            "Epoch 616/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4380 - acc: 0.8269 - val_loss: 0.4929 - val_acc: 0.8201\n",
            "Epoch 617/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4652 - acc: 0.8162 - val_loss: 0.4352 - val_acc: 0.8436\n",
            "Epoch 618/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4558 - acc: 0.8170 - val_loss: 0.4645 - val_acc: 0.8257\n",
            "Epoch 619/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4682 - acc: 0.8135 - val_loss: 0.4621 - val_acc: 0.8331\n",
            "Epoch 620/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4280 - acc: 0.8318 - val_loss: 0.4472 - val_acc: 0.8282\n",
            "Epoch 621/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4471 - acc: 0.8234 - val_loss: 0.4914 - val_acc: 0.8109\n",
            "Epoch 622/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4501 - acc: 0.8209 - val_loss: 0.4698 - val_acc: 0.8269\n",
            "Epoch 623/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4480 - acc: 0.8220 - val_loss: 0.5095 - val_acc: 0.8066\n",
            "Epoch 624/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4437 - acc: 0.8241 - val_loss: 0.4687 - val_acc: 0.8307\n",
            "Epoch 625/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4601 - acc: 0.8195 - val_loss: 0.4475 - val_acc: 0.8344\n",
            "Epoch 626/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4451 - acc: 0.8181 - val_loss: 0.4398 - val_acc: 0.8399\n",
            "Epoch 627/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4465 - acc: 0.8213 - val_loss: 0.4668 - val_acc: 0.8331\n",
            "Epoch 628/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4402 - acc: 0.8239 - val_loss: 0.4536 - val_acc: 0.8337\n",
            "Epoch 629/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4435 - acc: 0.8245 - val_loss: 0.4582 - val_acc: 0.8362\n",
            "Epoch 630/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4450 - acc: 0.8237 - val_loss: 0.4720 - val_acc: 0.8263\n",
            "Epoch 631/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4385 - acc: 0.8259 - val_loss: 0.4732 - val_acc: 0.8325\n",
            "Epoch 632/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4324 - acc: 0.8245 - val_loss: 0.4904 - val_acc: 0.8214\n",
            "Epoch 633/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4445 - acc: 0.8259 - val_loss: 0.4459 - val_acc: 0.8337\n",
            "Epoch 634/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4262 - acc: 0.8293 - val_loss: 0.4619 - val_acc: 0.8344\n",
            "Epoch 635/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4464 - acc: 0.8224 - val_loss: 0.4576 - val_acc: 0.8226\n",
            "Epoch 636/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4399 - acc: 0.8233 - val_loss: 0.4706 - val_acc: 0.8282\n",
            "Epoch 637/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4468 - acc: 0.8211 - val_loss: 0.4372 - val_acc: 0.8430\n",
            "Epoch 638/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4483 - acc: 0.8188 - val_loss: 0.4742 - val_acc: 0.8189\n",
            "Epoch 639/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4384 - acc: 0.8240 - val_loss: 0.4774 - val_acc: 0.8381\n",
            "Epoch 640/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4429 - acc: 0.8231 - val_loss: 0.4745 - val_acc: 0.8239\n",
            "Epoch 641/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4473 - acc: 0.8204 - val_loss: 0.4569 - val_acc: 0.8325\n",
            "Epoch 642/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4496 - acc: 0.8180 - val_loss: 0.4827 - val_acc: 0.8121\n",
            "Epoch 643/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4188 - acc: 0.8320 - val_loss: 0.4782 - val_acc: 0.8171\n",
            "Epoch 644/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4389 - acc: 0.8279 - val_loss: 0.4262 - val_acc: 0.8436\n",
            "Epoch 645/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4444 - acc: 0.8145 - val_loss: 0.4478 - val_acc: 0.8294\n",
            "Epoch 646/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4412 - acc: 0.8268 - val_loss: 0.4704 - val_acc: 0.8251\n",
            "Epoch 647/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4441 - acc: 0.8191 - val_loss: 0.4410 - val_acc: 0.8325\n",
            "Epoch 648/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4363 - acc: 0.8308 - val_loss: 0.4568 - val_acc: 0.8313\n",
            "Epoch 649/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4487 - acc: 0.8201 - val_loss: 0.4611 - val_acc: 0.8127\n",
            "Epoch 650/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4373 - acc: 0.8245 - val_loss: 0.4969 - val_acc: 0.8152\n",
            "Epoch 651/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4439 - acc: 0.8224 - val_loss: 0.4630 - val_acc: 0.8269\n",
            "Epoch 652/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4423 - acc: 0.8226 - val_loss: 0.4733 - val_acc: 0.8319\n",
            "Epoch 653/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4511 - acc: 0.8226 - val_loss: 0.4508 - val_acc: 0.8356\n",
            "Epoch 654/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4511 - acc: 0.8239 - val_loss: 0.4565 - val_acc: 0.8362\n",
            "Epoch 655/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4436 - acc: 0.8208 - val_loss: 0.4986 - val_acc: 0.8412\n",
            "Epoch 656/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4281 - acc: 0.8341 - val_loss: 0.4655 - val_acc: 0.8300\n",
            "Epoch 657/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4604 - acc: 0.8198 - val_loss: 0.4466 - val_acc: 0.8393\n",
            "Epoch 658/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4505 - acc: 0.8196 - val_loss: 0.4782 - val_acc: 0.8313\n",
            "Epoch 659/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4346 - acc: 0.8288 - val_loss: 0.4660 - val_acc: 0.8251\n",
            "Epoch 660/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4568 - acc: 0.8187 - val_loss: 0.5027 - val_acc: 0.8022\n",
            "Epoch 661/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4417 - acc: 0.8210 - val_loss: 0.5231 - val_acc: 0.8232\n",
            "Epoch 662/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4320 - acc: 0.8253 - val_loss: 0.5385 - val_acc: 0.7942\n",
            "Epoch 663/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4517 - acc: 0.8221 - val_loss: 0.4604 - val_acc: 0.8294\n",
            "Epoch 664/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4402 - acc: 0.8231 - val_loss: 0.4770 - val_acc: 0.8195\n",
            "Epoch 665/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4465 - acc: 0.8227 - val_loss: 0.4912 - val_acc: 0.8208\n",
            "Epoch 666/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4278 - acc: 0.8288 - val_loss: 0.4571 - val_acc: 0.8344\n",
            "Epoch 667/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4293 - acc: 0.8232 - val_loss: 0.4604 - val_acc: 0.8344\n",
            "Epoch 668/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4396 - acc: 0.8243 - val_loss: 0.4642 - val_acc: 0.8319\n",
            "Epoch 669/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4390 - acc: 0.8189 - val_loss: 0.4912 - val_acc: 0.8072\n",
            "Epoch 670/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4328 - acc: 0.8267 - val_loss: 0.4626 - val_acc: 0.8282\n",
            "Epoch 671/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4385 - acc: 0.8224 - val_loss: 0.4734 - val_acc: 0.8319\n",
            "Epoch 672/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4607 - acc: 0.8137 - val_loss: 0.4577 - val_acc: 0.8307\n",
            "Epoch 673/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4412 - acc: 0.8184 - val_loss: 0.4452 - val_acc: 0.8375\n",
            "Epoch 674/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4365 - acc: 0.8303 - val_loss: 0.4583 - val_acc: 0.8344\n",
            "Epoch 675/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4457 - acc: 0.8162 - val_loss: 0.4761 - val_acc: 0.8220\n",
            "Epoch 676/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4327 - acc: 0.8260 - val_loss: 0.5069 - val_acc: 0.8109\n",
            "Epoch 677/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4426 - acc: 0.8231 - val_loss: 0.4897 - val_acc: 0.8208\n",
            "Epoch 678/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4367 - acc: 0.8234 - val_loss: 0.5069 - val_acc: 0.8171\n",
            "Epoch 679/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4416 - acc: 0.8256 - val_loss: 0.4671 - val_acc: 0.8208\n",
            "Epoch 680/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4385 - acc: 0.8248 - val_loss: 0.5153 - val_acc: 0.8189\n",
            "Epoch 681/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4351 - acc: 0.8278 - val_loss: 0.5021 - val_acc: 0.8239\n",
            "Epoch 682/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4450 - acc: 0.8254 - val_loss: 0.4813 - val_acc: 0.8251\n",
            "Epoch 683/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4418 - acc: 0.8184 - val_loss: 0.4657 - val_acc: 0.8325\n",
            "Epoch 684/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4307 - acc: 0.8316 - val_loss: 0.4724 - val_acc: 0.8325\n",
            "Epoch 685/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4266 - acc: 0.8304 - val_loss: 0.5146 - val_acc: 0.7991\n",
            "Epoch 686/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4468 - acc: 0.8206 - val_loss: 0.4728 - val_acc: 0.8337\n",
            "Epoch 687/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4450 - acc: 0.8207 - val_loss: 0.4939 - val_acc: 0.8208\n",
            "Epoch 688/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4387 - acc: 0.8224 - val_loss: 0.4892 - val_acc: 0.8331\n",
            "Epoch 689/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4398 - acc: 0.8239 - val_loss: 0.4849 - val_acc: 0.8226\n",
            "Epoch 690/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4467 - acc: 0.8220 - val_loss: 0.4678 - val_acc: 0.8288\n",
            "Epoch 691/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4281 - acc: 0.8278 - val_loss: 0.5108 - val_acc: 0.8208\n",
            "Epoch 692/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4294 - acc: 0.8283 - val_loss: 0.4402 - val_acc: 0.8393\n",
            "Epoch 693/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4400 - acc: 0.8197 - val_loss: 0.5142 - val_acc: 0.8158\n",
            "Epoch 694/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4393 - acc: 0.8217 - val_loss: 0.4782 - val_acc: 0.8337\n",
            "Epoch 695/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4347 - acc: 0.8250 - val_loss: 0.4951 - val_acc: 0.8158\n",
            "Epoch 696/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4222 - acc: 0.8338 - val_loss: 0.4952 - val_acc: 0.8257\n",
            "Epoch 697/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4394 - acc: 0.8263 - val_loss: 0.4804 - val_acc: 0.8307\n",
            "Epoch 698/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4208 - acc: 0.8338 - val_loss: 0.5377 - val_acc: 0.8109\n",
            "Epoch 699/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4357 - acc: 0.8214 - val_loss: 0.4725 - val_acc: 0.8455\n",
            "Epoch 700/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4404 - acc: 0.8245 - val_loss: 0.4751 - val_acc: 0.8307\n",
            "Epoch 701/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4491 - acc: 0.8228 - val_loss: 0.4947 - val_acc: 0.8164\n",
            "Epoch 702/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4333 - acc: 0.8278 - val_loss: 0.4947 - val_acc: 0.8300\n",
            "Epoch 703/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4344 - acc: 0.8345 - val_loss: 0.4643 - val_acc: 0.8276\n",
            "Epoch 704/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4415 - acc: 0.8207 - val_loss: 0.4767 - val_acc: 0.8226\n",
            "Epoch 705/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4336 - acc: 0.8277 - val_loss: 0.4769 - val_acc: 0.8251\n",
            "Epoch 706/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4369 - acc: 0.8280 - val_loss: 0.4896 - val_acc: 0.8239\n",
            "Epoch 707/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4413 - acc: 0.8221 - val_loss: 0.4781 - val_acc: 0.8276\n",
            "Epoch 708/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4330 - acc: 0.8286 - val_loss: 0.4983 - val_acc: 0.8208\n",
            "Epoch 709/2500\n",
            "227/227 [==============================] - 6s 27ms/step - loss: 0.4389 - acc: 0.8248 - val_loss: 0.5287 - val_acc: 0.8053\n",
            "Epoch 710/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4483 - acc: 0.8209 - val_loss: 0.4558 - val_acc: 0.8313\n",
            "Epoch 711/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4323 - acc: 0.8272 - val_loss: 0.4748 - val_acc: 0.8164\n",
            "Epoch 712/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4416 - acc: 0.8234 - val_loss: 0.4824 - val_acc: 0.8337\n",
            "Epoch 713/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4371 - acc: 0.8271 - val_loss: 0.4580 - val_acc: 0.8257\n",
            "Epoch 714/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4449 - acc: 0.8241 - val_loss: 0.4595 - val_acc: 0.8356\n",
            "Epoch 715/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4395 - acc: 0.8254 - val_loss: 0.5400 - val_acc: 0.8109\n",
            "Epoch 716/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4525 - acc: 0.8197 - val_loss: 0.4660 - val_acc: 0.8288\n",
            "Epoch 717/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4355 - acc: 0.8278 - val_loss: 0.4405 - val_acc: 0.8350\n",
            "Epoch 718/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4185 - acc: 0.8322 - val_loss: 0.4831 - val_acc: 0.8245\n",
            "Epoch 719/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4462 - acc: 0.8181 - val_loss: 0.4717 - val_acc: 0.8362\n",
            "Epoch 720/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4302 - acc: 0.8296 - val_loss: 0.4459 - val_acc: 0.8356\n",
            "Epoch 721/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4626 - acc: 0.8164 - val_loss: 0.6267 - val_acc: 0.7522\n",
            "Epoch 722/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4391 - acc: 0.8276 - val_loss: 0.4808 - val_acc: 0.8337\n",
            "Epoch 723/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4296 - acc: 0.8268 - val_loss: 0.4676 - val_acc: 0.8269\n",
            "Epoch 724/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4362 - acc: 0.8297 - val_loss: 0.4689 - val_acc: 0.8239\n",
            "Epoch 725/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4473 - acc: 0.8220 - val_loss: 0.4723 - val_acc: 0.8319\n",
            "Epoch 726/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4345 - acc: 0.8288 - val_loss: 0.4622 - val_acc: 0.8189\n",
            "Epoch 727/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4384 - acc: 0.8289 - val_loss: 0.5192 - val_acc: 0.8035\n",
            "Epoch 728/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4206 - acc: 0.8286 - val_loss: 0.4729 - val_acc: 0.8375\n",
            "Epoch 729/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4316 - acc: 0.8261 - val_loss: 0.4927 - val_acc: 0.8300\n",
            "Epoch 730/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4187 - acc: 0.8319 - val_loss: 0.4650 - val_acc: 0.8325\n",
            "Epoch 731/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4461 - acc: 0.8204 - val_loss: 0.5111 - val_acc: 0.8288\n",
            "Epoch 732/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4347 - acc: 0.8304 - val_loss: 0.4897 - val_acc: 0.8146\n",
            "Epoch 733/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4291 - acc: 0.8314 - val_loss: 0.4540 - val_acc: 0.8195\n",
            "Epoch 734/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4348 - acc: 0.8316 - val_loss: 0.4775 - val_acc: 0.8375\n",
            "Epoch 735/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4404 - acc: 0.8249 - val_loss: 0.4895 - val_acc: 0.8189\n",
            "Epoch 736/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4334 - acc: 0.8294 - val_loss: 0.4463 - val_acc: 0.8294\n",
            "Epoch 737/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4269 - acc: 0.8274 - val_loss: 0.4829 - val_acc: 0.8337\n",
            "Epoch 738/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4401 - acc: 0.8237 - val_loss: 0.4595 - val_acc: 0.8294\n",
            "Epoch 739/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4341 - acc: 0.8240 - val_loss: 0.4508 - val_acc: 0.8195\n",
            "Epoch 740/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4404 - acc: 0.8269 - val_loss: 0.4596 - val_acc: 0.8263\n",
            "Epoch 741/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4313 - acc: 0.8307 - val_loss: 0.4558 - val_acc: 0.8307\n",
            "Epoch 742/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4372 - acc: 0.8254 - val_loss: 0.4704 - val_acc: 0.8226\n",
            "Epoch 743/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4374 - acc: 0.8268 - val_loss: 0.4491 - val_acc: 0.8319\n",
            "Epoch 744/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4275 - acc: 0.8313 - val_loss: 0.4435 - val_acc: 0.8319\n",
            "Epoch 745/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4257 - acc: 0.8341 - val_loss: 0.4751 - val_acc: 0.8307\n",
            "Epoch 746/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4305 - acc: 0.8323 - val_loss: 0.4749 - val_acc: 0.8133\n",
            "Epoch 747/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4406 - acc: 0.8243 - val_loss: 0.4459 - val_acc: 0.8269\n",
            "Epoch 748/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4269 - acc: 0.8245 - val_loss: 0.4633 - val_acc: 0.8337\n",
            "Epoch 749/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4385 - acc: 0.8311 - val_loss: 0.4595 - val_acc: 0.8405\n",
            "Epoch 750/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4254 - acc: 0.8268 - val_loss: 0.4473 - val_acc: 0.8405\n",
            "Epoch 751/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4364 - acc: 0.8278 - val_loss: 0.4711 - val_acc: 0.8344\n",
            "Epoch 752/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4401 - acc: 0.8257 - val_loss: 0.4780 - val_acc: 0.8288\n",
            "Epoch 753/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4159 - acc: 0.8349 - val_loss: 0.4704 - val_acc: 0.8356\n",
            "Epoch 754/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4425 - acc: 0.8209 - val_loss: 0.4545 - val_acc: 0.8257\n",
            "Epoch 755/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4357 - acc: 0.8260 - val_loss: 0.4510 - val_acc: 0.8201\n",
            "Epoch 756/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4281 - acc: 0.8300 - val_loss: 0.4553 - val_acc: 0.8288\n",
            "Epoch 757/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4428 - acc: 0.8291 - val_loss: 0.4481 - val_acc: 0.8412\n",
            "Epoch 758/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4226 - acc: 0.8344 - val_loss: 0.4379 - val_acc: 0.8344\n",
            "Epoch 759/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4291 - acc: 0.8317 - val_loss: 0.4705 - val_acc: 0.8288\n",
            "Epoch 760/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4226 - acc: 0.8336 - val_loss: 0.4885 - val_acc: 0.8337\n",
            "Epoch 761/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4310 - acc: 0.8266 - val_loss: 0.4705 - val_acc: 0.8282\n",
            "Epoch 762/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4387 - acc: 0.8249 - val_loss: 0.4886 - val_acc: 0.8313\n",
            "Epoch 763/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4352 - acc: 0.8251 - val_loss: 0.4889 - val_acc: 0.8337\n",
            "Epoch 764/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4275 - acc: 0.8331 - val_loss: 0.4903 - val_acc: 0.8171\n",
            "Epoch 765/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4224 - acc: 0.8316 - val_loss: 0.5039 - val_acc: 0.8164\n",
            "Epoch 766/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4385 - acc: 0.8205 - val_loss: 0.4900 - val_acc: 0.8239\n",
            "Epoch 767/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4134 - acc: 0.8331 - val_loss: 0.5255 - val_acc: 0.8041\n",
            "Epoch 768/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4398 - acc: 0.8302 - val_loss: 0.4917 - val_acc: 0.8232\n",
            "Epoch 769/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4418 - acc: 0.8276 - val_loss: 0.4980 - val_acc: 0.8208\n",
            "Epoch 770/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4408 - acc: 0.8240 - val_loss: 0.4538 - val_acc: 0.8282\n",
            "Epoch 771/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4242 - acc: 0.8339 - val_loss: 0.4701 - val_acc: 0.8269\n",
            "Epoch 772/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4506 - acc: 0.8190 - val_loss: 0.4543 - val_acc: 0.8368\n",
            "Epoch 773/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4389 - acc: 0.8297 - val_loss: 0.4566 - val_acc: 0.8263\n",
            "Epoch 774/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4396 - acc: 0.8239 - val_loss: 0.4742 - val_acc: 0.8226\n",
            "Epoch 775/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4130 - acc: 0.8325 - val_loss: 0.4851 - val_acc: 0.8257\n",
            "Epoch 776/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4377 - acc: 0.8253 - val_loss: 0.4823 - val_acc: 0.8331\n",
            "Epoch 777/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4508 - acc: 0.8278 - val_loss: 0.4611 - val_acc: 0.8276\n",
            "Epoch 778/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4259 - acc: 0.8303 - val_loss: 0.4876 - val_acc: 0.8195\n",
            "Epoch 779/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4485 - acc: 0.8224 - val_loss: 0.4763 - val_acc: 0.8263\n",
            "Epoch 780/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4381 - acc: 0.8252 - val_loss: 0.4671 - val_acc: 0.8208\n",
            "Epoch 781/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4240 - acc: 0.8259 - val_loss: 0.4513 - val_acc: 0.8313\n",
            "Epoch 782/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4364 - acc: 0.8264 - val_loss: 0.4659 - val_acc: 0.8282\n",
            "Epoch 783/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4439 - acc: 0.8278 - val_loss: 0.4560 - val_acc: 0.8331\n",
            "Epoch 784/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4264 - acc: 0.8326 - val_loss: 0.4587 - val_acc: 0.8337\n",
            "Epoch 785/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4420 - acc: 0.8241 - val_loss: 0.4525 - val_acc: 0.8294\n",
            "Epoch 786/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4329 - acc: 0.8281 - val_loss: 0.4706 - val_acc: 0.8344\n",
            "Epoch 787/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4212 - acc: 0.8348 - val_loss: 0.4650 - val_acc: 0.8307\n",
            "Epoch 788/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4179 - acc: 0.8349 - val_loss: 0.4690 - val_acc: 0.8344\n",
            "Epoch 789/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4383 - acc: 0.8246 - val_loss: 0.4631 - val_acc: 0.8245\n",
            "Epoch 790/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4238 - acc: 0.8295 - val_loss: 0.5003 - val_acc: 0.8245\n",
            "Epoch 791/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4328 - acc: 0.8219 - val_loss: 0.4882 - val_acc: 0.8257\n",
            "Epoch 792/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4212 - acc: 0.8326 - val_loss: 0.5036 - val_acc: 0.8041\n",
            "Epoch 793/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4265 - acc: 0.8290 - val_loss: 0.4838 - val_acc: 0.8208\n",
            "Epoch 794/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4179 - acc: 0.8351 - val_loss: 0.4897 - val_acc: 0.8171\n",
            "Epoch 795/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4279 - acc: 0.8268 - val_loss: 0.5291 - val_acc: 0.8096\n",
            "Epoch 796/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4266 - acc: 0.8301 - val_loss: 0.4740 - val_acc: 0.8356\n",
            "Epoch 797/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4441 - acc: 0.8199 - val_loss: 0.4763 - val_acc: 0.8195\n",
            "Epoch 798/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4242 - acc: 0.8316 - val_loss: 0.4803 - val_acc: 0.8387\n",
            "Epoch 799/2500\n",
            "227/227 [==============================] - 7s 29ms/step - loss: 0.4279 - acc: 0.8268 - val_loss: 0.4770 - val_acc: 0.8276\n",
            "Epoch 800/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4274 - acc: 0.8291 - val_loss: 0.5176 - val_acc: 0.8127\n",
            "Epoch 801/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4242 - acc: 0.8305 - val_loss: 0.4864 - val_acc: 0.8239\n",
            "Epoch 802/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4359 - acc: 0.8265 - val_loss: 0.4828 - val_acc: 0.8350\n",
            "Epoch 803/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4170 - acc: 0.8319 - val_loss: 0.5066 - val_acc: 0.8232\n",
            "Epoch 804/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4359 - acc: 0.8283 - val_loss: 0.4848 - val_acc: 0.8245\n",
            "Epoch 805/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4241 - acc: 0.8265 - val_loss: 0.4669 - val_acc: 0.8282\n",
            "Epoch 806/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4503 - acc: 0.8232 - val_loss: 0.4655 - val_acc: 0.8263\n",
            "Epoch 807/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4292 - acc: 0.8319 - val_loss: 0.4747 - val_acc: 0.8405\n",
            "Epoch 808/2500\n",
            "227/227 [==============================] - 6s 29ms/step - loss: 0.4236 - acc: 0.8300 - val_loss: 0.4617 - val_acc: 0.8443\n",
            "Epoch 809/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4337 - acc: 0.8332 - val_loss: 0.4659 - val_acc: 0.8412\n",
            "Epoch 810/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4290 - acc: 0.8309 - val_loss: 0.4465 - val_acc: 0.8350\n",
            "Epoch 811/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4276 - acc: 0.8285 - val_loss: 0.4449 - val_acc: 0.8313\n",
            "Epoch 812/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4402 - acc: 0.8308 - val_loss: 0.4625 - val_acc: 0.8319\n",
            "Epoch 813/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4189 - acc: 0.8329 - val_loss: 0.4635 - val_acc: 0.8430\n",
            "Epoch 814/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4406 - acc: 0.8297 - val_loss: 0.4544 - val_acc: 0.8251\n",
            "Epoch 815/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4426 - acc: 0.8237 - val_loss: 0.4644 - val_acc: 0.8257\n",
            "Epoch 816/2500\n",
            "227/227 [==============================] - 6s 28ms/step - loss: 0.4299 - acc: 0.8282 - val_loss: 0.4560 - val_acc: 0.8337\n",
            "Epoch 817/2500\n",
            "223/227 [============================>.] - ETA: 0s - loss: 0.4383 - acc: 0.8237"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mUAhvFxy-Mfs",
        "colab": {}
      },
      "source": [
        "# train with full augmentation\n",
        "print(mName, '\\n', 'Full Augmentation\\n')\n",
        "model.fit_generator(extraGen.flow(X_train, Y_train),\n",
        "                    steps_per_epoch=14557//batch_size,\n",
        "                    epochs=2500,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn56MVo7kuuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('Troika++ 2300', '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlwvBt9N5Iak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history.keys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tos15BFuVzm",
        "colab_type": "text"
      },
      "source": [
        "# **Best Configuration**<br>\n",
        "CCNN Dense w/ Adam, moreGen<br>\n",
        "Should converge to ~84% validation accuracy in ~600 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AS-QDzDtuvo-",
        "colab": {}
      },
      "source": [
        "moreGen = ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=0.05,\n",
        "                               height_shift_range=0.05,\n",
        "                               #shear_range=0.01,\n",
        "                               zoom_range=[0.9, 1.1],\n",
        "                               horizontal_flip=True,\n",
        "                               #vertical_flip=False,\n",
        "                               fill_mode='nearest',\n",
        "                               data_format='channels_last')\n",
        "\n",
        "moreGen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EEFrlMEeupaZ",
        "colab": {}
      },
      "source": [
        "# Trained w/ moreGen for about 600 epochs\n",
        "# Yields >85% testing accuracy\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, kernel_size=(2,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.name = 'CCNN Dense'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5erWUTVVuzrH",
        "colab": {}
      },
      "source": [
        "num_classes = 3\n",
        "batch_size = 64\n",
        "epochs = 700"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kcFlszeXu3L_",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=(['accuracy']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PmVoepVeu6KY",
        "colab": {}
      },
      "source": [
        "# train with full augmentation\n",
        "# this ruins validation accuracy\n",
        "print(mName, '\\n', 'Full Augmentation\\n')\n",
        "model.fit_generator(moreGen.flow(X_train, Y_train),\n",
        "                    steps_per_epoch=14557//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfxcnVReUp-J",
        "colab_type": "text"
      },
      "source": [
        "#**Export Section**\n",
        "Export results as formatted CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQRKPV-ApV_m",
        "colab_type": "code",
        "outputId": "b273d151-f68e-4cdf-85e2-0516370d7032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_pred = np.argmax(model.predict(test_data), axis=1)\n",
        "print(test_pred)\n",
        "\n",
        "row1=np.arange(len(test_pred))\n",
        "print(row1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 0 0 ... 1 2 2]\n",
            "[   0    1    2 ... 3962 3963 3964]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lpoG17cslZr",
        "colab_type": "code",
        "outputId": "045ab6a3-0f37-47be-cf06-bd1ae7355b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "val_pred = np.argmax(model.predict(X_valid), axis=1)\n",
        "print(val_pred[397])\n",
        "\n",
        "print(Y_valid[397])\n",
        "\n",
        "for i in range(len(Y_valid)):\n",
        "  print(val_pred[i], ' ', Y_valid[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "0   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "1   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "0   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "0   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [1. 0. 0.]\n",
            "2   [1. 0. 0.]\n",
            "0   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "0   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [1. 0. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [1. 0. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n",
            "2   [0. 0. 1.]\n",
            "2   [0. 0. 1.]\n",
            "1   [0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywck6WdGtIBf",
        "colab_type": "code",
        "outputId": "1074db73-89eb-4874-861a-79e282914a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res_matx = np.vstack([row1, test_pred]).transpose()\n",
        "print(res_matx.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3965, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myWyKT5Otacc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"res1.csv\", res_matx, delimiter=',', fmt='%d')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}